{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "necessary-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in the hyperparameter space with W&B sweep\n",
    "import logging\n",
    "from ast import literal_eval as load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import sklearn\n",
    "\n",
    "from simpletransformers.classification import (\n",
    "    ClassificationArgs,\n",
    "    ClassificationModel,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "available-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "df = pd.read_csv('triples.csv')\n",
    "df.insert(loc=0, column='idx', value=np.arange(len(df)))\n",
    "sent_num=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "operational-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(arr):\n",
    "    trip_ls = []\n",
    "    ls = []\n",
    "    for i in range(len(arr)):\n",
    "        pre_ls = literal_eval(arr[i, 3])\n",
    "        np_ls = literal_eval(arr[i, 4])\n",
    "        p_idx = [(1, *p[1]) for p in pre_ls]\n",
    "        n_idx = [(0, *n[1]) for n in np_ls]\n",
    "        for p in range(len(p_idx)):\n",
    "            for j in range(len(n_idx)-1):\n",
    "                for k in range(j+1, len(n_idx)):\n",
    "                    trip = [np_ls[j][0],pre_ls[p][0],np_ls[k][0]]\n",
    "                    trip_ls.append(trip)\n",
    "                    word_ls = arr[i, 2].split(' ')\n",
    "                    indx = sorted([p_idx[p], n_idx[j], n_idx[k]], key=lambda x:x[1])\n",
    "                    for w in range(len(indx)):\n",
    "                        if indx[w][0] == 1:\n",
    "                            word_ls.insert(indx[w][1]+2*w, '<<')\n",
    "                            word_ls.insert(indx[w][2]+2*w+1, '>>')\n",
    "                        else:\n",
    "                            word_ls.insert(indx[w][1]+2*w, '[[')\n",
    "                            word_ls.insert(indx[w][2]+2*w+1, ']]')\n",
    "                    flg = 0\n",
    "                    for tp in literal_eval(arr[i, 5]):\n",
    "                        if tp == [np_ls[j][0], pre_ls[p][0], np_ls[k][0]]:\n",
    "                            flg = 1\n",
    "                            break\n",
    "                    ls.append([int(arr[i, 0]), ' '.join(word_ls), flg])\n",
    "    dataframe = pd.DataFrame(ls)\n",
    "    dataframe.columns = ['idx', 'text', 'labels']\n",
    "    return dataframe,trip_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "verbal-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.values\n",
    "df,trip_ls=convert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tamil-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ClassificationArgs()\n",
    "\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.manual_seed = 1\n",
    "model_args.fp16 = False\n",
    "model_args.use_multiprocessing = True\n",
    "model_args.do_lower_case = True  # when using uncased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "finite-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_F1(ref, pred):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lyric-frontier",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520f459f927746bf98742887bc5fe077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88981 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0459bcf4bc4f108983b6b05eb16482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/11123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/hl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'tp': 0, 'tn': 83218, 'fp': 5763, 'fn': 0, 'F1_score': 0, 'eval_loss': 0.3230459850473971}\n"
     ]
    }
   ],
   "source": [
    "# Create a TransformerModel\n",
    "model = ClassificationModel(\n",
    "    \"bert\",\n",
    "    \"../rel/outputsA/best_model\",\n",
    "    args=model_args,\n",
    ")\n",
    "result, model_outputs, wrong_predictions = model.eval_model(df, F1_score=triple_F1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sacred-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list(model_outputs.argmax(axis=1))\n",
    "df['preds']=preds\n",
    "df['cand']=trip_ls\n",
    "df.loc[df['preds']==0,'cand']=None\n",
    "data=[]\n",
    "for i in range(sent_num):\n",
    "    temp = list(df[df['idx']==i]['cand'])\n",
    "    temp = [t for t in temp if t]\n",
    "    data.append(str(temp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cooperative-nigeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[]',\n",
       " '[]',\n",
       " \"[['RNNGs', 'operate via', 'recursive syntactic process'], ['decisions', 'parameterized using', 'RNNs'], ['RNNs', 'condition on', 'entire syntactic derivation history']]\",\n",
       " \"[['two variants', 'of', 'algorithm']]\",\n",
       " \"[['ancestor sampling', 'to obtain', 'samples'], ['samples', 'of', 'parse trees'], ['parse trees', 'for', 'sentences'], ['RNNGs', 'approximating', 'marginal likelihood and MAP tree']]\",\n",
       " \"[['simple importance sampling algorithm', 'uses', 'samples'], ['samples', 'from', 'discriminative parser'], ['samples', 'to solve', 'inference problems'], ['discriminative parser', 'to solve', 'inference problems'], ['inference problems', 'in', 'generative model']]\",\n",
       " \"[['discriminative model', 'used', 'hidden dimensions'], ['hidden dimensions', 'of', '128 and 2 - layer LSTMs']]\",\n",
       " \"[['generative model', 'used', '256 dimensions'], ['generative model', 'used', '2 layer LSTMs']]\",\n",
       " \"[['dropout rate', 'to maximize', 'validation set likelihood'], ['dropout rate', 'obtaining', 'optimal rates'], ['validation set likelihood', 'obtaining', 'optimal rates']]\",\n",
       " \"[['sequential LSTM baseline', 'For', 'language model'], ['sequential LSTM baseline', 'for', 'language model'], ['sequential LSTM baseline', 'found', 'optimal dropout rate'], ['optimal dropout rate', 'of', '0.3']]\",\n",
       " \"[['training', 'used', 'stochastic gradient descent'], ['stochastic gradient descent', 'with', 'learning rate'], ['learning rate', 'of', '0.1']]\",\n",
       " '[]',\n",
       " \"[['bi-directional transformer model', 'provides', 'significant performance gains']]\",\n",
       " '[]',\n",
       " \"[['even larger performance gains', 'jointly pretraining', 'both directions'], ['both directions', 'of', 'large language - model - inspired self - attention cloze model']]\",\n",
       " \"[['every token', 'in', 'training data']]\",\n",
       " \"[['cloze - style training objective', 'where', 'model'], ['center word', 'given', 'left - to - right and right - to - left context representations']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['CNN models', 'use', 'adaptive softmax'], ['adaptive softmax', 'in', 'output'], ['headband', 'contains', '60K most frequent types'], ['60K most frequent types', 'with', 'dimensionality'], ['dimensionality', 'followed by', '160 K band'], ['1024', 'followed by', '160 K band'], ['160 K band', 'with', 'dimensionality'], ['160 K band', 'with', 'momentum'], ['dimensionality', 'with', 'momentum'], ['momentum', 'of', '0.99'], ['gradients', 'if', 'norm'], ['norm', 'exceeds', '0.1']]\",\n",
       " \"[['linearly warmed up', 'from', '10 ? 7 to 1'], ['10 ? 7 to 1', 'for', '16 K steps'], ['learning rate', 'annealed using', 'cosine learning rate schedule'], ['cosine learning rate schedule', 'with', 'single phase'], ['single phase', 'to', '0.0001']]\",\n",
       " \"[['experiments', 'on', 'DGX - 1 machines'], ['DGX - 1 machines', 'with', '8 NVIDIA V100 GPUs']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Our CNN base model', 'performs', 'STILTs'], ['Our CNN base model', 'as well as', 'STILTs'], ['STILTs', 'in', 'aggregate'], ['STILTs', 'performs', 'much better']]\",\n",
       " '[]',\n",
       " \"[['fine tuning', 'gives', 'biggest gain']]\",\n",
       " '[]',\n",
       " \"[['bilm loss', 'dominating', 'triplet loss'], ['scaling', 'by', 'factor'], ['bilm term', 'by', 'factor'], ['factor', 'of', '0.15'], ['0.15', 'results in', 'better performance']]\",\n",
       " \"[['cloze loss', 'performs', 'significantly better'], ['significantly better', 'than', 'bilm loss'], ['cloze loss', 'combining', 'two loss types']]\",\n",
       " '[]',\n",
       " \"[['Seq2seq approach', 'as', 'stronger baseline'], ['stronger baseline', 'of', 'constituency parsing']]\",\n",
       " \"[['gradient clipping G', 'provided', 'better performance']]\",\n",
       " \"[['beam size', 'have', 'little impact'], ['little impact', 'on', 'performance'], ['L = 2 , H = 200 , and B = 5', 'looks', 'adequate'], ['adequate', 'in terms of', 'speed / performance trade - off']]\",\n",
       " \"[['subword split', 'as', 'input token unit'], ['input token unit', 'instead of', 'standard tokenized word unit']]\",\n",
       " \"[['subword information', 'as', 'features']]\",\n",
       " \"[['Seq2seq approach', 'successfully achieved', 'competitive level'], ['competitive level', 'as', 'current top - notch methods']]\",\n",
       " '[]',\n",
       " \"[['artificial dataset', 'by labelling', 'large corpus'], ['large corpus', 'with', 'BerkeleyParser']]\",\n",
       " \"[['sequence - to - sequence model', 'with', 'attention'], ['attention', 'on', 'small human - annotated parsing dataset'], ['sequence - to - sequence model', 'able to achieve', 'F 1 score'], ['F 1 score', 'of', '88.3'], ['90.5', 'with', 'ensemble'], ['ensemble', 'matches', 'performance']]\",\n",
       " \"[['second artificial dataset', 'consisting of', 'high - confidence parse trees'], ['high - confidence parse trees', 'measured by', 'agreement'], ['agreement', 'of', 'two parsers']]\",\n",
       " \"[['sequence - to - sequence model', 'with', 'attention'], ['F 1 score', 'of', '92.5']]\",\n",
       " \"[['model', 'with', '3 LSTM layers'], ['model', 'with', '256 units'], ['256 units', 'in', 'each layer']]\",\n",
       " '[]',\n",
       " \"[['embedding layer', 'for', '90K vocabulary'], ['90K vocabulary', 'can be', 'initialized randomly'], ['90K vocabulary', 'can be', 'pre-trained word - vector embeddings'], ['embedding layer', 'using', 'pre-trained word - vector embeddings']]\",\n",
       " \"[['skip - gram embeddings', 'of size', '512'], ['skip - gram embeddings', 'using', 'word2vec'], ['512', 'using', 'word2vec'], ['word2vec', 'on', '10B - word corpus']]\",\n",
       " \"[['single attention model', 'gets to', '88.3'], ['ensemble of 5 LSTM + A+D models', 'achieves', '90.5'], ['90.5', 'matching', 'single - model BerkeleyParser'], ['single - model BerkeleyParser', 'on', 'WSJ']]\",\n",
       " \"[['single LSTM + A model', 'achieves', '92.5']]\",\n",
       " \"[['ensemble', 'of', '5 LSTM+ A models'], ['5 LSTM+ A models', 'improves', 'score'], ['score', 'to', '92.8']]\",\n",
       " \"[['LSTM + A model', 'trained on', 'WSJ dataset'], ['WSJ dataset', 'produced', 'malformed trees'], ['malformed trees', 'for', '25 of the 1700 sentences'], ['25 of the 1700 sentences', 'in', 'our development set'], ['full high - confidence dataset', 'for', '14 sentences ( 0.8 % )']]\",\n",
       " \"[['difference', 'between', 'F 1 score'], ['F 1 score', 'on', 'sentences'], ['1.3', 'for', 'BerkeleyParser'], ['1.3', 'for', 'baseline LSTM'], ['1.3', 'for', '0.7'], ['1.7', 'for', 'baseline LSTM'], ['0.7', 'for', 'LSTM + A']]\",\n",
       " \"[['LSTM + A', 'trained on', 'high - confidence corpus'], ['high - confidence corpus', 'achieved', 'F 1 score'], ['F 1 score', 'of', '95.7'], ['F 1 score', 'of', '84.6'], ['95.7', 'on', 'QTB'], ['95.7', 'on', '84.6'], ['84.6', 'on', 'WEB']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['beam - based search procedure', 'with', 'augmented state space'], ['augmented state space', 'search directly in', 'generative models']]\",\n",
       " '[[\\'weighted average\\', \\'of\\', \\'scores\\'], [\\'scores\\', \\'of\\', \\'both models\\'], [\\'scores\\', \\'of\\', \\'both models\\'], [\\'scores\\', \\'when selecting\\', \\'parse\\'], [\\'both models\\', \\'when selecting\\', \\'parse\\'], [\\'parse\\', \\'from\\', \"base parser \\'s candidate list\"], [\\'score\\', \\'of\\', \\'generative model\\']]',\n",
       " '[]',\n",
       " \"[['performance', 'from', '93.45 F1'], ['93.45 F1', 'to', '92.78 F1'], ['92.78 F1', 'on', 'development set']]\",\n",
       " '[]',\n",
       " \"[['scores', 'of', 'both models'], ['score', 'of', 'either model alone'], ['score', 'of', 'either model alone']]\",\n",
       " '[]',\n",
       " \"[['candidates and scores', 'from', 'all three models'], ['candidates and scores', 'obtain', '93.94 F1 .'], ['candidates and scores', 'obtain', '93.94 F1'], ['all three models', 'obtain', '93.94 F1 .'], ['all three models', 'obtain', '93.94 F1']]\",\n",
       " \"[['same model type', 'trained from', 'different random initializations']]\",\n",
       " \"[['Performance', 'when using', 'ensembled RD models'], ['ensembled RD models', 'is', 'lower'], ['lower', 'rescoring', 'single RD model'], ['single RD model', 'with', 'score combinations']]\",\n",
       " \"[['ensembling', 'with', 'score combination'], ['ensembling', 'achieves', 'best over all result'], ['score combination', 'achieves', 'best over all result'], ['best over all result', 'of', '94.25']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['novel transition system', 'for', 'constituent parsing']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['bottom - up system', 'performs', 'slightly better'], ['slightly better', 'than', 'top - down system']]\",\n",
       " \"[['inorder system', 'outperforms', 'bottom - up and the top - down system']]\",\n",
       " \"[['bottom - up parser and the top - down parser', 'have', 'similar results'], ['similar results', 'under', 'greedy setting']]\",\n",
       " '[]',\n",
       " \"[['inorder parser', 'outperforms', 'state - of - the - art discrete parser'], ['inorder parser', 'outperforms', 'state - of - the - art neural parsers']]\",\n",
       " '[]',\n",
       " \"[['our final model', 'achieves', 'best results'], ['best results', 'among', 'transitionbased parsing'], ['our final model', 'obtains', 'comparable results'], ['comparable results', 'to', 'state - of - the - art graph - based models']]\",\n",
       " '[]',\n",
       " \"[['2 - 21', 'as', 'training']]\",\n",
       " '[]',\n",
       " \"[['neural - net parse reranker', 'achieves', 'very good results'], ['very good results', 'with', 'comparatively simple architecture']]\",\n",
       " \"[['three LSTM layers', 'with', '1,500 units'], ['three LSTM layers', 'trained with', 'truncated backpropagation'], ['truncated backpropagation', 'through', 'time'], ['truncated backpropagation', 'with', 'step size 50'], ['time', 'with', 'mini-batch size 20'], ['time', 'with', 'step size 50']]\",\n",
       " '[[\\'starting states\\', \\'with\\', \"previous minibatch \\'s last hidden states\"]]',\n",
       " \"[['forget gate bias', 'initialized to be', 'one'], ['rest of model parameters', 'sampled from', 'U ( ? 0.05 , 0.05 )']]\",\n",
       " \"[['Dropout', 'applied to', 'non-recurrent connections'], ['clipped', 'when', 'norm'], ['norm', 'bigger than', '20']]\",\n",
       " \"[['learning rate', 'is', '0.25 0.85 max']]\",\n",
       " \"[['vanilla softmax', 'over', 'entire vocabulary']]\",\n",
       " '[]',\n",
       " \"[['single LSTM - LM ( GS )', 'together with', 'Charniak ( GS )'], ['Charniak ( GS )', 'reaches', '93.6'], ['Charniak ( GS )', 'achieves', 'new state of the art']]\",\n",
       " \"[['trees', 'converted to', 'Stanford dependencies'], ['UAS and LAS', 'are', '95.9 % and 94.1 %']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['RNNGs', 'as', 'generative probabilistic models'], ['generative probabilistic models', 'over', 'trees']]\",\n",
       " \"[['inductive bias', 'of', 'RNNGs'], ['inductive bias', 'to test', 'linguistic hypotheses'], ['RNNGs', 'to test', 'linguistic hypotheses']]\",\n",
       " \"[['importance', 'of', 'composition function']]\",\n",
       " \"[['RNNG composition function', 'with', 'novel gated attention mechanism'], ['novel gated attention mechanism', 'leading to', 'GA - RNNG'], ['novel gated attention mechanism', 'to incorporate', 'more interpretability'], ['more interpretability', 'into', 'model']]\",\n",
       " \"[['GA - RNNG', 'investigating', 'role']]\",\n",
       " '[[\\'RNNG\\', \\'with\\', \\'only a stack\\'], [\\'\" full \" RNNG\\', \\'with\\', \\'all three data structures\\'], [\\'RNNG\\', \\'outperforms\\', \\'\" full \" RNNG\\'], [\\'\" full \" RNNG\\', \\'with\\', \\'all three data structures\\']]',\n",
       " \"[['stack', 'gives', 'worst'], ['worst', 'among', 'new results']]\",\n",
       " \"[['stack - only RNNG', 'achieves', 'best performance'], ['stack', 'is', 'most harmful']]\",\n",
       " \"[['syntax', 'without', 'explicit composition'], ['syntax', 'provides', 'little benefit'], ['little benefit', 'over', 'sequential LSTM language model']]\",\n",
       " \"[['stack - only results', 'are', 'best published PTB results'], ['best published PTB results', 'for', 'phrasestructure and dependency parsing'], ['phrasestructure and dependency parsing', 'among', 'supervised models']]\",\n",
       " '[]',\n",
       " \"[['model', 'outperforms', 'baseline RNNG'], ['baseline RNNG', 'with', 'all three structures'], ['competitive performance', 'with', 'strongest , stack - only , RNNG variant'], ['model', 'achieves', 'competitive performance'], ['competitive performance', 'with', 'strongest , stack - only , RNNG variant']]\",\n",
       " '[]',\n",
       " \"[['higher overlap', 'with', 'conversion'], ['conversion', 'using', 'Collins head rules ( 49.8 UAS )']]\",\n",
       " \"[['high error rate ( ? 90 % )', 'when', 'dependent'], ['dependent', 'is', 'verb']]\",\n",
       " \"[['conversion accuracy', 'better for', 'nouns ( ? 50 % error )'], ['conversion accuracy', 'much better for', 'determiners ( 30 % ) and particles ( 6 % )'], ['much better', 'for', 'determiners ( 30 % ) and particles ( 6 % )'], ['determiners ( 30 % ) and particles ( 6 % )', 'with respect to', 'Collins head rules']]\",\n",
       " '[]',\n",
       " \"[['test data', 'with', 'usual split'], ['GA - RNNG', 'achieves', '94.2 %'], ['U - GA - RNNG', 'achieves', '93.5 %']]\",\n",
       " '[]',\n",
       " \"[['parser', 'combines', 'encoder'], ['decoder', 'customized for', 'parsing']]\",\n",
       " \"[['character LSTM', 'performs', 'better'], ['better', 'than', 'other lexical representationseven']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['test score', 'of', '93.55 F1'], ['93.55 F1', 'for', 'our CharLSTM parser'], ['previous best numbers', 'for', 'single - system parsers'], ['our CharLSTM parser', 'exceeds', 'previous best numbers'], ['previous best numbers', 'for', 'single - system parsers'], ['single - system parsers', 'trained on', 'Penn Treebank']]\",\n",
       " \"[['our parser', 'augmented with', 'ELMo word representations'], ['our parser', 'achieves', 'new state - of - the - art score'], ['ELMo word representations', 'achieves', 'new state - of - the - art score'], ['new state - of - the - art score', 'of', '95.13 F1'], ['95.13 F1', 'on', 'WSJ test set']]\",\n",
       " '[]',\n",
       " \"[['Development set results', 'addition of', 'word embeddings'], ['word embeddings', 'to', 'model'], ['model', 'that uses', 'character LSTM'], ['performance', 'for', 'some languages'], ['hurts', 'for', 'others']]\",\n",
       " \"[['test set result', 'exceeds', 'previous best - published numbers']]\",\n",
       " '[]',\n",
       " \"[['deep neural network', 'to build', 'distributed representations'], ['distributed representations', 'of', 'pairs']]\",\n",
       " \"[['entity - level information', 'with', 'large number of learned , continuous features'], ['large number of learned , continuous features', 'instead of', 'small number of hand - crafted categorical ones']]\",\n",
       " \"[['two coreference clusters', 'is', 'desirable']]\",\n",
       " \"[['test time', 'builds up', 'coreference clusters'], ['coreference clusters', 'starting with', 'each mention'], ['each mention', 'in', 'own cluster'], ['coreference clusters', 'merging', 'pair of clusters']]\",\n",
       " \"[['novel easy - first cluster - ranking procedure', 'combines', 'strengths']]\",\n",
       " \"[['learning - to - search algorithm', 'inspired by', 'SEARN'], ['learning - to - search algorithm', 'to train', 'neural network'], ['SEARN', 'to train', 'neural network']]\",\n",
       " '[]',\n",
       " \"[['mention - ranking model', 'surpasses', 'all previous systems']]\",\n",
       " \"[['cluster - ranking model', 'improves', 'results'], ['results', 'across', 'both languages and all evaluation metrics'], ['further', 'across', 'both languages and all evaluation metrics']]\",\n",
       " '[]',\n",
       " \"[['goal - directed endto - end deep reinforcement learning framework', 'to resolve', 'coreference']]\",\n",
       " \"[['policy network', 'includes', 'learning'], ['span representation', 'scoring', 'potential entity mentions'], ['policy network', 'generating', 'probability distribution'], ['learning', 'generating', 'probability distribution'], ['actions', 'from', 'current mention'], ['actions', 'to', 'antecedents'], ['current mention', 'to', 'antecedents']]\",\n",
       " \"[['sequence of linking actions', 'made', 'reward function'], ['linking actions', 'made', 'reward function'], ['reward function', 'to measure', 'how good']]\",\n",
       " \"[['entropy regularization term', 'to encourage', 'exploration'], ['entropy regularization term', 'prevent', 'policy'], ['policy', 'prematurely converging to', 'bad local optimum']]\",\n",
       " \"[['regularized policy network parameters', 'based on', 'rewards'], ['rewards', 'associated with', 'sequences of sampled actions'], ['sequences of sampled actions', 'computed on', 'whole input document']]\",\n",
       " '[]',\n",
       " \"[['learned parameters', 'for', 'initialization'], ['our model', 'use', 'learned parameters'], ['learned parameters', 'for', 'initialization']]\",\n",
       " \"[['number of sampled trajectories N s', '=', '100'], ['number of sampled trajectories N s', 'tune', 'regularization parameter'], ['regularization parameter', 'in', '{ 10 ?5 , 10 ?4 , 0.001 , 0.01 , 0.1 , 1 }'], ['regularization parameter', 'set it to', '10 ? 4']]\",\n",
       " '[]',\n",
       " \"[['our base reinforced model', 'improves', 'average F 1 score'], ['average F 1 score', 'around', '2 points']]\",\n",
       " \"[['entropy regularization', 'to encourage', 'exploration'], ['entropy regularization', 'improve', 'result'], ['exploration', 'improve', 'result'], ['result', 'by', '1 point']]\",\n",
       " \"[['context - dependent ELMo embedding', 'to', 'our base model']]\",\n",
       " \"[['our full model', 'achieves', 'state - of the - art performance'], ['state - of the - art performance', 'of', '73.8 % F1 - score'], ['73.8 % F1 - score', 'when using', 'ELMo and entropy regularization'], ['best F1 -score', 'of', '70.5 %'], ['70.5 %', 'when using', 'fixed word embedding only']]\",\n",
       " '[]',\n",
       " \"[['two variants of reinforcement learning', 'to directly optimize', 'coreference system'], ['coreference system', 'for', 'coreference evaluation metrics']]\",\n",
       " '[[\\'max-margin coreference objective\\', \\'by incorporating\\', \\'reward\\'], [\\'reward\\', \\'associated with\\', \\'each coreference decision\\'], [\\'reward\\', \\'into\\', \"loss \\'s slack rescaling\"]]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['REINFORCE', 'does', 'slightly better'], ['slightly better', 'than', 'heuristic loss'], ['reward rescaling', 'performs', 'significantly better'], ['significantly better', 'than', 'both'], ['significantly better', 'on', 'both languages'], ['both', 'on', 'both languages']]\",\n",
       " \"[['reward - rescaled max - margin loss', 'combines', 'best of both worlds'], ['best of both worlds', 'resulting in', 'superior performance']]\",\n",
       " '[]',\n",
       " \"[['approximation', 'of', 'higher - order inference'], ['higher - order inference', 'uses', 'span - ranking architecture'], ['span - ranking architecture', 'in', 'iterative manner']]\",\n",
       " \"[['antecedent distribution', 'used as', 'attention mechanism'], ['attention mechanism', 'to optionally update', 'existing span representations'], ['existing span representations', 'enabling', 'later corefer']]\",\n",
       " \"[['coarseto - fine approach', 'learned with', 'single endto - end objective']]\",\n",
       " \"[['less accurate but more efficient coarse factor', 'in', 'pairwise scoring function']]\",\n",
       " \"[['extra pruning step', 'during', 'inference'], ['number of antecedents', 'considered by', 'more accurate but inefficient fine factor']]\",\n",
       " \"[['rough sketch', 'of', 'likely antecedents'], ['rough sketch', 'before applying', 'more expensive scoring function']]\",\n",
       " '[]',\n",
       " \"[['span - ranking model', 'augmented with', 'ELMo and hyperparameter tuning'], ['span - ranking model', 'achieves', '72.3 F1']]\",\n",
       " \"[['Our full approach', 'achieves', '73.0 F1']]\",\n",
       " '[]',\n",
       " \"[['much higher recall', 'when adopting', 'coarse - to - fine approach']]\",\n",
       " \"[['further improvement', 'including', 'second - order inference']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['mention - ranking model', 'for', 'coreference resolution'], ['Siamese Net', 'for learning', 'similarity']]\",\n",
       " \"[['LSTM - Siamese Net', 'learns', 'representations'], ['representations', 'for', 'candidate and the anaphoric sentence'], ['candidate and the anaphoric sentence', 'in', 'shared space']]\",\n",
       " \"[['representations', 'combined into', 'joint representation'], ['joint representation', 'used to calculate', 'score'], ['score', 'characterizes', 'relation']]\",\n",
       " \"[['highest - scoring antecedent candidate', 'for', 'given anaphoric sentence']]\",\n",
       " \"[['embedding', 'of', 'context'], ['embedding', 'of', 'embedding'], ['context', 'of', 'anaphor'], ['context', 'of', 'anaphor'], ['embedding', 'of', 'head of the anaphoric phrase'], ['embedding', 'of', 'head of the anaphoric phrase'], ['head of the anaphoric phrase', 'to', 'input'], ['input', 'to characterize', 'each individual anaphorsimilar']]\",\n",
       " \"[['model', 'learns', 'relation'], ['relation', 'between', 'anaphor'], ['anaphor', 'in', 'anaphoric sentence'], ['anaphor', 'in', 'antecedent']]\",\n",
       " \"[['large amounts of instances', 'easily adaptable to', 'other languages']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['preceding sentence baseline ( PS BL )', 'chooses', 'previous sentence'], ['preceding sentence baseline ( PS BL )', 'chooses', 'TAGbaseline ( TAG BL )'], ['previous sentence', 'for', 'antecedent'], ['previous sentence', 'for', 'TAGbaseline ( TAG BL )'], ['TAGbaseline ( TAG BL )', 'randomly chooses', 'candidate'], ['candidate', 'with', 'constituent tag label'], ['constituent tag label', 'in', '{S , VP , ROOT , SBAR }']]\",\n",
       " \"[['Glo Ve word embeddings', 'pre-trained on', 'Gigaword and Wikipedia']]\",\n",
       " \"[['Vocabulary', 'built from', 'words'], ['words', 'in', 'training data'], ['frequency', 'in', '{ 3 , U ( 1 , 10 ) }'], ['words', 'with', 'frequency'], ['training data', 'with', 'frequency'], ['frequency', 'in', '{ 3 , U ( 1 , 10 ) }'], ['OOV words', 'replaced with', 'UNK token']]\",\n",
       " \"[['size', 'of', 'LSTMs hidden states'], ['LSTMs hidden states', 'set to', '{ 100 , qlog - U ( 30 , 150 ) }']]\",\n",
       " \"[['weight matrices', 'of', 'LSTMs'], ['LSTMs', 'with', 'random orthogonal matrices']]\",\n",
       " \"[['first feed - forward layer size', 'set to', 'value'], ['value', 'in', 'Optimization']]\",\n",
       " \"[['our model', 'in', 'minibatches'], ['minibatches', 'using', 'Adam ( Kingma and Ba , 2015 )'], ['Adam ( Kingma and Ba , 2015 )', 'with', 'learning rate'], ['Adam ( Kingma and Ba , 2015 )', 'with', 'maximal batch size'], ['learning rate', 'of', '10 ? 4']]\",\n",
       " \"[['gradients', 'by', 'global norm'], ['global norm', 'with', 'clipping value'], ['clipping value', 'in', '{ 1.0 , U ( 1 , 100 ) }']]\",\n",
       " \"[['model', 'performs', 'best'], ['best', 'on', 'devset']]\",\n",
       " '[]',\n",
       " \"[['input', 'with', 'k p ? U (0.8 , 1.0 )'], ['outputs', 'of', 'LSTMs'], ['input', 'with', 'k p ? U (0.8 , 1.0 )']]\",\n",
       " '[]',\n",
       " \"[['HPs', 'tuned on', 'ARRAU - AA'], ['HPs', 'obtain', 'results'], ['results', 'well beyond', 'KZH13'], ['all ablated model variants', 'perform', 'worse'], ['worse', 'than', 'full model']]\",\n",
       " \"[['Performance', 'of', '68.10 s@1 score'], ['68.10 s@1 score', 'indicates', 'model']]\",\n",
       " '[]',\n",
       " \"[['more successful', 'in resolving', 'nominal']]\",\n",
       " '[[\\'shell noun resolution\\', \\'in\\', \"KZH13 \\'s dataset\"], [\\'s@1 scores\\', \\'in\\', \\'range\\'], [\\'nominal anaphors\\', \\'in\\', \\'ARRAU - AA\\'], [\\'MR - LSTM\\', \\'achieved\\', \\'s@1 scores\\'], [\\'s@1 scores\\', \\'in\\', \\'range\\'], [\\'51.89 s@1 score\\', \\'for\\', \\'nominal anaphors\\'], [\\'nominal anaphors\\', \\'in\\', \\'ARRAU - AA\\']]',\n",
       " \"[['MR - LSTM without context embedding ( ctx )', 'achieves', 'comparable s@ 2 score'], ['comparable s@ 2 score', 'with', 'variant'], ['variant', 'that omits', 'syntactic information']]\",\n",
       " '[]',\n",
       " \"[['coreference prediction', 'benefit from', 'modeling'], ['global information', 'about', 'entity - clusters']]\",\n",
       " \"[['global context', 'necessary for', 'further improvements'], ['further improvements', 'in', 'coreference resolution']]\",\n",
       " \"[['representations', 'of', 'mention clusters'], ['representations', 'by embedding them', 'sequentially'], ['sequentially', 'using', 'recurrent neural network']]\",\n",
       " \"[['global representation', 'from', 'individual mentions'], ['individual mentions', 'present in', 'each cluster']]\",\n",
       " '[]',\n",
       " \"[['mention - ranking sub-system', 'trained', 'end - to - end'], ['end - to - end', 'on', 'coreference task']]\",\n",
       " \"[['model', 'as', 'local classifier'], ['local classifier', 'with', 'fixed context']]\",\n",
       " \"[['training', 'use', 'document - size minibatches'], ['document - size minibatches', 'allows for', 'efficient pre-computation'], ['efficient pre-computation', 'of', 'RNN states'], ['document - size minibatches', 'minimize', 'loss'], ['loss', 'with', 'AdaGrad'], ['AdaGrad', 'after clipping', 'LSTM gradients']]\",\n",
       " \"[['initial learning rate', 'chosen for', 'AdaGrad'], ['significant impact', 'on', 'results'], ['initial learning rate', 'choose', 'learning rates'], ['learning rates', 'for', 'each layer'], ['each layer', 'out of', '{ 0.1 , 0.02 , 0.01 , 0.002 , 0.001 }']]\",\n",
       " \"[['ha ( x n ) , h c ( x n ) , and h ( m )', 'to be', '? R 200']]\",\n",
       " \"[['single - layer LSTM', 'implemented in', 'element - rnn library']]\",\n",
       " \"[['regularization', 'apply', 'Dropout'], ['Dropout', 'with', 'rate'], ['Dropout', 'with', 'rate'], ['rate', 'of', '0.4'], ['rate', 'of', '0.3'], ['rate', 'before applying', 'linear weights u'], ['0.4', 'before applying', 'linear weights u'], ['Dropout', 'apply', 'Dropout'], ['Dropout', 'with', 'rate'], ['rate', 'of', '0.3'], ['0.3', 'to', 'LSTM states'], ['LSTM states', 'before forming', 'dot -product scores']]\",\n",
       " '[]',\n",
       " \"[['GPU', 'for', 'training']]\",\n",
       " '[]',\n",
       " \"[['statistically significant improvement', 'of', 'over 0.8 Co NLL points'], ['over 0.8 Co NLL points', 'over', 'previous state of the art']]\",\n",
       " \"[['performance', 'with', 'most dramatic improve - ments'], ['most dramatic improve - ments', 'on', 'non-anaphoric pronouns']]\",\n",
       " \"[['RNN performance', 'is', 'significantly better'], ['significantly better', 'than', 'Avg baseline'], ['significantly better', 'barely improves over', 'mention - ranking'], ['Avg baseline', 'barely improves over', 'mention - ranking']]\",\n",
       " '[]',\n",
       " \"[['word embedding model', 'learns', 'cross - sentence dependency'], ['cross - sentence dependency', 'for improving', 'end - to - end co-reference resolution ( E2E - CR )']]\",\n",
       " \"[['attentional sentence linking models', 'to learn', 'crosssentence dependency']]\",\n",
       " '[]',\n",
       " \"[['cross - sentence encoder', 'for', 'end - to - end co-reference ( E2E - CR )']]\",\n",
       " \"[['external memory block', 'containing', 'syntactic and semantic information'], ['syntactic and semantic information', 'from', 'context sentences'], ['syntactic and semantic information', 'added to', 'standard LSTM model']]\",\n",
       " \"[['proposed model', 'able to encode', 'input sentences'], ['input sentences', 'as', 'batch'], ['proposed model', 'calculate', 'representations'], ['representations', 'of', 'input words'], ['input words', 'by taking', 'target sentences and context sentences'], ['input words', 'by taking', 'into consideration']]\",\n",
       " \"[['LSTM modules', 'have', '200 output units']]\",\n",
       " \"[['ASL', 'calculate', 'cross - sentence dependency'], ['cross - sentence dependency', 'using', 'multilayer perceptron'], ['multilayer perceptron', 'with', 'one hidden layer'], ['one hidden layer', 'consisting of', '150 hidden units']]\",\n",
       " \"[['initial learning rate', 'set as', '0.001'], ['initial learning rate', 'decays', '0.001 %'], ['0.001 %', 'every', '100 steps']]\",\n",
       " \"[['model', 'optimized with', 'Adam algorithm']]\",\n",
       " \"[['up to 40 continuous sentences', 'for', 'training'], ['up to 40 continuous sentences', 'if', 'input'], ['training', 'if', 'input'], ['input', 'is', 'too long']]\",\n",
       " '[]',\n",
       " \"[['baseline model', 'achieved', '67.2 % F1 score'], ['ASL model', 'improved', 'performance'], ['performance', 'by', '0.6 %'], ['ASL model', 'achieved', '67.8 % average F1']]\",\n",
       " \"[['models', 'consider', 'cross - sentence dependency'], ['cross - sentence dependency', 'significantly outperform', 'baseline model'], ['baseline model', 'encodes', 'each sentence'], ['each sentence', 'from', 'input document']]\",\n",
       " \"[['better performance', 'than', 'LSL model']]\",\n",
       " '[]',\n",
       " \"[['entity - level representation', 'in', 'simple and intuitive manner'], ['entity - level representation', 'facilitates', 'end - to - end optimization']]\",\n",
       " '[]',\n",
       " \"[['contextual embeddings', 'as', 'input mention representations']]\",\n",
       " '[]',\n",
       " \"[['BERT', 'in', 'fully convolutional manner']]\",\n",
       " '[]',\n",
       " \"[['span - ranking model', 'from with', 'ELMo input features'], ['span - ranking model', 'from with', 'second - order span representations'], ['second - order span representations', 'achieves', '73.0 % Avg.']]\",\n",
       " \"[['ELMo features', 'with', 'BERT features'], ['ELMo features', 'achieves', '76. 25 % average F1'], ['BERT features', 'achieves', '76. 25 % average F1']]\",\n",
       " \"[['second - order span - representations', 'while using', 'BERT features'], ['BERT features', 'achieves', '76.37 % F1'], ['76.37 % F1', 'achieving', 'higher recall and lower precision'], ['higher recall and lower precision', 'on', 'all evaluation metrics']]\",\n",
       " \"[['secondorder span representations', 'with', 'Entity Equalization'], ['secondorder span representations', 'achieves', '76. 64 % average F1'], ['Entity Equalization', 'achieves', '76. 64 % average F1'], ['secondorder span representations', 'consistently achieving', 'highest F 1 score']]\",\n",
       " \"[['new state of the art', 'for', 'coreference resolution'], ['new state of the art', 'improving', 'previous state of the art'], ['previous state of the art', 'by', '3.6 % average F1']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['end - toend', 'given', 'gold mention clusters']]\",\n",
       " '[]',\n",
       " \"[['space', 'of', 'all spans'], ['marginal likelihood', 'of', 'antecedent spans'], ['all spans', 'up to', 'maximum length'], ['marginal likelihood', 'of', 'antecedent spans'], ['antecedent spans', 'from', 'gold coreference clusters']]\",\n",
       " \"[['each span', 'is', 'good antecedent']]\",\n",
       " \"[['vector embeddings', 'representing', 'spans'], ['vector embeddings', 'combine', 'context - dependent boundary representations'], ['context - dependent boundary representations', 'with', 'head - finding attention mechanism'], ['head - finding attention mechanism', 'over', 'span']]\",\n",
       " \"[['attention component', 'inspired by', 'parser - derived head - word matching features'], ['parser - derived head - word matching features', 'from', 'previous systems'], ['attention component', 'less susceptible to', 'cascading errors']]\",\n",
       " '[]',\n",
       " \"[['word embeddings', 'area', 'fixed concatenation'], ['fixed concatenation', 'of', '300 - dimensional GloVe embeddings'], ['fixed concatenation', 'of', '50 - dimensional embeddings'], ['normalized', 'to be', 'unit vectors']]\",\n",
       " \"[['Outof - vocabulary words', 'represented by', 'vector'], ['vector', 'of', 'zeros']]\",\n",
       " \"[['characters', 'represented as', 'learned 8 - dimensional embeddings']]\",\n",
       " \"[['convolutions', 'have', 'window sizes'], ['window sizes', 'of', '3 , 4 , and 5 characters'], ['3 , 4 , and 5 characters', 'consisting of', '50 filters']]\",\n",
       " \"[['hidden states', 'in', 'LSTMs'], ['hidden states', 'have', '200 dimensions'], ['LSTMs', 'have', '200 dimensions']]\",\n",
       " \"[['feedforward neural network', 'consists of', 'two hidden layers'], ['feedforward neural network', 'consists of', 'rectified linear units'], ['two hidden layers', 'with', '150 dimensions']]\",\n",
       " \"[['ADAM', 'for', 'learning'], ['learning', 'with', 'minibatch size'], ['minibatch size', 'of', '1']]\",\n",
       " \"[['LSTM weights', 'initialized with', 'random orthonormal matrices']]\",\n",
       " \"[['0.5 dropout', 'to', 'word embeddings and character CNN outputs']]\",\n",
       " \"[['0.2 dropout', 'to', 'all hidden layers and feature embeddings']]\",\n",
       " \"[['Dropout masks', 'shared across', 'timesteps'], ['Dropout masks', 'to preserve', 'long - distance information']]\",\n",
       " \"[['learning rate', 'decayed by', '0.1 %'], ['0.1 %', 'every', '100 steps']]\",\n",
       " \"[['up to 150 epochs', 'with', 'early stopping'], ['early stopping', 'based on', 'development set']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['previous systems', 'in', 'all metrics']]\",\n",
       " \"[['our single model', 'improves', 'state - of - the - art average F1'], ['our single model', 'improves', 'our 5 - model ensemble'], ['state - of - the - art average F1', 'by', '1.5'], ['improves', 'by', '3.1']]\",\n",
       " \"[['most significant gains', 'come from', 'improvements'], ['improvements', 'in', 'recall']]\",\n",
       " \"[['spans and the width of spans', 'are', 'crucial signals'], ['crucial signals', 'for', 'coreference resolution']]\",\n",
       " \"[['3.8 F1', 'to', 'final result']]\",\n",
       " \"[['contribution', 'of', '0.9 F1'], ['0.9 F1', 'from', 'character - level modeling']]\",\n",
       " \"[['1.3 F1 degradation', 'in', 'performance'], ['1.3 F1 degradation', 'without', 'attention mechanism'], ['attention mechanism', 'for finding', 'task - specific heads']]\",\n",
       " \"[['mention candidates', 'detected by', 'rule - based system'], ['mention candidates', 'over', 'predicted parse trees'], ['rule - based system', 'over', 'predicted parse trees'], ['mention candidates', 'degrades', 'performance'], ['rule - based system', 'degrades', 'performance'], ['predicted parse trees', 'degrades', 'performance'], ['performance', 'by', '1 F1']]\",\n",
       " \"[['oracle mentions', 'see', 'improvement'], ['improvement', 'of', '17.5 F1']]\",\n",
       " '[]',\n",
       " \"[['BERT', 'to', 'coreference resolution']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['original Tensorflow implementations', 'of', 'c 2f - coref'], ['original Tensorflow implementations', 'of', 'BERT']]\",\n",
       " \"[['all models', 'on', 'OntoNotes English data'], ['OntoNotes English data', 'for', '20 epochs'], ['20 epochs', 'using', 'dropout'], ['20 epochs', 'using', 'learning rates'], ['dropout', 'of', '0.3'], ['learning rates', 'of', '1 10 ?5 and 2 10 ? 4'], ['1 10 ?5 and 2 10 ? 4', 'with', 'linear decay'], ['linear decay', 'for', 'BERT parameters']]\",\n",
       " \"[['separate models', 'with', 'max segment len'], ['max segment len', 'of', '128 , 256 , 384 , and 512'], ['models', 'trained on', '128 and 384 word pieces'], ['128 and 384 word pieces', 'performed', 'best'], ['best', 'for', 'BERT - base and BERT - large']]\",\n",
       " '[]',\n",
       " \"[['BERT', 'improves', 'c 2 f - coref'], ['c 2 f - coref', 'by', '9 % and 11.5 %'], ['9 % and 11.5 %', 'for', 'base and large models']]\",\n",
       " '[]',\n",
       " \"[['BERT - base', 'offers', 'improvement'], ['improvement', 'of', '0.9 %'], ['0.9 %', 'over', 'ELMo - based c2 fcoref model']]\",\n",
       " \"[['BERT - large', 'improves', 'c 2 f - coref'], ['c 2 f - coref', 'by', 'much larger margin'], ['much larger margin', 'of', '3.9 %']]\",\n",
       " \"[['overlap variant', 'offers', 'no improvement'], ['no improvement', 'over', 'independent']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['new structured - data encoder', 'assuming', 'structures'], ['new structured - data encoder', 'assuming that', 'structures'], ['structures', 'should be', 'hierarchically captured']]\",\n",
       " \"[['encoding', 'of', 'data - structure'], ['decoder', 'chosen to be', 'classical module']]\",\n",
       " \"[['general structure', 'of', 'data'], ['data', 'using', 'two - level architecture'], ['two - level architecture', 'first encoding', 'all entities'], ['all entities', 'on the basis of', 'elements'], ['data structure', 'on the basis of', 'entities'], ['Transformer encoder', 'in', 'data - to - text models'], ['data - to - text models', 'to ensure', 'robust encoding'], ['robust encoding', 'of', 'each element / entities'], ['each element / entities', 'in comparison to', 'all others'], ['two - level architecture', 'integrate', 'hierarchical attention mechanism'], ['hierarchical attention mechanism', 'to compute', 'hierarchical context'], ['hierarchical context', 'fed into', 'decoder']]\",\n",
       " '[]',\n",
       " \"[['Wiseman', 'is', 'standard encoder - decoder system'], ['standard encoder - decoder system', 'with', 'copy mechanism']]\",\n",
       " \"[['Li', 'is', 'standard encoder - decoder'], ['standard encoder - decoder', 'with', 'delayed copy mechanism'], ['placeholders', 'replaced by', 'salient records'], ['salient records', 'extracted from', 'table'], ['table', 'by', 'pointer network']]\",\n",
       " \"[['Puduppully - plan', 'acts in', 'two steps'], ['first standard encoder - decoder', 'generates', 'plan'], ['second standard encoder - decoder', 'generates', 'text'], ['text', 'from', 'plan']]\",\n",
       " '[]',\n",
       " \"[['standard encoder - decoder', 'with', 'added module'], ['added module', 'aimed at updating', 'record representations'], ['record representations', 'during', 'generation process']]\",\n",
       " \"[['records', 'should be', 'updated']]\",\n",
       " \"[['size', 'of', 'record value embeddings and hidden layers'], ['record value embeddings and hidden layers', 'of', 'Transformer encoders'], ['size', 'of', 'record value embeddings and hidden layers'], ['record value embeddings and hidden layers', 'of', 'Transformer encoders'], ['Transformer encoders', 'set to', '300']]\",\n",
       " \"[['dropout', 'at', 'rate 0.5']]\",\n",
       " \"[['batch size', 'of', '64']]\",\n",
       " \"[['model', 'for', 'fixed number of 25 K updates'], ['weights', 'of', 'last 5 checkpoints'], ['last 5 checkpoints', 'to ensure', 'more stability'], ['more stability', 'across', 'runs']]\",\n",
       " \"[['initial learning rate', 'is', '0.001'], ['initial learning rate', 'reduced by', 'half'], ['half', 'every', '10 K steps']]\",\n",
       " \"[['beam search', 'with', 'beam size'], ['beam size', 'of', '5'], ['beam size', 'during', 'inference'], ['5', 'during', 'inference']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['lower results', 'obtained by', 'Flat scenario'], ['Flat scenario', 'compared to', 'other scenarios']]\",\n",
       " \"[['scenario Hierarchical - kv and Hierarchical -k', 'omitting', 'influence'], ['influence', 'of', 'record values'], ['record values', 'in', 'attention mechanism'], ['slightly better', 'in', 'all metrics'], ['attention mechanism', 'is', 'more effective'], ['slightly better', 'in', 'all metrics'], ['slightly better', 'excepted', 'CS - R%'], ['all metrics', 'excepted', 'CS - R%']]\",\n",
       " \"[['Our hierarchical models', 'achieve', 'significantly better scores'], ['significantly better scores', 'on', 'all metrics'], ['significantly better scores', 'compared to', 'flat architecture Wiseman']]\",\n",
       " \"[['Flat scenario', 'obtains', 'significant higher BLEU score ('], ['Flat scenario', 'generates', 'fluent descriptions'], ['fluent descriptions', 'with', 'accurate mentions ( RG - P % )'], ['accurate mentions ( RG - P % )', 'included in', 'gold descriptions ( CS - R% )']]\",\n",
       " \"[['Our hierarchical models', 'outperform', 'two - step decoders'], ['two - step decoders', 'of', 'Li and Puduppully - plan'], ['Li and Puduppully - plan', 'on', 'BLEU and all qualitative metrics']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['neural ensemble natural language generator', 'train and test on', 'three large unaligned datasets'], ['three large unaligned datasets', 'in', 'restaurant , television , and laptop domains']]\",\n",
       " \"[['novel ways', 'to represent', 'MR inputs'], ['MR inputs', 'including', 'novel methods']]\",\n",
       " \"[['ensemble model', 'using', 'seq2seq framework'], ['seq2seq framework', 'for', 'TensorFlow']]\",\n",
       " \"[['individual LSTM models', 'use', 'bidirectional LSTM encoder'], ['bidirectional LSTM encoder', 'with', '512 cells per layer'], ['CNN models', 'use', 'pooling encoder']]\",\n",
       " \"[['decoder', 'in', 'all models'], ['decoder', 'was', '4 - layer RNN decoder'], ['all models', 'was', '4 - layer RNN decoder'], ['4 - layer RNN decoder', 'with', '512 LSTM cells per layer'], ['4 - layer RNN decoder', 'with', 'attention'], ['4 - layer RNN decoder', 'with', 'attention']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['LSTM and the CNN models', 'benefit from', 'additional pseudo - samples'], ['additional pseudo - samples', 'in', 'training set']]\",\n",
       " \"[['our ensemble model', 'performs', 'comparably'], ['comparably', 'to', 'baseline model'], ['comparably', 'in terms of', 'automatic metrics'], ['baseline model', 'in terms of', 'automatic metrics'], ['TGen', 'in terms of', 'automatic metrics']]\",\n",
       " '[]',\n",
       " \"[['our ensemble model', 'performs', 'competitively'], ['competitively', 'with', 'baseline'], ['baseline', 'on', 'TV dataset'], ['outperforms', 'on', 'Laptop dataset'], ['outperforms', 'on', 'Laptop dataset'], ['outperforms', 'by', 'wide margin'], ['Laptop dataset', 'by', 'wide margin']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['text generation', 'as', 'sequenceto - sequence problem']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['model', 'with', 'GCN encoder'], ['LSTM encoder', 'with', '.009 BLEU points'], ['GCN encoder', 'outperforms', 'strong baseline'], ['strong baseline', 'employs', 'LSTM encoder'], ['LSTM encoder', 'with', '.009 BLEU points']]\",\n",
       " \"[['GCN model', 'is', 'more stable'], ['more stable', 'than', 'baseline'], ['baseline', 'with', 'standard deviation']]\",\n",
       " \"[['GCN EC model', 'outperforms', 'PKUWRITER'], ['GCN EC model', 'outperforms', 'further reinforcement learning step'], ['GCN EC model', 'outperforms', 'MELBOURNE'], ['PKUWRITER', 'uses', 'ensemble of 7 models'], ['PKUWRITER', 'uses', 'further reinforcement learning step'], ['further reinforcement learning step', 'by', '.047 BLEU points'], ['MELBOURNE', 'by', '.014 BLEU points']]\",\n",
       " '[]',\n",
       " \"[['neural models', 'with', 'upper bound results'], ['upper bound results', 'on', 'same dataset'], ['upper bound results', 'by', 'pipeline model'], ['same dataset', 'by', 'pipeline model'], ['STUMBA - D and TBDIL model', 'outperforming', 'GCN - based model']]\",\n",
       " \"[['importance', 'of', 'skip connections'], ['skip connections', 'between', 'GCN layers']]\",\n",
       " \"[['Residual and dense connections', 'lead to', 'similar results']]\",\n",
       " \"[['Dense connections', 'produce', 'models']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['canonical presentation', 'of', 'RSA framework'], ['RSA framework', 'grounded in', 'reference resolution']]\",\n",
       " '[]',\n",
       " \"[['pragmatic methods', 'obtain', 'improvements'], ['pragmatic methods', 'obtain', '0.2-1.8 METEOR'], ['improvements', 'of', '0.2-0.5'], ['improvements', 'of', '0.2-1.8 METEOR'], ['0.2-0.5', 'in', 'ROUGE scores'], ['0.2-1.8 METEOR', 'over', 'base S 0 model'], ['base S 0 model', 'with', 'distractor - based approach SD 1'], ['distractor - based approach SD 1', 'outperforming', 'reconstructorbased approach S R 1']]\",\n",
       " \"[['SD 1', 'is', 'strong'], ['strong', 'across', 'all metrics'], ['SD 1', 'obtaining', 'results'], ['strong', 'obtaining', 'results'], ['all metrics', 'obtaining', 'results'], ['results', 'competitive to', 'best previous abstractive systems'], ['attribute type', 'for', 'base model S0'], ['Coverage ratios', 'for', 'pragmatic system SD 1'], ['pragmatic system SD 1', 'when constructing', 'distractor'], ['distractor', 'by masking', 'specified attribute']]\",\n",
       " '[]',\n",
       " \"[['content plan', 'from', 'input and conditions'], ['input and conditions', 'on', 'content plan'], ['content plan', 'to generate', 'output document']]\",\n",
       " \"[['end - to - end', 'using', 'neural networks']]\",\n",
       " \"[['one - layer pointer networks', 'during', 'content planning'], ['two - layer LSTMs', 'during', 'text generation'], ['two - layer LSTMs', 'during', 'text generation']]\",\n",
       " \"[['Input feeding', 'employed for', 'text decoder']]\",\n",
       " \"[['dropout', 'at', 'rate'], ['rate', 'of', '0.3']]\",\n",
       " \"[['Models', 'trained for', '25 epochs'], ['25 epochs', 'with', 'Adagrad optimizer'], ['initial learning rate', 'was', '0.15'], ['learning rate decay', 'selected from', '{ 0.5 , 0.97 }']]\",\n",
       " \"[['text decoding', 'made use of', 'BPTT'], ['truncation size', 'to', '100']]\",\n",
       " \"[['beam size', 'to', '5'], ['beam size', 'during', 'inference'], ['5', 'during', 'inference']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['NCP', 'improves upon', 'vanilla encoderdecoder models ( ED + JC , ED + CC )']]\",\n",
       " \"[['NCP', 'achieves', 'comparable scores'], ['comparable scores', 'with', 'joint or conditional copy mechanism']]\",\n",
       " \"[['NCP + CC', 'achieves', 'best content selection and content ordering scores'], ['best content selection and content ordering scores', 'in terms of', 'BLEU']]\",\n",
       " \"[['best reported system', 'achieve', 'absolute improvement'], ['absolute improvement', 'of', 'approximately 12 %'], ['absolute improvement', 'of', '12 %'], ['approximately 12 %', 'in terms of', 'relation generation'], ['12 %', 'in terms of', 'relation generation'], ['content selection precision', 'improves by', '5 %'], ['improves', 'by', '5 %'], ['recall', 'by', '15 %'], ['BLEU', 'by', '1.5 points']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['fluent language', 'describing', 'information']]\",\n",
       " \"[['output', 'fed into', 'neural generation system']]\",\n",
       " \"[['text planner', 'determines', 'information structure'], ['text planner', 'expresses it', 'unambiguously']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['best', 'on', 'all categories'], ['all categories', 'in', 'automatic evaluation'], ['all categories', 'in', 'UPF - FORGe'], ['all categories', 'in', 'classic grammar - based NLG system'], ['classic grammar - based NLG system', 'scored', 'best'], ['best', 'in', 'human evaluation']]\",\n",
       " \"[['end - to - end neural baseline', 'outperforms', 'WebNLG neural systems']]\",\n",
       " \"[['LSTM decoder', 'with', 'attention'], ['LSTM decoder', 'with', 'neural checklist model'], ['LSTM decoder', 'applying', 'entity dropout']]\",\n",
       " '[]',\n",
       " \"[['StrongNeural and BestPlan systems', 'outperform', 'all the WebNLG participating systems'], ['all the WebNLG participating systems', 'on', 'all automatic metrics']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['more general approach', 'to', 'text generation']]\",\n",
       " \"[['character - level sequence - to - sequence model', 'with', 'attention mechanism'], ['attention mechanism', 'results in', 'completely neural end - to - end architecture']]\",\n",
       " '[]',\n",
       " \"[['vocabulary - free model', 'inherently', 'more general']]\",\n",
       " \"[['character - wise copy mechanism', 'consisting in', 'soft switch'], ['soft switch', 'between', 'generation and copy mode'], ['model', 'to learn', 'rare and unhelpful self - correspondences'], ['state - of - art architecture', 'enhancing', 'recall'], ['internal representation capabilities', 'enhancing', 'recall'], ['state - of - art architecture', 'consists in', 'exchange']]\",\n",
       " \"[['our system', 'using', 'PyTorch framework']]\",\n",
       " \"[['negative log - likelihood loss', 'using', 'teacher forcing and Adam']]\",\n",
       " '[]',\n",
       " \"[['higher metric values', 'with respect to', 'TGen'], ['TGen', 'on', 'Hotel and Restaurant datasets'], ['TGen', 'on', 'E2E dataset'], ['three out of five higher metrics values', 'on', 'E2E dataset'], ['three out of five higher metrics values', 'on', 'E2E dataset']]\",\n",
       " \"[['TGen', 'achieves', 'three out of five higher metrics values']]\",\n",
       " \"[['approach', 'allows to obtain', 'better performance'], ['better performance', 'with respect to', 'training EDA_CS'], ['training EDA_CS', 'in', 'standard way'], ['standard way', 'on', 'Hotel and Restaurant datasets']]\",\n",
       " '[[\\'EDA_CS TL\\', \\'shows\\', \\'bleu increment\\'], [\\'bleu increment\\', \\'of\\', \\'at least 14 %\\'], [\\'at least 14 %\\', \\'with respect to\\', \"TGen \\'s score\"], [\"TGen \\'s score\", \\'compared to\\', \\'Hotel and Restaurant datasets\\']]',\n",
       " \"[['baseline model', 'largely outperformed by', 'all other examined methods'], ['EDA', 'largely outperformed by', 'all other examined methods']]\",\n",
       " '[]',\n",
       " \"[['novel neural network model', 'for', 'joint part - of - speech ( POS ) tagging and dependency parsing']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['novel neural network - based model', 'for', 'jointly learning']]\",\n",
       " \"[['joint model', 'extends', 'well - known BIST graph - based dependency parser'], ['well - known BIST graph - based dependency parser', 'with', 'additional lower - level BiLSTM - based tagging component']]\",\n",
       " \"[['jPTDP v 2.0', 'implemented using', 'DYNET v2.0'], ['DYNET v2.0', 'with', 'fixed random seed']]\",\n",
       " '[]',\n",
       " \"[['dropout', 'with', '67 % keep probability'], ['67 % keep probability', 'to', 'inputs'], ['inputs', 'of', 'BiLSTMs and MLPs']]\",\n",
       " '[[\\'word dropout\\', \\'to learn\\', \\'embedding\\'], [\\'embedding\\', \\'for\\', \\'unknown words\\'], [\\'embedding\\', \\'replace\\', \\'each word token w\\'], [\\'each word token w\\', \\'with\\', \\'special \" unk \" symbol\\'], [\\'training set\\', \\'with\\', \\'special \" unk \" symbol\\'], [\\'special \" unk \" symbol\\', \\'with\\', \\'probability punk ( w )\\']]',\n",
       " \"[['objective loss', 'using', 'Adam ( Kingma and Ba , 2014 )'], ['Adam ( Kingma and Ba , 2014 )', 'with', 'initial learning rate'], ['initial learning rate', 'at', '0.001'], ['initial learning rate', 'no', 'mini-batches']]\",\n",
       " '[]',\n",
       " \"[['number of hidden nodes', 'in', 'MLPs'], ['number of hidden nodes', 'at', '100'], ['MLPs', 'at', '100']]\",\n",
       " \"[['our model', 'produces', 'very competitive parsing results']]\",\n",
       " \"[['UAS score', 'at', '94.51 %'], ['LAS score', 'at', '92.87 %'], ['LAS score', 'at', '92.87 %'], ['UAS and LAS scores', 'of', 'BIST graph - based model']]\",\n",
       " \"[['0.9 % lower parsing scores', 'than', 'state - of - the - art dependency parser']]\",\n",
       " \"[['state - of - the - art POS tagging accuracy', 'at', '97.97 %']]\",\n",
       " '[]',\n",
       " \"[['BiLSTMs', 'are', 'strong and trainable sequence models']]\",\n",
       " \"[['each word', 'by', 'BiLSTM encoding'], ['feature function', 'passed to', 'non-linear scoring function ( multi - layer perceptron )']]\",\n",
       " \"[['BiLSTM', 'trained with', 'rest of the parser'], ['rest of the parser', 'to learn', 'good feature representation'], ['good feature representation', 'for', 'parsing problem']]\",\n",
       " \"[['BiLSTM feature extractor', 'in', 'two parsing architectures']]\",\n",
       " \"[['graphbased parser', 'jointly train', 'structured - prediction model'], ['structured - prediction model', 'on top of', 'BiLSTM'], ['structured - prediction model', 'propagating', 'errors'], ['BiLSTM', 'propagating', 'errors'], ['errors', 'from', 'structured objective']]\",\n",
       " \"[['parsers', 'implemented in', 'python'], ['parsers', 'using', 'PyCNN toolkit'], ['python', 'using', 'PyCNN toolkit'], ['PyCNN toolkit', 'for', 'neural network training']]\",\n",
       " '[]',\n",
       " \"[['LSTM variant', 'implemented in', 'PyCNN'], ['LSTM variant', 'optimize using', 'Adam optimizer'], ['LSTM variant', 'using', 'Adam optimizer'], ['optimize', 'using', 'Adam optimizer']]\",\n",
       " \"[['our parsers', 'are', 'very competitive']]\",\n",
       " \"[['first - order graph - based parser', 'with', '2 features'], ['outperforms', 'thatare not using', 'external resources'], ['all other systems', 'thatare not using', 'external resources'], ['external resources', 'including', 'third - order TurboParser']]\",\n",
       " \"[['greedy transition based parser', 'with', '4 features'], ['beam - based transition parser', 'with', 'heavily engineered features'], ['4 features', 'matches or outperforms', 'most other parsers'], ['most other parsers', 'including', 'beam - based transition parser'], ['beam - based transition parser', 'with', 'heavily engineered features'], ['beam - based transition parser', 'with', 'Stack - LSTM parser'], ['same parser', 'trained using', 'dynamic oracle']]\",\n",
       " \"[['simple ( 4 features )', 'to', 'extended ( 11 features ) feature set'], ['simple ( 4 features )', 'leads to', 'some gains'], ['extended ( 11 features ) feature set', 'leads to', 'some gains'], ['some gains', 'in', 'accuracy'], ['accuracy', 'for', 'English and Chinese']]\",\n",
       " \"[['accuracy', 'of', 'graph - based parser']]\",\n",
       " \"[['probabilistic interpretation', 'to', 'ensemble parser'], ['probabilistic interpretation', 'viewing it as', 'instance'], ['ensemble parser', 'viewing it as', 'instance'], ['instance', 'of', 'minimum Bayes risk inference']]\",\n",
       " \"[['ensemble', 'into', 'single FOG parser'], ['single FOG parser', 'with', 'discriminative training'], ['discriminative training', 'by defining', 'new cost function']]\",\n",
       " '[[\\'cost\\', \\'of\\', \\'each possible attachment\\'], [\\'each possible attachment\\', \\'from\\', \"ensemble \\'s division of votes\"], [\\'cost\\', \\'in\\', \\'discriminative learning\\']]',\n",
       " '[]',\n",
       " \"[['neural FOG parser', 'trained with', 'Hamming cost']]\",\n",
       " '[]',\n",
       " \"[['same model', 'with', 'distillation cost'], ['distillation cost', 'gives', 'consistent improvements'], ['consistent improvements', 'for', 'all languages']]\",\n",
       " '[]',\n",
       " \"[['best published scores', 'For', 'German'], ['Chinese', 'achieves', 'best published scores'], ['best published scores', 'for', 'German']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['parser choice', 'on', 'biomedical event extraction']]\",\n",
       " \"[['Stanford - Biaffine', 'utilizes', 'pre-trained word embeddings'], ['pre-trained word embeddings', 'employ', '200 dimensional pre-trained word vectors']]\",\n",
       " \"[['traditional feature - based models', 'use', 'original pure Java implementations'], ['NLP4J - dep', 'use', 'original pure Java implementations'], ['original pure Java implementations', 'with', 'default hyperparameter settings']]\",\n",
       " \"[['BiLSTM - CRF - based models', 'use', 'default hyper - parameters'], ['default hyper - parameters', 'use', 'Nadam'], ['default hyper - parameters', 'run for', '50 epochs']]\",\n",
       " \"[['Stanford - NNdep', 'select', 'word CutOff'], ['word CutOff', 'from', '{ 1 , 2 }'], ['hidden layer', 'from', '{ 100 , 150 , 200 , 250 , 300 , 350 , 400 }'], ['hidden layer', 'from', '{ 100 , 150 , 200 , 250 , 300 , 350 , 400 }'], ['word CutOff', 'fix', 'other hyperparameters'], ['other hyperparameters', 'with', 'default values']]\",\n",
       " \"[['jPTDP', 'use', '50 - dimensional character embeddings'], ['50 - dimensional character embeddings', 'fix', 'initial learning rate'], ['initial learning rate', 'at', '0.0005']]\",\n",
       " \"[['number of BiLSTM layers', 'at', '2'], ['number of LSTM units', 'in', 'each layer'], ['each layer', 'from', '{ 100 , 150 , 200 , 250 , 300 }']]\",\n",
       " '[]',\n",
       " \"[['BiLSTM - CRF and Mar - MoT', 'obtain', 'lowest scores'], ['lowest scores', 'on', 'GENIA and CRAFT']]\",\n",
       " \"[['jPTDP', 'obtains', 'similar score'], ['similar score', 'to', 'Mar - MoT'], ['similar score', 'to', 'BiLSTM - CRF'], ['Mar - MoT', 'on', 'GENIA'], ['BiLSTM - CRF', 'on', 'CRAFT'], ['similar score', 'to', 'BiLSTM - CRF'], ['BiLSTM - CRF', 'on', 'CRAFT']]\",\n",
       " \"[['MarMoT', 'obtains', 'accuracy results'], ['accuracy results', 'at', '98.61 % and 97.07 %'], ['98.61 % and 97.07 %', 'on', 'GENIA and CRAFT']]\",\n",
       " \"[['BiLSTM - CRF', 'obtains', 'accuracies'], ['accuracies', 'of', '98.44 %'], ['98.44 %', 'on', 'GE - NIA'], ['98.44 %', 'on', 'CRAFT'], ['97.25 %', 'on', 'CRAFT'], ['97.25 %', 'on', 'CRAFT']]\",\n",
       " \"[['CNN - based character - level word embeddings', 'provided', '0.1 % improvement'], ['0.1 % improvement', 'to', 'BiLSTM - CRF']]\",\n",
       " \"[['BiLSTM - CRF', 'with', 'character - level word embeddings'], ['character - level word embeddings', 'obtains', 'highest accuracy scores']]\",\n",
       " '[]',\n",
       " \"[['GENIA', 'among', 'pre-trained models'], ['BLLIP', 'obtains', 'highest results']]\",\n",
       " \"[['pre-trained Stanford - Biaffine ( v1 ) model', 'produces', 'lower scores'], ['lower scores', 'than', 'pre-trained Stanford - NNdep model'], ['pre-trained Stanford - NNdep model', 'on', 'GENIA']]\",\n",
       " \"[['pre-trained NNdep and Biaffine models', 'result in', 'no significant performance differences'], ['no significant performance differences', 'irrespective of', 'source of POS tags'], ['pre-trained Stanford tagger', 'at', '98.37 %'], ['retrained NLP4J - POS model', 'at', '98.80 %']]\",\n",
       " '[]',\n",
       " \"[['novel neural network architecture', 'for', 'dependency parsing']]\",\n",
       " \"[['STACKPTR', 'is', 'transition - based architecture'], ['STACKPTR', 'maintains', 'global view'], ['global view', 'of', 'sentence']]\",\n",
       " \"[['STACKPTR parser', 'has', 'pointer network'], ['pointer network', 'as', 'backbone'], ['STACKPTR parser', 'equipped with', 'internal stack'], ['internal stack', 'to maintain', 'order'], ['order', 'of', 'head words'], ['head words', 'in', 'tree structures']]\",\n",
       " \"[['STACKPTR parser', 'performs', 'parsing'], ['parsing', 'in', 'incremental , topdown , depth - first fashion'], ['incremental , topdown , depth - first fashion', 'at', 'each step'], ['arc', 'by assigning', 'child'], ['child', 'for', 'headword'], ['headword', 'top of', 'internal stack']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['BIAF', 'On', 'Chinese'], ['Full variation of STACKPTR', 'with', 'decoding beam size 10'], ['decoding beam size 10', 'outperforms', 'BIAF'], ['BIAF', 'on', 'Chinese'], ['competitive performance', 'on', 'English and German'], ['Full variation of STACKPTR', 'obtains', 'competitive performance'], ['competitive performance', 'on', 'English and German']]\",\n",
       " \"[['Full model', 'achieves', 'best accuracy'], ['best accuracy', 'on', 'English and Chinese'], ['+ sib', 'on', 'German'], ['slightly worse', 'than', '+ sib'], ['+ sib', 'on', 'German']]\",\n",
       " \"[['BIAF', 'On', 'all languages'], ['STACKPTR', 'significantly outperforms', 'BIAF'], ['BIAF', 'on', 'all languages'], ['all languages', 'showing', 'superiority']]\",\n",
       " \"[['results', 'of', 'our parser'], ['our parser', 'on', 'RA'], ['results', 'slightly worse than', 'BIAF'], ['our parser', 'slightly worse than', 'BIAF']]\",\n",
       " \"[['BIAF', 'obtains', 'better performance'], ['better performance', 'than', 'original one']]\",\n",
       " \"[['Our model', 'achieves', 'state - of - the - art performance'], ['state - of - the - art performance', 'on', 'UAS and LAS'], ['state - of - the - art performance', 'on', 'Chinese'], ['state - of - the - art performance', 'on', 'best UAS'], ['state - of - the - art performance', 'on', 'English'], ['UAS and LAS', 'on', 'Chinese'], ['best UAS', 'on', 'English'], ['UAS and LAS', 'on', 'Chinese'], ['best UAS', 'on', 'English'], ['best UAS', 'on', 'English']]\",\n",
       " \"[['performance', 'competitive with', 'BIAF'], ['significantly better', 'than', 'other models']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['sentences', 'processed in', 'linear left to right pass']]\",\n",
       " \"[['representational power', 'of', 'neural networks'], ['neural networks', 'with', 'superior search'], ['superior search', 'enabled by', 'structured training and inference']]\",\n",
       " \"[['neural network', 'to model', 'probability'], ['probability', 'of', 'individual parse actions']]\",\n",
       " \"[['activations', 'from', 'all layers'], ['all layers', 'of', 'neural network'], ['activations', 'as', 'representation'], ['neural network', 'as', 'representation'], ['representation', 'in', 'structured perceptron model'], ['structured perceptron model', 'trained with', 'beam search and early updates']]\",\n",
       " \"[['high - confidence parse trees', 'by parsing', 'unlabeled data'], ['unlabeled data', 'with', 'two different parsers'], ['high - confidence parse trees', 'selecting', 'sentences'], ['two parsers', 'produced', 'same trees']]\",\n",
       " \"[['our neural network parser', 'than', 'other approaches'], ['significantly more', 'than', 'other approaches']]\",\n",
       " \"[['publicly available word2vec 2 tool', 'to learn', 'CBOW embeddings']]\",\n",
       " '[]',\n",
       " \"[['reported accuracy', 'of', '94.22 % UAS']]\",\n",
       " \"[['competitive', 'with', 'some of the highest reported accuries'], ['some of the highest reported accuries', 'dependencies on', 'WSJ']]\",\n",
       " '[]',\n",
       " \"[['neural graphbased approach', 'to achieve', 'competitive performance'], ['competitive performance', 'build', 'network'], ['network', 'uses', 'more regularization'], ['affine label classifier', 'with', 'biaffine ones']]\",\n",
       " \"[['optimize', 'optimize with', 'Adam'], ['Adam', 'keeps', 'moving average'], ['moving average', 'of', 'L 2 norm'], ['L 2 norm', 'of', 'gradient'], ['L 2 norm', 'of', 'gradient'], ['gradient', 'for', 'each parameter'], ['each parameter', 'throughout', 'training'], ['gradient', 'for', 'each parameter'], ['gradient', 'by', 'moving average'], ['each parameter', 'by', 'moving average']]\",\n",
       " \"[['Our model', 'gets', 'nearly the same UAS performance'], ['Our model', 'gets', 'SOTA UAS performance'], ['Our model', 'gets', 'SOTA performance'], ['nearly the same UAS performance', 'on', 'PTB - SD 3.3.0'], ['PTB - SD 3.3.0', 'as', 'current SOTA model'], ['Our model', 'gets', 'SOTA UAS performance'], ['SOTA UAS performance', 'on', 'CTB 5.1 7'], ['SOTA performance', 'on', 'all CoNLL 09 languages']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['classification component', 'takes into account', 'features'], ['features', 'of', 'current parser state'], ['classification component', 'predicts', 'next action'], ['next action', 'conditioned on', 'state']]\",\n",
       " \"[['training criterion', 'to explore', 'parser states']]\",\n",
       " '[]',\n",
       " \"[['interpolating', 'between', 'algorithm states'], ['algorithm states', 'sampled from', 'model'], ['algorithm states', 'sampled from', 'training data'], ['more robust predictions', 'at', 'test time']]\",\n",
       " '[]',\n",
       " \"[['score', 'achieved by', 'dynamic oracle'], ['dynamic oracle', 'for', 'English'], ['dynamic oracle', 'is', '93.56 UAS'], ['English', 'is', '93.56 UAS']]\",\n",
       " \"[['Chinese score', 'establishes', 'state - of - the - art']]\",\n",
       " '[]',\n",
       " \"[['globally normalized transition - based neural network model', 'achieves', 'state - of - the - art part - ofspeech tagging']]\",\n",
       " \"[['simple feed - forward networks', 'without', 'any recurrence'], ['simple feed - forward networks', 'can achieve', 'comparable or better accuracies'], ['comparable or better accuracies', 'than', 'LSTMs']]\",\n",
       " '[]',\n",
       " \"[['beam search', 'for maintaining', 'multiple hypotheses'], ['global normalization', 'with', 'conditional random field ( CRF ) objective'], ['conditional random field ( CRF ) objective', 'to overcome', 'label bias problem']]\",\n",
       " \"[['beam inference', 'approximate', 'partition function'], ['partition function', 'summing over', 'elements'], ['elements', 'in', 'beam'], ['beam inference', 'use', 'early updates'], ['partition function', 'use', 'early updates']]\",\n",
       " \"[['gradients', 'based on', 'approximate global normalization'], ['gradients', 'perform', 'full backpropagation training'], ['full backpropagation training', 'of', 'all neural network parameters'], ['all neural network parameters', 'based on', 'CRF loss']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['globally normalized model', 'significantly outperforms', 'local model']]\",\n",
       " \"[['Beam search', 'with', 'locally normalized model'], ['locally normalized model', 'suffers from', 'severe label bias issues']]\",\n",
       " \"[['beam search', 'with', 'locally normalized model'], ['beam search', 'with', 'global normalization'], ['locally normalized model', 'does', 'help'], ['beam search', 'with', 'global normalization'], ['global normalization', 'leads to', '7 % reduction'], ['7 % reduction', 'in', 'relative error']]\",\n",
       " '[[\\'character ngrams feature\\', \\'is\\', \\'very important\\'], [\\'character ngrams feature\\', \\'increasing\\', \\'average accuracy\\'], [\\'average accuracy\\', \\'on\\', \"CoNLL \\'09 datasets\"]]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['94.26 % LAS and 92.41 % UAS', 'with', 'tri-training']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['very large corpus', 'with', 'large output space']]\",\n",
       " \"[['linear models', 'with', 'rank constraint'], ['billion words', 'within', 'ten minutes'], ['performance', 'on par with', 'state - of - the - art']]\",\n",
       " '[]',\n",
       " \"[['fastText', 'for', '5 epochs'], ['5 epochs', 'with', 'learning rate'], ['learning rate', 'selected on', 'validation set'], ['validation set', 'from', '{ 0.05 , 0.1 , 0.25 , 0.5 }']]\",\n",
       " \"[['bigram information', 'improves', 'performance'], ['performance', 'by', '1 - 4 %']]\",\n",
       " \"[['our accuracy', 'slightly better than', 'char - CNN and char - CRNN'], ['our accuracy', 'bit worse than', 'VDCNN']]\",\n",
       " \"[['accuracy', 'by using', 'more n-grams'], ['slightly', 'by using', 'more n-grams'], ['more n-grams', 'for example with', 'trigrams'], ['performance', 'on', 'Sogou'], ['Sogou', 'goes up to', '97.1 %']]\",\n",
       " \"[['hyperparameters', 'on', 'validation set'], ['n-grams', 'up to', '5'], ['n-grams', 'leads to', 'best performance'], ['5', 'leads to', 'best performance']]\",\n",
       " '[]',\n",
       " \"[['frequency - based baseline', 'predicts', 'most frequent tag']]\",\n",
       " \"[['Tagspace', 'is', 'tag prediction model'], ['Tagspace', 'based on', 'Wsabie model']]\",\n",
       " '[]',\n",
       " \"[['Both models', 'achieve', 'similar performance'], ['similar performance', 'with', 'small hidden layer'], ['Both models', 'adding', 'bigrams'], ['bigrams', 'gives us', 'significant boost'], ['significant boost', 'in', 'accuracy']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['weakly supervised learning', 'such as', 'unsupervised pre-training'], ['weakly supervised learning', 'such as', 'unsupervised data augmentation'], ['domain gap', 'in', 'XLU']]\",\n",
       " '[]',\n",
       " \"[['masked language model ( MLM ) pre-training', 'using', 'unlabeled target language corpora']]\",\n",
       " \"[['unsupervised data augmentation ( UDA ) )', 'where', 'synthetic paraphrases'], ['synthetic paraphrases', 'generated from', 'unlabeled corpus'], ['model', 'trained on', 'label consistency loss']]\",\n",
       " \"[['pre-trained model', 'with', 'source - domain training set']]\",\n",
       " '[]',\n",
       " \"[['unlabeled data', 'from', 'target domain'], ['unlabeled data', 'by optimizing', 'UDA loss function']]\",\n",
       " \"[['Self - training', 'based on', 'UDA model ( UDA + Self )']]\",\n",
       " \"[['better one', 'as', 'teacher model']]\",\n",
       " \"[['new XLM student', 'using', 'only unlabeled data U tgt'], ['only unlabeled data U tgt', 'in', 'target domain']]\",\n",
       " \"[['Ft ( XLM ) results', 'without the help of', 'unlabeled data'], ['unlabeled data', 'from', 'target domain'], ['substantial gap', 'between', 'model performance'], ['substantial gap', 'between', 'monolingual baselines'], ['substantial gap', 'when using', 'state - of - the - art pre-trained cross -lingual representations']]\",\n",
       " \"[['UDA algorithm and MLM pre-training', 'offer', 'significant improvements'], ['significant improvements', 'by utilizing', 'unlabeled data']]\",\n",
       " \"[['sentiment classification task', 'where', 'unlabeled data size'], ['unlabeled data size', 'is', 'larger'], ['Ft ( XLM ft ) model usnig MLM pre-training', 'consistently provides', 'larger improvements'], ['larger improvements', 'compared with', 'UDA method']]\",\n",
       " \"[['MLM method', 'is', 'relatively more resource intensive'], ['MLM method', 'takes', 'longer']]\",\n",
       " \"[['MLdoc dataset', 'when', 'size'], ['size', 'of', 'unlabeled samples'], ['size', 'is', 'limited'], ['unlabeled samples', 'is', 'limited'], ['UDA method', 'is', 'more helpful']]\",\n",
       " \"[['sentiment classification task', 'observe', 'self - training technique'], ['consistently improves', 'over', 'teacher model']]\",\n",
       " \"[['best results', 'in', 'XLM and XLM ft based classifiers']]\",\n",
       " \"[['self - training', 'achieves', 'best results']]\",\n",
       " \"[['monolingual fine - tune baseline', 'completely close', 'performance gap'], ['performance gap', 'by utilizing', 'unlabeled data'], ['unlabeled data', 'in', 'target language']]\",\n",
       " \"[['our framework', 'reaches', 'new state - of - the - art results'], ['our framework', 'improving over', 'vanilla XLM baselines'], ['new state - of - the - art results', 'improving over', 'vanilla XLM baselines'], ['vanilla XLM baselines', 'by', '44 %']]\",\n",
       " \"[['unlabeled data', 'from', 'other domains'], ['unlabeled data', 'does not offer', 'consistent improvement'], ['other domains', 'does not offer', 'consistent improvement'], ['consistent improvement', 'provide', 'additional value'], ['additional value', 'in', 'isolated cases']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Neural Attentive Bagof - Entities ( NABoE ) model', 'is', 'neural network model'], ['neural network model', 'addresses', 'text classification problem'], ['text classification problem', 'by modeling', 'semantics'], ['semantics', 'in', 'target documents'], ['semantics', 'using', 'entities'], ['entities', 'in', 'KB']]\",\n",
       " \"[['each entity name', 'in', 'document'], ['entities', 'represents', 'document'], ['document', 'using', 'weighted average'], ['weighted average', 'of', 'embeddings'], ['embeddings', 'of', 'entities']]\",\n",
       " \"[['weights', 'computed using', 'novel neural attention mechanism'], ['novel neural attention mechanism', 'enables', 'model'], ['model', 'to focus on', 'small subset'], ['small subset', 'of', 'entities'], ['entities', 'that are', 'less ambiguous'], ['less ambiguous', 'in', 'meaning'], ['novel neural attention mechanism', 'more relevant to', 'document'], ['model', 'more relevant to', 'document']]\",\n",
       " \"[['attention mechanism', 'designed to compute', 'weights'], ['weights', 'by jointly addressing', 'entity linking and entity salience detection tasks']]\",\n",
       " \"[['mini-batch SGD', 'with', 'learning rate'], ['learning rate', 'controlled by', 'Adam'], ['mini-batch size', 'set to', '32']]\",\n",
       " \"[['size', 'of', 'embeddings'], ['size', 'of', 'embeddings'], ['embeddings', 'of', 'words and entities'], ['size', 'set to', 'd = 300'], ['words and entities', 'set to', 'd = 300']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['logistic regression classifier', 'with', 'conventional binary BoW features']]\",\n",
       " '[]',\n",
       " \"[['bidirectional RNN', 'with', 'gated recurrent units ( GRU )']]\",\n",
       " \"[['NTEE', 'is', 'state - of - the - art model'], ['state - of - the - art model', 'uses', 'multi - layer perceptron classifier'], ['multi - layer perceptron classifier', 'with', 'features'], ['multi - layer perceptron classifier', 'trained on', 'Wikipedia'], ['words and entities', 'trained on', 'Wikipedia'], ['Wikipedia', 'using', 'neural network model']]\",\n",
       " '[]',\n",
       " \"[['our models', 'yielded', 'enhanced over all performance'], ['enhanced over all performance', 'on', 'both datasets']]\",\n",
       " \"[['NABoE - full model', 'outperformed', 'all baseline models'], ['all baseline models', 'in terms of', 'both measures'], ['both measures', 'on', 'both datasets']]\",\n",
       " \"[['NABoE-entity model', 'outperformed', 'all the baseline models'], ['all the baseline models', 'in terms of', 'both measures'], ['both measures', 'on', '20NG dataset'], ['F 1 score', 'on', 'R8 dataset']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['inherently jointed', 'to construct', 'word embeddings']]\",\n",
       " \"[['task information', 'regularize', 'distribution'], ['distribution', 'of', 'salient words'], ['salient words', 'to have', 'clear classification boundary'], ['task information', 'adjust', 'distribution'], ['distribution', 'of', 'other words'], ['other words', 'in', 'embedding space']]\",\n",
       " \"[['BOW method', 'employed as', 'basic baseline']]\",\n",
       " \"[['each document', 'as', 'bag of words'], ['weighting scheme', 'is', 'TFIDF']]\",\n",
       " \"[['Word2 Vec method', 'is', 'neural network language method'], ['neural network language method', 'which learns', 'word embeddings'], ['word embeddings', 'by maximizing', 'conditional probability'], ['conditional probability', 'leveraging', 'contextual information']]\",\n",
       " \"[['Our method', 'performs', 'better'], ['better', 'than', 'other methods']]\",\n",
       " \"[['ToWE - SG method', 'significantly outperforms', 'other baselines'], ['other baselines', 'on', '20 New s Group'], ['other baselines', 'on', '5 Abstract s Group'], ['other baselines', 'on', 'MR']]\",\n",
       " \"[['word embedding methods', 'outperform', 'basic bag - of - words methods'], ['basic bag - of - words methods', 'in', 'most cases'], ['basic bag - of - words methods', 'indicating', 'superiority'], ['most cases', 'indicating', 'superiority']]\",\n",
       " \"[['Our method', 'achieves', 'better performance'], ['better performance', 'over', 'Retrofit method']]\",\n",
       " \"[['Our method', 'outperforms', 'TWE method'], ['TWE method', 'on', 'document - level and sentence - level tasks']]\",\n",
       " '[]',\n",
       " \"[['new graph neural networkbased method', 'for', 'text classification']]\",\n",
       " \"[['single large graph', 'from', 'entire corpus'], ['entire corpus', 'contains', 'words and documents'], ['words and documents', 'as', 'nodes']]\",\n",
       " \"[['graph', 'with', 'Graph Convolutional Network ( GCN )'], ['graph', 'with', 'simple and effective graph neural network'], ['simple and effective graph neural network', 'captures', 'high order neighborhoods information']]\",\n",
       " '[[\\'edge\\', \\'between\\', \\'two word nodes\\'], [\\'edge\\', \\'between\\', \\'word node and document node\\'], [\\'word node and document node\\', \\'built using\\', \\'word frequency\\'], [\\'word node and document node\\', \\'built using\\', \"word \\'s document frequency\"]]',\n",
       " \"[['text classification problem', 'into', 'anode classification problem']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['bag - of - words model', 'with', 'term frequencyinverse document frequency weighting']]\",\n",
       " \"[['Logistic Regression', 'used as', 'classifier']]\",\n",
       " '[]',\n",
       " \"[['CNN -rand', 'uses', 'randomly initialized word embeddings'], ['CNN -rand', 'uses', 'CNN - non- static'], ['CNN - non- static', 'uses', 'pre-trained word embeddings'], ['CNN - non- static', 'uses', 'pre-trained word embeddings']]\",\n",
       " \"[['last hidden state', 'as', 'representation'], ['representation', 'of', 'whole text']]\",\n",
       " '[]',\n",
       " \"[['orders of words', 'in', 'text']]\",\n",
       " \"[['Logistic Regression', 'as', 'classifier']]\",\n",
       " \"[['paragraph vector model', 'considers', 'word order']]\",\n",
       " \"[['Logistic Regression', 'as', 'classifier']]\",\n",
       " \"[['predictive text embedding', 'firstly learns', 'word embedding'], ['word embedding', 'based on', 'heterogeneous text network'], ['heterogeneous text network', 'containing', 'words , documents and labels'], ['words , documents and labels', 'as', 'nodes'], ['predictive text embedding', 'averages', 'word embeddings'], ['word embeddings', 'as', 'document embeddings'], ['document embeddings', 'for', 'text classification']]\",\n",
       " \"[['average of word / n- grams embeddings', 'as', 'document embeddings'], ['document embeddings', 'into', 'linear classifier']]\",\n",
       " \"[['SWEM', 'employs', 'simple pooling strategies'], ['simple word embedding models', 'employs', 'simple pooling strategies'], ['simple pooling strategies', 'operated over', 'word embeddings']]\",\n",
       " \"[['label - embedding attentive models', 'embeds', 'words and labels'], ['label - embedding attentive models', 'in', 'same joint space'], ['words and labels', 'in', 'same joint space'], ['same joint space', 'for', 'text classification']]\",\n",
       " '[]',\n",
       " \"[['graph CNN model', 'operates', 'convolutions'], ['convolutions', 'over', 'word embedding similarity graphs']]\",\n",
       " \"[['Graph - CNN - S', 'using', 'Spline filter']]\",\n",
       " \"[['Graph - CNN - F', 'same as', 'Graph - CNN - C'], ['Graph - CNN - F', 'using', 'Fourier filter']]\",\n",
       " \"[['Text GCN', 'set', 'embedding size'], ['embedding size', 'of', 'first convolution layer'], ['first convolution layer', 'as', '200'], ['embedding size', 'set', 'window size'], ['window size', 'as', '20']]\",\n",
       " \"[['other parameters', 'set', 'learning rate'], ['learning rate', 'as', '0.02']]\",\n",
       " \"[['baseline models', 'using', 'pre-trained word embeddings'], ['pre-trained word embeddings', 'used', '300 dimensional Glo Ve word embeddings']]\",\n",
       " \"[['Text GCN', 'performs', 'best']]\",\n",
       " \"[['pre-trained Glo Ve word embeddings', 'provided', 'CNN'], ['CNN', 'performs', 'much better'], ['much better', 'especially on', 'Ohsumed and 20 NG']]\",\n",
       " \"[['LSTM - based models', 'rely on', 'pre-trained word embeddings'], ['LSTM - based models', 'perform', 'better'], ['better', 'when', 'documents'], ['documents', 'are', 'shorter']]\",\n",
       " \"[['PV - DBOW', 'achieves', 'comparable results'], ['comparable results', 'to', 'strong baselines'], ['strong baselines', 'on', '20 NG and Ohsumed']]\",\n",
       " \"[['PV - DM', 'performs', 'worse'], ['worse', 'than', 'PV - DBOW']]\",\n",
       " \"[['Graph - CNN models', 'show', 'competitive performances']]\",\n",
       " '[]',\n",
       " \"[['deep pyramid CNN ( DPCNN )', 'as', 'computation time per layer']]\",\n",
       " \"[['discrete text', 'to', 'continuous representation'], ['DPCNN architecture', 'alternates', 'convolution block'], ['DPCNN architecture', 'alternates', 'downsampling layer'], ['downsampling layer', 'over and over', '1'], ['1', 'leading to', 'deep network'], ['deep network', 'in which', 'internal data size']]\",\n",
       " \"[['network depth', 'treated as', 'meta-parameter']]\",\n",
       " \"[['computational complexity', 'of', 'network']]\",\n",
       " \"[['DPCNN', 'with', '15 weight layers'], ['15 weight layers', 'outperforms', 'previous best models'], ['previous best models', 'on', 'six benchmark datasets'], ['six benchmark datasets', 'for', 'sentiment classification']]\",\n",
       " \"[['first layer', 'performs', 'text region embedding'], ['commonly used word embedding', 'to', 'embedding'], ['embedding', 'of', 'text regions']]\",\n",
       " \"[['pooling layers', 'with', 'stride 2'], ['stride 2', 'for', 'downsampling']]\",\n",
       " \"[['internal data', 'for', 'each document'], ['each document', 'into', 'one vector']]\",\n",
       " \"[['max pooling', 'for', 'all pooling layers']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['DPCNN', 'outperforms', 'all of the previous results']]\",\n",
       " '[]',\n",
       " \"[['DPCNN performances', 'with', '100 - dim unsupervised embed - dings'], ['100 - dim unsupervised embed - dings', 'as good as', '300 - dim unsupervised embeddings']]\",\n",
       " \"[['ShallowCNN', 'rivals', 'DPCNN'], ['best linear model', 'moved up', 'worst performer'], ['worst performer', 'to', 'third best performer']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['general framework', 'of', 'region embedding + pooling'], ['more sophisticated region embedding', 'via', 'Long Short - Term Memory ( LSTM )']]\",\n",
       " \"[['learning', 'of', 'dependencies'], ['dependencies', 'over', 'larger time lags']]\",\n",
       " \"[['text regions', 'of', 'variable ( and possibly large ) sizes']]\",\n",
       " \"[['elimination', 'of', 'word embedding layer']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Optimization', 'done with', 'SGD'], ['Optimization', 'done with', 'optionally'], ['SGD', 'with', 'mini-batch size'], ['SGD', 'with', 'optionally'], ['50 or 100', 'with', 'momentum'], ['rmsprop', 'for', 'acceleration']]\",\n",
       " \"[['our one - hot bidirectional LSTM with pooling ( oh - 2 LSTMp )', 'outperforms', 'word - vector LSTM ( wv - LSTM )'], ['word - vector LSTM ( wv - LSTM )', 'on', 'all the datasets']]\",\n",
       " '[]',\n",
       " \"[['oh - 2 LSTMp', 'outperforms', 'CNN']]\",\n",
       " \"[['n-gram SVM', 'no better than', 'bag - of - word SVM'], ['bow - CNN', 'outperforms', 'seq-CNN']]\",\n",
       " \"[['one - hot CNN', 'works', 'surprising well']]\",\n",
       " \"[['previous best performance', 'on', '20NG'], ['20NG', 'is', '15.3'], ['pre-training wv - LSTM', 'of', '1024 units'], ['DL15', 'obtained by', 'pre-training wv - LSTM'], ['pre-training wv - LSTM', 'of', '1024 units'], ['1024 units', 'with', 'labeled training data']]\",\n",
       " \"[['oh - 2 LSTMp', 'achieved', '13.32']]\",\n",
       " '[]',\n",
       " \"[['supervised wv - LSTM', 'underperformed', 'models'], ['models', 'with', 'region tv-embeddings']]\",\n",
       " \"[['wv - 2 LSTMp', 'using', 'Google News vectors'], ['Google News vectors', 'performed', 'relatively poorly']]\",\n",
       " \"[['performance', 'of', 'one - hot CNN'], ['one - hot CNN', 'with', 'one 200 - dim CNN tv-embedding'], ['one 200 - dim CNN tv-embedding', 'comparable with', 'our LSTM']]\",\n",
       " \"[['LSTM', 'rivals or outperforms', 'CNN'], ['CNN', 'on', 'IMDB / Elec'], ['underperforms', 'on', 'RCV1']]\",\n",
       " \"[['dimensionality', 'of', 'LSTM tvembeddings'], ['LSTM tvembeddings', 'from', '100 to 300'], ['100 to 300', 'on', 'RCV1'], ['LSTM tvembeddings', 'does not reach', '7.97'], ['7.97', 'of', 'CNN']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['input', 'is', 'discrete']]\",\n",
       " \"[['perturbation', 'on', 'continuous word embeddings'], ['continuous word embeddings', 'instead of', 'discrete word inputs']]\",\n",
       " \"[['text classifier', 'by stabilizing', 'classification function']]\",\n",
       " \"[['TensorFlow', 'on', 'GPUs']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['gradient clipping', 'with', 'norm'], ['norm', 'set to', '1.0'], ['1.0', 'on', 'all the parameters'], ['all the parameters', 'except', 'word embeddings']]\",\n",
       " \"[['regularization', 'of', 'recurrent language model'], ['regularization', 'applied', 'dropout'], ['recurrent language model', 'applied', 'dropout'], ['dropout', 'on', 'word embedding layer'], ['word embedding layer', 'with', '0.5 dropout rate']]\",\n",
       " \"[['512 hidden units LSTM', 'For', 'standard order and reversed order sequences'], ['bidirectional LSTM model', 'used', '512 hidden units LSTM'], ['512 hidden units LSTM', 'for', 'standard order and reversed order sequences'], ['bidirectional LSTM model', 'used', '256 dimensional word embeddings']]\",\n",
       " \"[['cosine distance', 'on', 'adversarial and virtual adversarial training ( 0.159-0.331 )'], ['cosine distance', 'were', 'much smaller'], ['adversarial and virtual adversarial training ( 0.159-0.331 )', 'were', 'much smaller']]\",\n",
       " \"[['test performance', 'on', 'Elec and RCV1 datasets']]\",\n",
       " \"[['test performance', 'on', 'baseline method'], ['state of the art performance', 'on', 'both datasets'], ['state of the art performance', 'on', 'both datasets']]\",\n",
       " \"[['Our unidirectional LSTM model', 'improves on', 'state of the art method'], ['Our unidirectional LSTM model', 'improves on', 'our method'], ['our method', 'with', 'bidirectional LSTM'], ['results', 'on', 'RCV1']]\",\n",
       " \"[['test performance', 'on', 'Rotten Tomatoes dataset']]\",\n",
       " \"[['Adversarial training', 'able to', 'improve'], ['improve', 'over', 'baseline method'], ['Adversarial training', 'with', 'adversarial and virtual adversarial cost'], ['adversarial and virtual adversarial cost', 'achieved', 'almost the same performance'], ['almost the same performance', 'as', 'current state of the art method']]\",\n",
       " \"[['test performance', 'of', 'only virtual adversarial training'], ['test performance', 'was', 'worse'], ['only virtual adversarial training', 'was', 'worse'], ['test performance', 'worse than', 'baseline'], ['only virtual adversarial training', 'worse than', 'baseline'], ['worse', 'than', 'baseline']]\",\n",
       " '[]',\n",
       " \"[['new architecture', 'short for', 'C - LSTM'], ['new architecture', 'by combining', 'CNN and LSTM'], ['CNN and LSTM', 'to model', 'sentences']]\",\n",
       " \"[['simple end - to - end , unified architecture', 'by feeding', 'output'], ['output', 'of', 'one - layer CNN'], ['one - layer CNN', 'into', 'LSTM']]\",\n",
       " \"[['CNN', 'constructed on top of', 'pre-trained word vectors'], ['pre-trained word vectors', 'from', 'massive unlabeled text data'], ['massive unlabeled text data', 'to learn', 'higher - level representions'], ['higher - level representions', 'of', 'n-grams']]\",\n",
       " \"[['sequential correlations', 'from', 'higher - level suqence representations'], ['feature maps', 'of', 'CNN'], ['feature maps', 'organized as', 'sequential window features'], ['CNN', 'organized as', 'sequential window features'], ['sequential window features', 'to serve as', 'input'], ['input', 'of', 'LSTM']]\",\n",
       " \"[['sequence - based input', 'relying on', 'syntactic parse trees'], ['syntactic parse trees', 'before feeding in', 'neural network']]\",\n",
       " \"[['our model', 'based on', 'Theano'], ['our model', 'based on', 'python library'], ['python library', 'supports', 'efficient symbolic differentiation'], ['our model', 'transparent use of', 'GPU']]\",\n",
       " \"[['model', 'on', 'GPU']]\",\n",
       " \"[['one convolutional layer and one LSTM layer', 'for', 'both tasks']]\",\n",
       " \"[['number of filters', 'set to be', '300'], ['memory dimension', 'set to be', '300']]\",\n",
       " \"[['word vector layer and the LSTM layer', 'dropped outwith', 'probability'], ['probability', 'of', '0.5']]\",\n",
       " \"[['L2 regularization', 'with', 'factor'], ['factor', 'of', '0.001'], ['0.001', 'to', 'weights'], ['weights', 'in', 'softmax layer'], ['softmax layer', 'for', 'both tasks']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['fourth best published result', 'for', '5 - class classification task']]\",\n",
       " \"[['binary classification task', 'achieve', 'comparable results'], ['comparable results', 'with respect to', 'state - of - the - art ones']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['state - of - the - art SVM', 'depends on', 'highly engineered features']]\",\n",
       " \"[['single convolutional layer', 'with', 'filter length 3'], ['filter length 3', 'always outperforms', 'other cases']]\",\n",
       " \"[['single convolutional layer', 'with', 'filter length 3'], ['filter length 3', 'performs', 'best'], ['best', 'among', 'all filter configurations']]\",\n",
       " \"[['multiple convolutional layers', 'shown that', 'filter configurations'], ['filter configurations', 'with', 'filter length 3'], ['filter configurations', 'performs', 'better'], ['better', 'without', 'tri-gram filters']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['deep architectures', 'of', 'many convolutional layers']]\",\n",
       " \"[['dictionary', 'consists of', 'following characters'], ['following characters', 'plus', 'special padding'], ['abcdefghijklmnopqrstuvwxyz0123456', 'plus', 'special padding']]\",\n",
       " \"[['input text', 'padded to', 'fixed size'], ['fixed size', 'of', '1014']]\",\n",
       " \"[['character embedding', 'of', 'size']]\",\n",
       " \"[['Training', 'performed with', 'SGD'], ['SGD', 'using', 'mini-batch'], ['SGD', 'using', 'momentum'], ['mini-batch', 'of size', '128'], ['initial learning rate', 'of size', '0.01'], ['initial learning rate', 'of', '0.01'], ['momentum', 'of', '0.9'], ['momentum', 'of', '0.9']]\",\n",
       " \"[['implementation', 'done using', 'Torch'], ['implementation', 'done using', 'Torch 7']]\",\n",
       " '[]',\n",
       " \"[['temporal batch norm', 'without', 'dropout']]\",\n",
       " \"[['deep architecture', 'works', 'well'], ['well', 'on', 'big data sets'], ['well', 'even for', 'small depths'], ['big data sets', 'even for', 'small depths']]\",\n",
       " '[]',\n",
       " \"[['most important decrease', 'in', 'classification error'], ['most important decrease', 'observed on', 'largest data set Amazon Full'], ['classification error', 'observed on', 'largest data set Amazon Full']]\",\n",
       " \"[['temporal max - pooling', 'works', 'best'], ['best', 'on', 'all data sets']]\",\n",
       " '[]',\n",
       " \"[['text', 'as', 'kind of raw signal'], ['kind of raw signal', 'at', 'character level']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['bag - of - words model', 'constructed by selecting', '50,000 most frequent words'], ['50,000 most frequent words', 'from', 'training subset']]\",\n",
       " '[]',\n",
       " \"[['bag - of - ngrams models', 'constructed by selecting', '500,000 most frequent n-grams ( up to 5 - grams )'], ['500,000 most frequent n-grams ( up to 5 - grams )', 'from', 'training subset'], ['training subset', 'for', 'each dataset']]\",\n",
       " \"[['Bag - of - means', 'on', 'word embedding']]\",\n",
       " \"[['experimental model', 'uses', 'k-means'], ['k-means', 'on', 'word2vec'], ['word2vec', 'learnt from', 'training subset'], ['training subset', 'of', 'each dataset'], ['learnt means', 'as', 'representatives'], ['representatives', 'of', 'clustered words']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['character - level ConvNets', 'work for', 'text classification'], ['text classification', 'need for', 'words']]\",\n",
       " \"[['Traditional methods', 'like', 'n-grams TFIDF'], ['n-grams TFIDF', 'remain', 'strong candidates'], ['strong candidates', 'for', 'dataset'], ['of size', 'up to', 'several hundreds of thousands'], ['character - level ConvNets', 'start to do', 'better']]\",\n",
       " \"[['Conv Nets', 'work', 'well'], ['well', 'for', 'user - generated data']]\",\n",
       " \"[['Choice of alphabet', 'makes', 'difference']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Bidirectional Long Short - Term Memory Networks with Two - Dimensional Max Pooling ( BLSTM - 2DPooling )', 'to capture', 'features'], ['features', 'on', 'time - step dimension'], ['features', 'on', 'feature vector dimension']]\",\n",
       " \"[['Bidirectional Long Short - Term Memory Networks ( BLSTM )', 'to transform', 'text'], ['text', 'into', 'vectors']]\",\n",
       " \"[['2D max pooling operation', 'to obtain', 'fixed - length vector']]\",\n",
       " \"[['2D convolution ( BLSTM - 2DCNN )', 'to capture', 'more meaningful features'], ['more meaningful features', 'to represent', 'input text']]\",\n",
       " \"[['dimension', 'of', 'word embeddings'], ['hidden units', 'of', 'LSTM'], ['dimension', 'is', '300'], ['word embeddings', 'is', '300'], ['LSTM', 'is', '300'], ['hidden units', 'of', 'LSTM'], ['hidden units', 'is', '300'], ['LSTM', 'is', '300']]\",\n",
       " \"[['100 convolutional filters', 'for', 'window sizes'], ['window sizes', 'of', '( 3 , 3 )'], ['2D pooling size', 'of', '( 2 , 2 )'], ['2D pooling size', 'of', '( 2 , 2 )']]\",\n",
       " \"[['mini-batch size', 'as', '10'], ['learning rate', 'of', 'AdaDelta'], ['learning rate', 'as', 'default value'], ['AdaDelta', 'as', 'default value']]\",\n",
       " \"[['0.5', 'For', 'word embeddings'], ['0.2', 'For', 'BLSTM layer'], ['regularization', 'employ', 'Dropout operation'], ['Dropout operation', 'with', 'dropout rate'], ['dropout rate', 'of', '0.5'], ['0.5', 'for', 'word embeddings'], ['0.2', 'for', 'BLSTM layer'], ['0.2', 'for', '0.4'], ['0.4', 'for', 'penultimate layer'], ['l 2 penalty', 'with', 'coefficient 10 ? 5'], ['coefficient 10 ? 5', 'over', 'parameters']]\",\n",
       " '[]',\n",
       " \"[['BLSTM - 2DCNN model', 'achieves', 'excellent performance'], ['excellent performance', 'on', '4 out of 6 tasks']]\",\n",
       " \"[['52.4 % and 89.5 % test accuracies', 'on', 'SST - 1 and SST - 2']]\",\n",
       " \"[['BLSTM - 2DPooling', 'performs', 'worse'], ['worse', 'than', 'state - of - the - art models']]\",\n",
       " \"[['BLSTM - CNN', 'beats', 'all baselines'], ['all baselines', 'on', 'SST - 1 , SST - 2 , and TREC datasets']]\",\n",
       " \"[['BLSTM - 2DCNN', 'gets', 'second higher accuracies']]\",\n",
       " \"[['BLSTM - 2DCNN', 'achieves', 'comparable result']]\",\n",
       " \"[['external language - specific features', 'such as', 'dependency parse trees']]\",\n",
       " \"[['BLSTM - 2DCNN', 'on', 'five datasets'], ['outperforms', 'on', 'five datasets']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['simple bi-directional LSTM ( BiLSTM ) architecture', 'with', 'appropriate regularization'], ['appropriate regularization', 'yields', 'accuracy and F 1'], ['accuracy and F 1', 'competitive or exceed', 'state of the art'], ['state of the art', 'on', 'four standard benchmark datasets']]\",\n",
       " \"[['large - scale reproducibility study', 'involving', 'HAN'], ['large - scale reproducibility study', 'involving', 'XML - CNN'], ['large - scale reproducibility study', 'involving', 'KimCNN'], ['large - scale reproducibility study', 'involving', 'SGM']]\",\n",
       " \"[['neural approaches', 'to', 'logistic regression ( LR )'], ['neural approaches', 'to', 'support vector machines ( SVMs )']]\",\n",
       " \"[['LR model', 'trained using', 'one - vs - rest multi-label objective'], ['SVM', 'trained with', 'linear kernel']]\",\n",
       " \"[['Nvidia GTX 1080 and RTX 2080 Ti GPUs', 'with', 'PyTorch 0.4.1'], ['PyTorch 0.4.1', 'as', 'backend framework']]\",\n",
       " \"[['Scikitlearn 0.19.2', 'for computing', 'tf - idf vectors'], ['Scikitlearn 0.19.2', 'implementing', 'LR and SVMs']]\",\n",
       " \"[['our simple LSTM reg model', 'achieves', 'state of the art'], ['state of the art', 'on', 'Reuters and IMDB'], ['state of the art', 'establishing', 'mean scores'], ['mean scores', 'of', '87.0 and 52.8'], ['87.0 and 52.8', 'for', 'F 1 score and accuracy'], ['F 1 score and accuracy', 'on', 'test sets'], ['test sets', 'of', 'Reuters and IMDB']]\",\n",
       " \"[['LSTM reg', 'consistently improves upon', 'performance'], ['performance', 'of', 'LSTM base'], ['LSTM base', 'across', 'all of the tasks'], ['increases', 'of', '1.5 and 0.5 points'], ['1.5 and 0.5 points', 'for', 'F 1 score and accuracy']]\",\n",
       " \"[['state - of - theart test F 1 scores', 'on', 'AAPD']]\",\n",
       " \"[['non-neural LR and SVM baselines', 'perform', 'remarkably well']]\",\n",
       " \"[['SVM', 'beats', 'many neural baselines']]\",\n",
       " \"[['SVM', 'ties or beats', 'other models']]\",\n",
       " \"[['LR baseline', 'better suited for', 'single - label datasets'], ['LR baseline', 'achieves', 'better accuracy']]\",\n",
       " '[]',\n",
       " \"[['mLSTM and Transformer language models', 'on', 'large 40 GB text dataset'], ['multidimensional emotion classification', 'based on', 'Plutchik wheel of emotions']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Transformer', 'gets', 'close'], ['Transformer', 'does not exceed', 'state of the art'], ['state of the art', 'on', 'SST dataset'], ['Watson and Google Sentiment APIs', 'on', 'company tweets'], ['state of the art', 'exceeds', 'mL - STM and ELMo baseline'], ['Watson and Google Sentiment APIs', 'on', 'company tweets']]\",\n",
       " '[]',\n",
       " \"[['outperform', 'on', 'every emotion category'], ['Watson', 'on', 'every emotion category']]\",\n",
       " '[]',\n",
       " \"[['Our model', 'achieved', 'top macro-averaged F1 score'], ['top macro-averaged F1 score', 'among', 'all submission'], ['top macro-averaged F1 score', 'with', 'competitive but lower scores'], ['competitive but lower scores', 'for', 'micro -average F1']]\",\n",
       " \"[['deep learning architectures', 'of', 'Transformer and m LSTM'], ['Transformer', 'outperforms', 'm LSTM'], ['m LSTM', 'across', 'Plutchik categories']]\",\n",
       " \"[['Our models', 'gets', 'lower F 1 scores'], ['lower F 1 scores', 'on', 'company tweets dataset'], ['lower F 1 scores', 'than on', 'equivalent Se -m Eval categories']]\",\n",
       " '[]',\n",
       " \"[['modifications', 'on', 'network'], ['modifications', 'reducing', 'number of parameters'], ['network', 'reducing', 'number of parameters']]\",\n",
       " '[]',\n",
       " \"[['text classification model', 'requires', 'significantly fewer parameters'], ['significantly fewer parameters', 'compared to', 'stateof - the - art CNNs']]\",\n",
       " \"[['network architecture', 'implemented in', 'PyTorch']]\",\n",
       " \"[['SVDCNN experimental settings', 'using', 'same dictionary'], ['SVDCNN experimental settings', 'using', 'same embedding size'], ['same embedding size', 'of', '16']]\",\n",
       " \"[['training', 'performed with', 'SGD'], ['SGD', 'utilizing', 'size batch'], ['size batch', 'of', '64'], ['size batch', 'with', 'maximum of 100 epochs'], ['64', 'with', 'maximum of 100 epochs']]\",\n",
       " \"[['initial learning rate', 'of', '0.01'], ['momentum', 'of', '0.9'], ['weight decay', 'of', '0.001'], ['momentum', 'of', '0.9'], ['weight decay', 'of', '0.001'], ['weight decay', 'of', '0.001']]\",\n",
       " '[]',\n",
       " \"[['network reduction', 'obtained by', 'GAP'], ['GAP', 'is', 'even more representative']]\",\n",
       " \"[['dataset', 'with', 'four target classes'], ['SVDCNN', 'with', 'VDCNN'], ['SVDCNN', 'with', 'VDCNN'], ['number of parameters', 'of', 'FC layers'], ['12.59 to 0.02 million parameters', 'representing', 'reduction'], ['reduction', 'of', '99.84 %']]\",\n",
       " \"[['11.36 million', 'of', 'FC parameters']]\",\n",
       " \"[['VDCNN', 'with', 'same depth'], ['same depth', 'occupies', '64. 16 MB'], ['64. 16 MB', 'of', 'storage']]\",\n",
       " '[]',\n",
       " \"[['performance difference', 'between', 'VDCNN and SVDCNN models'], ['performance difference', 'varies between', '0.4 and 1.3 %'], ['VDCNN and SVDCNN models', 'varies between', '0.4 and 1.3 %']]\",\n",
       " '[]',\n",
       " \"[['Label - Embedding Attentive Model ( LEAM )', 'to improve', 'text classification']]\",\n",
       " \"[['proposed LEAM', 'implemented by', 'jointly embedding'], ['word and label', 'in', 'same latent space'], ['text representations', 'constructed directly using', 'text - label compatibility']]\",\n",
       " \"[['Label - attentive text representation', 'is', 'informative'], ['informative', 'for', 'downstream classification task']]\",\n",
       " \"[['LEAM learning procedure', 'involves', 'series of basic algebraic operations'], ['LEAM learning procedure', 'retains', 'interpretability'], ['interpretability', 'of', 'simple models']]\",\n",
       " \"[['300 - dimensional Glo Ve word embeddings', 'as', 'initialization'], ['initialization', 'for', 'word embeddings and label embeddings'], ['word embeddings and label embeddings', 'in', 'our model']]\",\n",
       " \"[['Out - Of - Vocabulary ( OOV ) words', 'initialized from', 'uniform distribution'], ['uniform distribution', 'with', 'range [ ? 0.01 , 0.01 ]']]\",\n",
       " \"[['final classifier', 'implemented as', 'MLP layer'], ['MLP layer', 'followed by', 'sigmoid or softmax function'], ['sigmoid or softmax function', 'depending on', 'specific task']]\",\n",
       " \"[['initial learning rate', 'of', '0.001'], ['minibatch size', 'of', '100']]\",\n",
       " \"[['Dropout regularization', 'employed on', 'final MLP layer'], ['Dropout regularization', 'with', 'dropout rate 0.5'], ['final MLP layer', 'with', 'dropout rate 0.5']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['logistic regression model', 'with', 'bag - ofwords'], ['logistic regression model', 'with', 'single - layer 1 D convolutional network']]\",\n",
       " \"[['multi-label classification of clinical text', 'including', 'Condensed Memory Networks ( C - MemNN )'], ['multi-label classification of clinical text', 'including', 'Attentive LSTM'], ['multi-label classification of clinical text', 'including', 'Convolutional Attention ( CAML )']]\",\n",
       " \"[['LEAM', 'provides', 'best AUC score'], ['better F1 and P@5 values', 'than', 'all methods'], ['all methods', 'except', 'CNN']]\",\n",
       " \"[['CNN', 'consistently outperforms', 'basic Bi - GRU architecture'], ['logistic regression baseline', 'performs', 'worse'], ['worse', 'than', 'all deep learning architectures']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['hierarchical classification', 'call', 'Hierarchical Deep Learning for Text classification ( HDLTex )']]\",\n",
       " \"[['hierarchical document classification', 'call', 'Hierarchical Deep Learning for Text classification ( HDLTex )']]\",\n",
       " \"[['HDLTex', 'combines', 'deep learning architectures'], ['deep learning architectures', 'to allow', 'over all and specialized learning']]\",\n",
       " '[]',\n",
       " \"[['processing', 'done on', 'Xeon E5 ? 2640 ( 2.6 GHz )'], ['processing', 'done on', 'GPU cards'], ['processing', 'done on', 'N vidia Tesla K20c'], ['Xeon E5 ? 2640 ( 2.6 GHz )', 'with', '32 cores'], ['Xeon E5 ? 2640 ( 2.6 GHz )', 'with', '64GB memory'], ['GPU cards', 'were', 'N vidia Quadro K620'], ['GPU cards', 'were', 'N vidia Tesla K20c']]\",\n",
       " \"[['Python', 'using', 'Compute Unified Device Architecture ( CUDA )'], ['Compute Unified Device Architecture ( CUDA )', 'is', 'parallel computing platform']]\",\n",
       " \"[['Keras and Tensor Flow libraries', 'for creating', 'neural networks']]\",\n",
       " \"[['stacking SVM', 'with', 'three deep learning approaches']]\",\n",
       " \"[['RNN', 'outperforms', 'others'], ['others', 'for', 'all three W OS data sets']]\",\n",
       " \"[['CNN', 'performs', 'secondbest'], ['secondbest', 'for', 'three data sets']]\",\n",
       " \"[['term weighting', 'is', 'third'], ['third', 'for', 'first two sets'], ['third place', 'for', 'third data set'], ['multi-word approach', 'in', 'third place'], ['third place', 'for', 'third data set']]\",\n",
       " \"[['nave Bayes', 'does', 'much worse'], ['much worse', 'than', 'other methods']]\",\n",
       " \"[['HDLTex approaches', 'with', 'stacked , deep learning architectures'], ['stacked , deep learning architectures', 'provide', 'superior performance']]\",\n",
       " \"[['combination RNN', 'For', 'first level of classification'], ['DNN', 'For', 'second level'], ['best accuracy', 'obtained by', 'combination RNN'], ['combination RNN', 'for', 'first level of classification'], ['combination RNN', 'for', 'DNN'], ['DNN', 'for', 'second level'], ['DNN', 'for', 'second level']]\",\n",
       " \"[['accuracies', 'of', '94 %'], ['94 %', 'for', 'first level'], ['94 %', 'for', '86 %'], ['92 %', 'for', 'second level'], ['92 %', 'for', 'second level']]\",\n",
       " \"[['RNN', 'For', 'level one'], ['RNN', 'For', 'level 2'], ['best scores', 'achieved by', 'RNN'], ['RNN', 'for', 'level one'], ['RNN', 'for', 'level 2'], ['RNN', 'for', 'level 2']]\",\n",
       " '[]',\n",
       " \"[['interaction mechanism', 'capable of incorporating', 'word - level matching signals'], ['word - level matching signals', 'for', 'text classification']]\",\n",
       " '[]',\n",
       " \"[['proposed framework', 'consists of', 'three main components']]\",\n",
       " \"[['word - level encoder', 'projects', 'textual contents'], ['textual contents', 'into', 'word - level representations']]\",\n",
       " \"[['interaction layer', 'calculates', 'matching scores'], ['matching scores', 'between', 'words and classes']]\",\n",
       " \"[['matching scores', 'into', 'predictions'], ['predictions', 'over', 'each class']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['multi -class task', 'chose', 'region embedding'], ['region embedding', 'as', 'Encoder'], ['Encoder', 'in', 'EXAM']]\",\n",
       " \"[['region size', 'is', '7'], ['embedding size', 'is', '128'], ['embedding size', 'is', '128']]\",\n",
       " \"[['adam ( Kingma and Ba 2014 )', 'as', 'optimizer'], ['adam ( Kingma and Ba 2014 )', 'with', 'initial learning rate'], ['optimizer', 'with', 'initial learning rate'], ['batch size', 'set to', '16']]\",\n",
       " \"[['aggregation MLP', 'set', 'size'], ['size', 'of', 'hidden layer'], ['size', 'as', '2 times'], ['size', 'as', '2 times interaction feature length'], ['hidden layer', 'as', '2 times'], ['hidden layer', 'as', '2 times interaction feature length']]\",\n",
       " \"[['MXNet ( Chen et al. )', 'with', 'single NVIDIA TITAN Xp']]\",\n",
       " '[]',\n",
       " \"[['baselines', 'mainly in', 'three variants']]\",\n",
       " \"[['models', 'based on', 'feature engineering']]\",\n",
       " '[]',\n",
       " \"[['Models', 'based on', 'feature engineering'], ['Models', 'get', 'worst results'], ['feature engineering', 'get', 'worst results'], ['worst results', 'on', 'all the five datasets'], ['worst results', 'compared to', 'other methods'], ['all the five datasets', 'compared to', 'other methods']]\",\n",
       " \"[['Char - based models', 'get', 'highest over all scores'], ['highest over all scores', 'on', 'two Amazon datasets']]\",\n",
       " \"[['Word - based baselines', 'exceed', 'other variants'], ['other variants', 'on', 'three datasets'], ['lose', 'on', 'two Amazon datasets']]\",\n",
       " \"[['W.C Region Emb', 'performs', 'best']]\",\n",
       " \"[['EXAM', 'achieves', 'best performance'], ['best performance', 'over', 'three datasets']]\",\n",
       " \"[['EXAM', 'improves', 'best performance'], ['best performance', 'by', '1.1 %']]\",\n",
       " '[]',\n",
       " \"[['EXAM', 'by', 'MXNet']]\",\n",
       " \"[['matrix', 'trained by', 'word2vec'], ['word2vec', 'to initialize', 'embedding layer'], ['embedding size', 'is', '256']]\",\n",
       " \"[['GRU', 'as', 'Encoder'], ['each GRU Cell', 'has', '1,024 hidden states']]\",\n",
       " \"[['accumulated MLP', 'has', '60 hidden units']]\",\n",
       " \"[['Adam', 'to optimize', 'models'], ['models', 'on', 'one NVIDIA TITAN Xp'], ['one NVIDIA TITAN Xp', 'with', 'batch size'], ['batch size', 'of', '1000'], ['initial learning rate', 'is', '0.001']]\",\n",
       " \"[['validation set', 'applied for', 'early - stopping'], ['early - stopping', 'to avoid', 'overfitting']]\",\n",
       " \"[['Word - based models', 'better than', 'char - based models'], ['char - based models', 'in', 'Kanshan - Cup dataset']]\",\n",
       " \"[['Our models', 'achieve', 'state - of - the - art performance'], ['state - of - the - art performance', 'over', 'two different datasets']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['each language', 'define', 'train , development and test corpus']]\",\n",
       " '[]',\n",
       " \"[['classifiers', 'based on', 'MultiCCA embeddings'], ['classifiers', 'perform', 'very well'], ['MultiCCA embeddings', 'perform', 'very well'], ['very well', 'on', 'development corpus']]\",\n",
       " \"[['system', 'trained on', 'English'], ['system', 'achieves', 'excellent results'], ['English', 'achieves', 'excellent results'], ['excellent results', 'transfered to', 'different languages']]\",\n",
       " \"[['transfer accuracies', 'are', 'quite low'], ['quite low', 'when training', 'classifiers'], ['classifiers', 'on', 'other languages'], ['other languages', 'than', 'English']]\",\n",
       " \"[['systems', 'using', 'multilingual sentence embeddings']]\",\n",
       " \"[['German or French', 'leads to', 'better transfer performance'], ['better transfer performance', 'training on', 'English']]\",\n",
       " \"[['Crosslingual transfer', 'between', 'very different languages'], ['very different languages', 'like', 'Chinese and Russian'], ['Crosslingual transfer', 'achieves', 'remarkable results']]\",\n",
       " '[]',\n",
       " \"[['important improvement', 'for', 'all languages'], ['important improvement', 'in comparison to', 'zero - shot or targeted transfer learning'], ['all languages', 'in comparison to', 'zero - shot or targeted transfer learning']]\",\n",
       " '[]',\n",
       " \"[['positioninvariance', 'into', 'RNN'], ['novel model', 'named', 'Disconnected Recurrent Neural Network ( DRNN )']]\",\n",
       " \"[['position - invariance', 'utilize', 'max pooling'], ['max pooling', 'to extract', 'important information']]\",\n",
       " \"[['special 1D CNN', 'where', 'convolution kernels'], ['convolution kernels', 'replaced with', 'recurrent units']]\",\n",
       " \"[['300D Glo Ve 840B vectors', 'as', 'pre-trained word embeddings']]\",\n",
       " \"[['Adadelta ( Zeiler , 2012 )', 'to optimize', 'all the trainable parameters']]\",\n",
       " \"[['hyperparameter', 'of', 'Adadelta']]\",\n",
       " \"[['gradient explosion problem', 'apply', 'gradient norm clipping']]\",\n",
       " \"[['batch size', 'set to', '128'], ['all the dimensions', 'of', 'input vectors and hidden'], ['input vectors and hidden', 'shows', 'our proposed model'], ['all the other models', 'in', '7 datasets']]\",\n",
       " \"[['very deep CNN ( VDCNN )', 'performs', 'well'], ['well', 'in', 'large datasets']]\",\n",
       " \"[['our model', 'achieves', '10 - 50 % relative error reduction'], ['10 - 50 % relative error reduction', 'compared with', 'char - CRNN']]\",\n",
       " \"[['DRNN', 'performs', 'far better'], ['far better', 'than', 'CNN']]\",\n",
       " \"[['Our model DRNN', 'achieves', 'much better performance'], ['much better performance', 'than', 'GRU and LSTM']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['iterative routing process', 'to decide', 'credit attribution'], ['credit attribution', 'between', 'nodes'], ['credit attribution', 'from', 'lower and higher layers']]\",\n",
       " '[[\\'Three strategies\\', \\'to stabilize\\', \\'dynamic routing process\\'], [\\'dynamic routing process\\', \\'to alleviate\\', \\'disturbance\\'], [\\'disturbance\\', \\'of\\', \\'some noise capsules\\'], [\\'\" background \" information\\', \\'such as\\', \\'stop words\\']]',\n",
       " \"[['300 - dimensional word2vec vectors', 'to initialize', 'embedding vectors']]\",\n",
       " '[[\\'mini-batch\\', \\'with\\', \\'size\\'], [\\'50\\', \\'for\\', \"AG \\'s news\"], [\\'25\\', \\'for\\', \\'other datasets\\'], [\\'25\\', \\'for\\', \\'other datasets\\']]',\n",
       " \"[['Adam optimization algorithm', 'with', '1e - 3 learning rate'], ['1e - 3 learning rate', 'to train', 'model']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['capsule networks', 'achieve', 'best results'], ['best results', 'on', '4 out of 6 benchmarks'], ['best results', 'verifies', 'effectiveness'], ['4 out of 6 benchmarks', 'verifies', 'effectiveness'], ['effectiveness', 'of', 'capsule networks']]\",\n",
       " '[]',\n",
       " \"[['capability', 'of', 'capsule network'], ['capsule network', 'on', 'multi-label text classification'], ['multi-label text classification', 'by using', 'single - label samples'], ['single - label samples', 'as', 'training data']]\",\n",
       " \"[['capsule networks', 'have', 'substantial and significant improvement'], ['substantial and significant improvement', 'in terms of', 'all four evaluation metrics'], ['all four evaluation metrics', 'over', 'strong baseline methods'], ['strong baseline methods', 'on', 'test sets'], ['test sets', 'in', 'Reuters - Full datasets']]\",\n",
       " \"[['larger improvement', 'achieved on', 'Reuters - Multi - label dataset'], ['multi-label documents', 'in', 'test set']]\",\n",
       " \"[['much stronger transferring capability', 'than', 'conventional deep neural networks']]\",\n",
       " \"[['good results', 'on', 'Reuters - Full'], ['competitors', 'on', 'single - label documents'], ['good results', 'indicate', 'capsule network'], ['Reuters - Full', 'indicate', 'capsule network'], ['robust superiority', 'over', 'competitors'], ['competitors', 'on', 'single - label documents']]\",\n",
       " '[]',\n",
       " \"[['capsule networks', 'correctly recognize and cluster', 'important phrases'], ['important phrases', 'with respect to', 'text categories']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['local information', 'based on', 'words'], ['context window', 'around', 'global information'], ['global information', 'exploiting', 'document - level coherence']]\",\n",
       " \"[['deep learning', 'to learn', 'basic features and their combinations']]\",\n",
       " '[]',\n",
       " \"[['Wikipedia ( Feb 2014 ) corpus', 'For', 'training'], ['entity embeddings only', 'use', 'Wikipedia ( Feb 2014 ) corpus'], ['Wikipedia ( Feb 2014 ) corpus', 'for', 'training']]\",\n",
       " \"[['0 mean normal distribution', 'with', 'standard deviation 1']]\",\n",
       " '[[\\'each entity vector\\', \\'on\\', \"entity \\'s Wikipedia canonical description page\"], [\"entity \\'s Wikipedia canonical description page\", \\'for\\', \\'400 iterations\\']]',\n",
       " \"[['Adagrad', 'with', 'learning rate'], ['learning rate', 'of', '0.3']]\",\n",
       " \"[['embedding size d', '=', '300'], ['window size', 'of', '20'], ['20', 'for', 'hyperlinks']]\",\n",
       " \"[['Training', 'takes', '20 hours'], ['20 hours', 'on', 'single TitanX GPU'], ['single TitanX GPU', 'with', '12 GB']]\",\n",
       " \"[['Our local and global ED models', 'trained on', 'AIDA - train ( multiple epochs )'], ['AIDA - train ( multiple epochs )', 'validated on', 'AIDA - A']]\",\n",
       " \"[['Adam', 'with', 'learning rate'], ['learning rate', 'of', '1e - 4'], ['1e - 4', 'until', 'validation accuracy'], ['validation accuracy', 'exceeds', '90 %'], ['validation accuracy', 'setting it to', '1e - 5'], ['90 %', 'setting it to', '1e - 5']]\",\n",
       " \"[['regularize', 'use', 'early stopping'], ['early stopping', 'stop', 'learning'], ['learning', 'if', 'validation accuracy'], ['does not increase', 'after', '500 epochs']]\",\n",
       " \"[['single GPU', 'takes', '2 ms'], ['single GPU', 'takes', '16 hours'], ['single GPU', 'on average', '2 ms'], ['2 ms', 'per', 'mention'], ['16 hours', 'for', '1250 epochs'], ['1250 epochs', 'over', 'AIDA - train']]\",\n",
       " \"[['state of the art accuracy', 'on', 'AIDA'], ['AIDA', 'is', 'largest and hardest']]\",\n",
       " \"[['accuracy', 'on', 'AIDA - B dataset'], ['gold entities', 'have', 'low frequency or mention prior']]\",\n",
       " \"[['our method', 'performs', 'well'], ['well', 'in', 'harder cases']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['words and entities', 'for', 'named entity disambiguation ( NED )']]\",\n",
       " \"[['NED', 'using', 'simple NED model'], ['simple NED model', 'based on', 'trained contextualized embeddings']]\",\n",
       " \"[['new contextualized embedding model', 'for', 'words and entities'], ['words and entities', 'for', 'NED'], ['new contextualized embedding model', 'for', 'NED'], ['words and entities', 'for', 'NED']]\",\n",
       " '[]',\n",
       " \"[['sequence of words and entities', 'in', 'input text'], ['contextualized embedding', 'for', 'each word and entity']]\",\n",
       " '[]',\n",
       " \"[['model', 'using', 'texts and their entity annotations'], ['texts and their entity annotations', 'retrieved from', 'Wikipedia']]\",\n",
       " \"[['our models', 'outperformed', 'all previously proposed models']]\",\n",
       " \"[['pseudo entity annotations', 'boosted', 'accuracy'], ['accuracy', 'by', '0.3 %']]\",\n",
       " \"[['new state - of - the - art results', 'on', 'four of the five datasets'], ['four of the five datasets', 'namely', 'MSNBC'], ['four of the five datasets', 'namely', 'AQUAINT'], ['four of the five datasets', 'namely', 'ACE2004'], ['four of the five datasets', 'namely', 'WNED - WIKI'], ['four of the five datasets', 'performed', 'competitive'], ['competitive', 'on', 'WNED - CLUEWEB dataset']]\",\n",
       " \"[['pseudo entity annotations', 'improved', 'performance'], ['performance', 'on', 'AQUAINT and ACE2004 datasets']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['each token', 'assigned', 'representation'], ['representation', 'function of', 'entire input sentence']]\",\n",
       " \"[['vectors', 'derived from', 'bidirectional LSTM'], ['bidirectional LSTM', 'trained with', 'coupled lan - guage model ( LM ) objective'], ['coupled lan - guage model ( LM ) objective', 'on', 'large text corpus']]\",\n",
       " '[]',\n",
       " \"[['ELMo representations', 'are', 'deep']]\",\n",
       " \"[['linear combination of the vectors', 'stacked above', 'each input word'], ['vectors', 'stacked above', 'each input word'], ['each input word', 'for', 'each end task'], ['each input word', 'markedly improves', 'performance'], ['performance', 'over', 'top LSTM layer']]\",\n",
       " \"[['intrinsic evaluations', 'show', 'higher - level LSTM states'], ['higher - level LSTM states', 'capture', 'context - dependent aspects'], ['context - dependent aspects', 'of', 'word meaning'], ['lowerlevel states', 'model', 'aspects']]\",\n",
       " '[]',\n",
       " \"[['ELMo', 'to', 'baseline model'], ['4.7 %', 'from', '81.1 % to 85.8 %'], ['24.9 % relative error reduction', 'over', 'baseline'], ['test set F 1', 'improving', 'overall single model state - of - the - art'], ['overall single model state - of - the - art', 'by', '1.4 %']]\",\n",
       " \"[['increase', 'of', '4.7 %'], ['4.7 %', 'with', 'ELMo'], ['significantly larger', 'then', '1.8 % improvement'], ['1.8 % improvement', 'from adding', 'CoVe'], ['1.8 % improvement', 'to', 'baseline model'], ['CoVe', 'to', 'baseline model']]\",\n",
       " '[]',\n",
       " \"[['ELMo', 'to', 'ESIM model'], ['ELMo', 'improves', 'accuracy'], ['ESIM model', 'improves', 'accuracy'], ['accuracy', 'by', 'average of 0.7 %'], ['average of 0.7 %', 'across', 'five random seeds']]\",\n",
       " '[]',\n",
       " \"[['OntoNotes coreference annotations', 'from', 'CoNLL 2012 shared task'], ['OntoNotes coreference annotations', 'adding', 'ELMo'], ['ELMo', 'improved', 'average F 1'], ['average F 1', 'by', '3.2 %'], ['3.2 %', 'from', '67.2 to 70.4']]\",\n",
       " '[]',\n",
       " \"[['ELMo enhanced biLSTM - CRF', 'achieves', '92. 22 % F 1'], ['92. 22 % F 1', 'averaged over', 'five runs']]\",\n",
       " '[]',\n",
       " \"[['size', 'of', 'neural WSD models'], ['coverage', 'without', 'additional training data'], ['two different methods', 'without impacting', 'precision']]\",\n",
       " \"[['WSD system', 'relies on', 'pre-trained BERT word vectors'], ['state of the art', 'on', 'all WSD evaluation tasks']]\",\n",
       " '[]',\n",
       " \"[['semantic relationships', 'between', 'senses'], ['senses', 'included in', 'WordNet'], ['senses', 'such as', 'hypernymy'], ['senses', 'such as', 'hyponymy'], ['senses', 'such as', 'meronymy'], ['senses', 'such as', 'antonymy'], ['WordNet', 'such as', 'hypernymy']]\",\n",
       " '[]',\n",
       " \"[['BERT', 'used', 'model'], ['model', 'named', 'bert - largecased'], ['bert - largecased', 'of', 'PyTorch implementation'], ['bert - largecased', 'consists of', 'vectors'], ['PyTorch implementation', 'consists of', 'vectors']]\",\n",
       " '[[\\'Transformer encoder layers\\', \\'used\\', \\'same parameters\\'], [\\'same parameters\\', \\'as\\', \\'\" base \" model\\'], [\\'6 layers\\', \\'with\\', \\'8 attention heads\\'], [\\'6 layers\\', \\'with\\', \\'dropout\\'], [\\'hidden size\\', \\'of\\', \\'2048\\'], [\\'dropout\\', \\'of\\', \\'0.1\\']]',\n",
       " \"[['our systems', 'that use', 'sense vocabulary compression'], ['sense vocabulary compression', 'through', 'all relations'], ['all relations', 'obtain', 'scores'], ['overall equivalent', 'to', 'systems']]\",\n",
       " \"[['Princeton WordNet Gloss Corpus', 'use of', 'BERT'], ['BERT', 'as', 'input embeddings'], ['state of the art', 'on', 'every task']]\",\n",
       " \"[['BERT', 'as', 'input embeddings'], ['scores', 'above', 'state of the art']]\",\n",
       " \"[['BERT', 'instead of', 'ELMo or Glo Ve'], ['BERT', 'improves', 'score'], ['ELMo or Glo Ve', 'improves', 'score'], ['score', 'by', 'approximately 3 and 5 points'], ['improves', 'by', 'approximately 2 points'], ['BERT', 'adding', 'WNGC'], ['ELMo or Glo Ve', 'adding', 'WNGC'], ['WNGC', 'to', 'training data'], ['improves', 'by', 'approximately 2 points']]\",\n",
       " \"[['ensembles', 'adds', 'roughly another 1 point'], ['roughly another 1 point', 'to', 'final F1 score']]\",\n",
       " \"[['compression method', 'through', 'all relations'], ['compression method', 'negatively impact', 'results'], ['all relations', 'negatively impact', 'results'], ['results', 'in', 'some cases'], ['results', 'when using', 'ELMo or GloVe'], ['some cases', 'when using', 'ELMo or GloVe']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['Lexical resources', 'like', 'WordNet']]\",\n",
       " \"[['gloss - augmented WSD neural network', 'variant of', 'memory network']]\",\n",
       " \"[['GAS', 'jointly encodes', 'context and glosses'], ['context and glosses', 'of', 'target word'], ['GAS', 'models', 'semantic relationship'], ['semantic relationship', 'between', 'context and glosses'], ['context and glosses', 'in', 'memory module']]\",\n",
       " \"[['inner relationship', 'between', 'glosses and context'], ['inner relationship', 'employ', 'multiple passes operation'], ['multiple passes operation', 'within', 'memory'], ['memory', 'as', 're-reading process'], ['multiple passes operation', 'adopt', 'two memory updating mechanisms']]\",\n",
       " '[]',\n",
       " \"[['pre-trained word embeddings', 'with', '300 dimensions']]\",\n",
       " \"[['256 hidden units', 'in', 'context module']]\",\n",
       " \"[['Orthogonal initialization', 'used for', 'weights'], ['weights', 'in', 'LSTM'], ['random uniform initialization', 'with', 'range [ - 0.1 , 0.1 ]'], ['Orthogonal initialization', 'used for', 'others'], ['random uniform initialization', 'used for', 'others'], ['range [ - 0.1 , 0.1 ]', 'used for', 'others']]\",\n",
       " '[]',\n",
       " \"[['number of passes | T M |', 'from', '1 to 5'], ['1 to 5', 'in', 'our framework'], ['finding', 'performs', 'best']]\",\n",
       " \"[['Adam optimizer', 'in', 'training process'], ['Adam optimizer', 'with', '0.001 initial learning rate'], ['training process', 'with', '0.001 initial learning rate']]\",\n",
       " \"[['overfitting', 'use', 'dropout regularization'], ['drop rate', 'to', '0.5']]\",\n",
       " '[[\\'up to 100 epochs\\', \\'with\\', \\'early stopping\\'], [\\'early stopping\\', \\'if\\', \\'validation loss\\'], [\"does n\\'t improve\", \\'within\\', \\'last 10 epochs\\']]',\n",
       " '[]',\n",
       " \"[['Babelfy', 'exploits', 'semantic network structure'], ['semantic network structure', 'from', 'BabelNet'], ['Babelfy', 'builds', 'unified graph - based architecture'], ['unified graph - based architecture', 'for', 'WSD and Entity Linking']]\",\n",
       " '[]',\n",
       " \"[['IMS', 'selects', 'linear Support Vector Machine ( SVM )'], ['linear Support Vector Machine ( SVM )', 'as', 'classifier'], ['linear Support Vector Machine ( SVM )', 'makes use of', 'set of features'], ['set of features', 'surrounding', 'target word'], ['target word', 'within', 'limited window'], ['limited window', 'such as', 'POS tags'], ['limited window', 'such as', 'local words'], ['limited window', 'such as', 'local collocations']]\",\n",
       " \"[['IMS +emb', 'selects', 'IMS'], ['IMS', 'as', 'underlying framework'], ['IMS +emb', 'makes use of', 'word embeddings'], ['word embeddings', 'as', 'features']]\",\n",
       " '[]',\n",
       " \"[['Bi- LSTM', 'leverages', 'bidirectional LSTM network'], ['bidirectional LSTM network', 'shares', 'model parameters'], ['model parameters', 'among', 'all words']]\",\n",
       " \"[['WSD', 'into', 'sequence learning task'], ['multi - task learning framework', 'for', 'WSD'], ['multi - task learning framework', 'for', 'coarse - grained semantic labels ( LEX )']]\",\n",
       " '[]',\n",
       " \"[['GAS and GAS ext', 'achieves', 'state - of - theart performance'], ['state - of - theart performance', 'concatenation of', 'all test datasets']]\",\n",
       " \"[['GAS ext', 'with', 'concatenation memory updating strategy'], ['concatenation memory updating strategy', 'achieves', 'best results'], ['70.6', 'concatenation of', 'four test datasets']]\",\n",
       " \"[['appropriate number of passes', 'boost', 'performance'], ['appropriate number of passes', 'avoid', 'over - fitting'], ['over - fitting', 'of', 'model']]\",\n",
       " '[]',\n",
       " \"[['multiple passes operation', 'performs', 'better'], ['better', 'than', 'one pass']]\",\n",
       " '[]',\n",
       " \"[['number of passes', 'larger than', '3'], ['F1- score', 'stops', 'increasing or even decreases'], ['increasing or even decreases', 'due to', 'over-fitting']]\",\n",
       " '[]',\n",
       " '[]',\n",
       " '[]',\n",
       " \"[['sequence of words', 'surrounding', 'target word'], ['words', 'using', 'real valued vector representation']]\",\n",
       " '[]',\n",
       " \"[['freely available 2 Glo Ve vectors', 'trained on', 'Wikipedia and Gigaword']]\",\n",
       " \"[['Words', 'initialized from', 'N ( 0 , 0.1 )']]\",\n",
       " \"[['Our proposed model', 'achieves', 'top score'], ['top score', 'on', 'SE2'], ['IMS + adapted CW', 'on', 'SE3'], ['Our proposed model', 'tied with', 'IMS + adapted CW'], ['IMS + adapted CW', 'on', 'SE3']]\",\n",
       " \"[['dropword', 'consistently improves', 'results'], ['results', 'on', 'SE2 and SE3']]\",\n",
       " \"[['input words', 'yields', 'substantially worse result']]\",\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "historical-gospel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[['RNNGs', 'operate via', 'recursive syntactic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[['two variants', 'of', 'algorithm']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[['ancestor sampling', 'to obtain', 'samples']...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>[['model', 'by minimizing', 'loss L'], ['loss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>[['initial learning rate', 'for', 'finetuning'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>[['NQ dev and test set', 'with', 'single Tesla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>[['BERT model', 'for', 'NQ'], ['BERT model', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>[['Our model', 'closes', 'gap'], ['gap', 'betw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2720 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               triple_A\n",
       "0                                                    []\n",
       "1                                                    []\n",
       "2     [['RNNGs', 'operate via', 'recursive syntactic...\n",
       "3                 [['two variants', 'of', 'algorithm']]\n",
       "4     [['ancestor sampling', 'to obtain', 'samples']...\n",
       "...                                                 ...\n",
       "2715  [['model', 'by minimizing', 'loss L'], ['loss ...\n",
       "2716  [['initial learning rate', 'for', 'finetuning'...\n",
       "2717  [['NQ dev and test set', 'with', 'single Tesla...\n",
       "2718  [['BERT model', 'for', 'NQ'], ['BERT model', '...\n",
       "2719  [['Our model', 'closes', 'gap'], ['gap', 'betw...\n",
       "\n",
       "[2720 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(data,columns=['triple_A'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cultural-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('A.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-welcome",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
