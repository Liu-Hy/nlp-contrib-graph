title
Face Alignment using a 3D Deeply-initialized Ensemble of Regression Trees
abstract
Face alignment algorithms locate a set of landmark points in images of faces taken in unrestricted situations. State-of-the-art approaches typically fail or lose accuracy in the presence of occlusions, strong deformations, large pose variations and ambiguous configurations. In this paper we present 3DDE, a robust and efficient face alignment algorithm based on a coarse-to-fine cascade of ensembles of regression trees. It is initialized by robustly fitting a 3D face model to the probability maps produced by a convolutional neural network. With this initialization we address self-occlusions and large face rotations. Further, the regressor implicitly imposes a prior face shape on the solution, addressing occlusions and ambiguous face configurations. Its coarse-to-fine structure tackles the combinatorial explosion of parts deformation. In the experiments performed, 3DDE improves the state-of-the-art in 300W, COFW, AFLW and WFLW data sets. Finally, we perform cross-dataset experiments that reveal the existence of a significant data set bias in these benchmarks.
Introduction
Face alignment algorithms precisely locate a set of points of interest in the images of faces taken in unrestricted conditions. It has received much attention from the research community since it is a preliminary step for estimating 3D facial structure and many other face image analysis problems such as verification and recognition, attributes estimation or facial expression recognition, to name a few. Present approaches typically fail or lose precision in the presence of occlusions, strong deformations produced by facial expressions, large pose variations and ambiguous configurations caused, for example, by strong make-up or the existence of other nearby faces.
Top performers in the most popular benchmarks are based on Convolutional Neural Networks (CNNs) and Ensemble of Regression Trees (ERT), see e.g., Tables 1, 2, 3, 4 and 5. The large effective receptive field of deep models) enable them to model context better and produce robust landmark estimations. However, in these models it is not easy to enforce facial shape consistency, something that limits their accuracy in the presence of occlusions and ambiguous facial configurations. ERT-based models, on the other hand, are difficult to initialize, but may implicitly impose face shape consistency in their estimations. This increases their performance in occluded and ambiguous situations. They are also much more efficient than deep models and, as we demonstrate in our experiments, with a good initialization they are also very accurate.
In this paper we present the 3DDE (3D Deeply-initialized Ensemble) regressor, a robust and efficient face alignment algorithm based on a coarse-to-fine cascade of ERTs. It is a hybrid approach that inherits good properties of ERT, such as the ability to impose a face shape prior, and the robustness of deep models. It is initialized by robustly fitting a 3D face model to the probability maps produced by a CNN. With this initialization we tackle one of the main drawbacks of ERT, namely the difficulty in initializing the regressor in the presence of occlusions and large face rotations. On the other hand, the ERT implicitly imposes a prior face shape on the solution, addressing the shortcomings of deep models when occlusions and ambiguous face configurations are present. Finally, its coarse-to-fine structure tackles the combinatorial explosion of parts deformation, which is also a key limitation of approaches using shape constraints.
A preliminary version of our work appeared in. Here we refine and extend it in several ways. First we improve the initialization by using a RANSAC-like procedure that increases its robustness in the presence of occlusions. We have also introduced early stopping and better data augmentation techniques for increasing the regularization when training both the ERT and the CNN. We also extend the evaluation including the newly released WFLW database and a detailed ablation study. Finally, 3DDE may also be trained in presence of missing and occluded landmarks in the training set. This has enabled us to perform cross-dataset experiments that reveal the existence of significant data set bias that may limit the generalization capabilities of regressors trained on present data bases. To the best of our knowledge, this is the first time such a problem has been raised in the field.

Related Work
Face alignment has been a topic of intense research for more than twenty years. Initial successful results were based on 2D and 3D generative approaches such as the Active Appearance Models (AAM) or the 3D Morphable Models (3DMM). Recent approaches are based on a cascaded combination of discriminative regressors.
In the earliest case these regressors are Random Ferns, Ensembles of Regression Trees or linear models. Key ideas in this approach are indexing image description relative to the current shape estimate, and the use of a regressor whose predictions lie on the subspace spanned by the training face shapes, this is the so-called Cascade Shape Regressor (CSR) framework. improved the original cascade framework by proposing a realtime ensemble of regression trees. used locally binary features to boost the performance up to 3000 FPS. included occlusion estimation and decreased the influence of occluded landmarks. refine the initial location of face landmarks using a random forest and SIFT features. also use SIFT features and learn the linear regressor dividing the search space into individual regions with similar gradient directions. Overall, this set of approaches are very sensitive to the starting point of the regression process. For this reason an important part of recent work revolves around how to find good initializations. However, they are extremely efficient and may take advantage of implicit shape constraints.
The recent development of deep learning techniques has also impacted the face alignment field with the widespread use of CNN-based regressors. were pioneers to apply a three-level CNN for locating landmarks. proposed a multi-task solution to deal with face alignment and attributes classification. use global and local face parts regressors for fine-grained facial deformation estimation. transform the landmarks rather than the input image for the refinement cascade. and are the first approaches that fuse the feature extraction and regression steps of CSR into a recurrent neural network trained end-to-end. and use a global similarity transform to normalize landmark locations followed by a VGG-based and a Stacked Hourglass network respectively to regress the final shape. derive face landmarks from boundary lines, which helps to remove the ambiguities in the landmark definition. Deep CNN models have large effective receptive fields that let them model context better and convey these approaches with a high degree of robustness to face rotation, scale, deformation and initialization. However, when used in a cascaded framework they may notably increase the computational requirements. Moreover, it is not clear how to impose facial shape consistency on the estimated set of landmarks. Hence, the regressor accuracy maybe harmed in the presence of occlusions or ambiguities.
There is also an increasing number of works based on 3D face models. In the simplest case, they fit a mean model to the estimated image landmarks positions or jointly regress the pose and shape of the face. and fit a 3DMM in a cascaded way. These approaches provide 3D pose information that maybe used to estimate landmark self-occlusions or to train simpler regressors specialized in a given head orientation. However, building and fitting a 3D face model is a difficult task and the results of the full 3D approaches in current benchmarks are not as good as those described above.
Our proposal tries to leverage on the good properties of the three approaches described above. Using a CNN-based initialization we inherit the robustness of deep learning models. Like the simple 3D approaches we fit a rigid 3D face model to initialize the regressor and estimate the initial face orientation to address selfocclusions and ambiguities. Finally, we use a cascaded ERT within a coarse-to-fine framework to achieve accuracy and efficiency while avoiding the combinatorial explosion of independent parts deformations.

3D deeply-initialized Ensemble
In this section we present 3DDE. It consists of two main steps: CNN-based rigid face pose computation and ERT-based non-rigid face deformation estimation, both shown in.

Rigid pose computation
ERT-based regressors require a good initialization to converge. We propose the use of face landmarks location probability maps to generate plausible shape initialization candidates. We define a UNet-like architecture, with a loss function that handles missing landmarks. We train this CNN to obtain a set of probability maps, P(I), that model the position of each landmark in the input image (see). The maximum of each smoothed probability map determines our initial landmark positions. Note in that these predictions are sensitive to occlusions, ambiguities and may not be a valid face shape. Compared to typical CNN-based approaches, e.g.,, our CNN is much simpler, since we only require a rough estimation of landmark locations.
To start the ERT with a plausible face, we compute the initial shape by fitting a rigid 3D head model to the estimated 2D landmarks locations. To this end we use the softPOSIT algorithm proposed by within a robust scheme. Unlike, here we use a set of the distinct landmarks to establish the correspondences between the CNN predictions and the 3D face model. This avoids problems related to ambiguous landmarks around the jaw that do not correspond always to the same 3D points and produce wrong initializations, mainly in profile faces. Moreover, we have also implemented a RANSAC-like procedure, that runs softPOSIT several times with subsets of correspondences, to obtain a robust estimation (see Algorithm 1).
Let X ? R L×3 be the 3D coordinates of the L landmarks on the 3D face model, x ? R L×2 their 2D projections onto the image plane and v ? {0, 1} L their visibilities. We produce sub- sets of correspondences (x s , X s ) from the distinct landmarks shown in, estimate the 3D face model pose (R, t) with softPOSIT and evaluate the goodness of each estimation as the sum of landmarks probabilities,
where x z (l) are the 2D coordinates of the l-th landmark and Pl (I) is the probability map for landmark l. Finally, we select the rigid transformation (R, t) with highest p(x z ). As a result, we project the 3D model onto the image using the most likely estimated rigid transformation. This provides the ERT with a rough estimation of the scale, translation and 3D pose of the target face (see), and the visibility estimation of the self-occluded parts of the face.
Let x 0 = g 0 (P(I), X) be the initial shape, the output of the initialization function g 0 after processing the input image I. With our initialization we enforce two key requirements for the convergence of the ERT. First, that x 0 lies on the face with an approximately correct 3D face pose. Second, that x 0 is a valid face shape. The latter guarantees that the predictions in the next step of the algorithm will also be valid face shapes.

ERT-based non-rigid shape estimation
. Each shape s i has its own training image, I i , ground truth shape, x g i , ground truth visibility label, v g i , annotated landmark label, w g i ? {0, 1} L , initial shape, x 0 i , and visibilities, v 0 i , for training the ERT regressor. In our implementa-tion we use shape-indexed features, ?(P(I i ), x ti , w g i ), that depend on the current shape x ti of the landmarks in image I i and whether they are annotated or not, w g i . We divide the regression process into a maximum of T stages. We learn an ensemble of K regression trees for the t-th stage,
) and x j are the coordinates of the landmarks estimated in j-th stage. To train the ERT we use the N training shapes in S to generate an augmented training set of samples, SA , and a validation set, S V , with cardinality N A = |S A | and NV = |S V | respectively. The total number of samples is NT = N A + NV . Instead of using a fixed number of stages, like, we stop training when the validation error stops improving. In this way the regressor has a variable number of stages. We compute the initialization for each sample using the 3D projections produced by g 0 (see generated initializations in). We also improve the data augmentation used in. To this end we add random noise to the yaw, pitch and roll angles, of the rotation matrix R * estimated with g 0 , to generate new training initializations for each sample in SA .
Following et al. and, we attach to each landmark in S the binary labels {v, w} ? {0, 1} that model respectively whether it is visible and annotated. We learn these labels in the ERT together with the landmark location. Each initial shape is progressively refined by estimating a shape and visibility incre-
represents the current shape of the i-th sample (see Algorithm 2). C v t is trained to minimize only the landmark position errors but on each tree leaf, in addition to the mean shape, we also output the mean of all training shapes visibilities, v g i , that belong to that node. We define
as the set of all current shapes and corresponding visibility vectors for all training and validation data, respectively.

Algorithm 2 Training an Ensemble of Regression Trees
Input: S, T // Generate an augmented training set of samples SA, SV = dataAugmentation(S) repeat // Extract training (FA) and validation (FV ) fea-
Compared with conventional ERT approaches, our ensemble is simpler. It will require fewer trees because we only have to estimate the nonrigid face deformation, since the 3D rigid component has already been estimated in the previous step. In the following we describe the details.

Initial shapes for regression
The selection of the starting point in the ERT is fundamental to reach a good solution. The simplest choice is the mean of the ground truth training shapes,x 0 = N i=1 x g i /N . However,, or randomly deform the initial shape.
In our approach we initialize the ERT using the algorithm described in section 3.1, that provides a robust pose and a valid shape for initialization (see). Hence, the ERT only needs to estimate the non-rigid deformation component of the face.

Feature Extraction
ERT efficiency depends on the feature extraction step. In general, descriptor features such as SIFT used by and improve face alignment results, but have higher computational cost compared to simpler features such as plain pixel value differences. In our case, a simple feature suffices, since shape landmarks are close to their ground truth location.
We use the probability maps P(I) to extract features for the cascade. To this end, we select a landmark land its associated probability map Pl (I). The feature is computed as the difference between two pixels values in Pl (I) from a FREAK descriptor pattern around l, similar to those in. However, ours are defined on the probability maps, P(I), instead of the image, I. We let the training algorithm select the most informative landmark and pair of pixels in each iteration.

Learn a coarse-to-fine regressor
To train the t-th stage regressor, C v t , we fit an ERT. Thus, the goal is to sequentially learn a series of weak learners to greedily minimize the regression loss function:
where is the Hadamard product. There are different ways of minimizing Equation 1. present a general framework based on Gradient Boosting for learning an ensemble of regression trees. establish an optimization method based on Gaussian Processes also learning an ensemble of regression trees but outperforming previous literature by reducing the overfitting. In our approach we adopt a Gradient Boosting scheme (see Algorithm 3).
A crucial problem when training a global face landmark regressor is the lack of examples showing all possible combinations of face parts deformations. Hence, these regressors quickly overfit and generalize poorly to combinations of part deformations not present in the training set. To address this problem we introduce the coarse-tofine ERT architecture. The goal is to be able to cope with combinations of face part deformations not seen during training. A single monolithic regressor is notable to estimate these local deformations (see the difference between monolithic and coarse-to-fine NME curves in). Our algorithm is agnostic in the number of parts and stages of the coarse-to-fine estimation. Algorithm 3 details the training of P face parts regressors (each one with a subset of the landmarks) to build a coarseto-fine regressor. Note that A k?1 in this context is the shape and visibility vectors from the last regressor output (e.g., the previous part regressor or a previous full stage regressor). In our implementation the coarse-to-fine scheme has two stages. The coarse stage has one part, P = 1, that involves all landmarks and K 1 trees. The fine stage hasten parts, P = 10, left/right eyebrow, left/right eye, nose, top/bottom mouth, left/right ear and chin (see), with K 2 trees.

Algorithm 3 Training P parts regressors
Input: SA, FA, At?1, ?, K, P for k=1 to K do for p=1 to P do // Compute residuals: // is the Hadamard product // (p) selects elements of vectors in that part
// Update samples with the regression tree estimation, // ?, shrinkage factor to scale each tree contribution: The P = 10 face parts of 300W, COFW, AFLW and WFLW data bases in the fine stage of our coarse-to-fine ERT.

Fit a regression tree
The training objective for the k-th regression tree is to minimize the sum of squared residuals, taking into account the annotated landmark labels:
We learn each regression binary tree by recursively splitting the training set into the left (l) and right (r) child nodes. The tree node split function is designed to minimize E k from Equation 2 in the selected landmark. To train a regression tree node we randomly generate a set of candidate split functions, each of them involving four parameters ? = (?, p 1 , p 2 , l), where p 1 and p 2 are pixels coordinates on a fixed FREAK structure around the l-th landmark coordinates in x k?1 i . The feature value corresponding to ? for the i-th training sample is
, the difference of probability values in the maps for the given landmark. Finally, we compute the split function thresholding the feature value, f i (?) > ? .
Given N ? SA the set of training samples at anode, fitting a tree node for the k-th tree, consists of finding the parameter ? that minimizes
where N ?,l and N ?,r are, respectively, the samples sent to the left and right child nodes due to the decision induced by ?. The mean residual µ ?,b fora candidate split function and a subset of training data is given by
Once we know the optimal split each leaf node stores the mean residual, µ ?,b , as the output of the regression for any example reaching that leaf. We also output the mean visibility of the samples reaching the tree leaf.

Experiments
To train and evaluate our proposal, we perform experiments with 300W, COFW, AFLW and WFLW that are considered the most challenging public data sets:
• 300W. It provides 68 manually annotated landmarks,. We follow the most established approach and divide the 300W annotations into 3148 training and 689 testing images (public competition). Evaluation is also performed on the 300W private competition using the previous 3837 images as training and 600 newly updated images as testing set. • AFLW. It provides a collection of 25993 in-the-wild faces, with 21 facial landmarks annotated depending on their visibility,. We have found several annotations errors and, consequently, removed these faces from our experiments. From the remaining faces we randomly choose 19312 images for training/validation and 4828 instances for testing.
• WFLW. It consists of 7500 extremely challenging training and 2500 testing faces divided into six subgroups, pose, expression, illumination, make-up, occlusion and blur, with 98 fully manual annotated landmarks,.

Evaluation
We use the Normalized Mean Error (NME) as a metric to measure the shape estimation error
It computes the mean euclidean distance between the ground-truth and estimated landmark positions normalized by d i . We report our results using different values of d i : the ground truth distance between the eye centers (pupils), the ground truth distance between the outer eye corners (corners) and the ground truth bounding box size (height).
In addition, we also compare our results using Cumulative Error Distribution (CED) curves.
We calculate AU C ? as the area under the CED curve for images with an NME smaller than ? and F R ? as the failure rate representing the percentage of testing faces with NME greater than ?. We use precision/recall percentages to compare occlusion prediction.
To train our algorithm we shuffle the training set of each database and split it into 90% trainset and 10% validation-set.

Implementation
All experiments have been carried outwith the settings described in this section. For each data set, we train from scratch the CNN selecting the model parameters with lowest validation error. We crop faces using the ground truth bounding boxes annotations enlarged by 30%. We generate different training samples in each epoch by applying random in plane rotations between ±45 • , scale changes by ±15% and translations by ±5% of bounding box size, randomly mirroring images horizontally and generating random rectangular occlusions. We use Adam stochastic optimization with ? 1 = 0.9, ? 2 = 0.999 and = 1e ?8 parameters. We train until convergence with an initial learning rate ? = 0.001. When validation error levels out for 10 epochs, we multiply the learning rate by decay = 0.05. In the CNN the cropped input face is reduced from 160×160 to 1×1 pixels gradually dividing by half their size across B = 8 branches applying astride 2 convolution with kernel size 2×2 1 . We apply batch normalization after each convolution. All layers contain 68 filters to describe the required landmark features. We apply a Gaussian filter with ? = 33 to the output probability maps to stabilize the initialization, g 0 .
We train the coarse-to-fine ERT with the Gradient Boosting algorithm). It requires a maximum of T = 20 stages of K = 50 regression trees per stage. The depth of trees is set to 4. The number of tests to choose the best split parameters, ?, is set to 200. We resize each image to set the face size to 160×160 pixels. For feature extraction, the FREAK pattern diameter is reduced gradually in each stage (i.e., in the last stages the pixel pairs for each feature are closer). We generate Z = 25 initializations in the robust softPOSIT scheme of g 0 . We augment the shapes of each face training image to create a set, SA , of at least N A = 60000 samples to train the cascade. To avoid overfitting we use a shrinkage factor ? = 0.1 and subsampling factor ? = 0.5 in the ERT. Our regressor triggers the coarse-to-fine strategy once the training error is below the validation error, e.g., t = 5 in.
Training the CNN and the coarse-to-fine ensemble of trees takes 48 hours using a NVidia GeForce GTX 1080Ti (11GB) GPU and an dual Intel Xeon Silver 4114 CPU at 2.20GHz (2×10 cores/20 threads, 128 GB of RAM) with a batch size of 32 images. At runtime our method process test images on average at a rate of 12.5 FPS, where the CNN takes 75 ms and the ERT 5 ms per face image using C++, Tensorflow and OpenCV libraries.

Experiments using public code
Published results in the literature are sometimes not fully comparable. In this section we use publicly available code to ensure a fair comparison between 3DDE and DCFE, LAB, DAN, RCN, cGPRT, RCPR and ERT with the same settings (including same training, valida-tion and bounding boxes), in different benchmarks: 300W public, 300W private, COFW and WFLW. Note that LAB only provides a trained model for the WFLW data set. In addition, DAN provides code using 68 landmarks, for this reason we only report results in 300W. In we plot the CED curves for all data bases. In the legend we provide the AU C and F R values for each algorithm.
The selected algorithms are representative of the three main families of solutions: a) ensembles of regression trees (cGPRT, RCPR, ERT), b) CNN-based approaches (LAB, DAN, RCN) and c) mixed approaches with deep nets and ensembles of regression trees (3DDE, DCFE). Overall, 3DDE is better than any other providing a public implementation in the literature. We improve over our preliminary algorithm,, because of the better 3D initialization and regularization (see a complete analysis in section 4.5). In general we are able to improve by a large margin other ERT methods as RCPR, ERT or cGPRT because of the better initialization and the robust features provided by the CNN. We also outperform RCN (without any denoising model), a CNN architecture like the one used in 3DDE. Even DAN and LAB, that implement a cascade of CNN regressors, cannot compete with the regularization obtained by using the cascade of ERT in 3DDE (see). The fact that the largest margin is in COFW reflects the importance of the implicit shape model in our cascade to address occlusions.

Experiments using published results
In this section we compare 3DDE with other methods in the literature by using their published results. Since our method is able to train with unannotated landmarks and visibilities, we are able to train and evaluate all data sets in the literature.
First we test our method against the 300W benchmark. Our approach obtains the best overall performance in the indoor and outdoor subsets of the private competition (see) and in the full subset of the 300W public test set (see). This is due to the excellent accuracy achieved by the coarse-to-fine ERT scheme enforcing valid face shapes and the deep robust features extracted from the CNN. In the challenging subset of the 300W public competition, SHN gets better results than 3DDE. This is due to 3DDE failing to estimate good landmark probability maps for images with large scale variations. Our method exhibits superior capability in handling typical cases in the database, since we achieve the best NME full set results in We may assess the improvement achieved by the 3D initialization and the coarse-to-fine ERT by comparing the results of 3DDE in the full subset of 300W, 4.39, with Honari's RCN using the denoising model, 5.41. It roughly represents a 19% improvement in the inter-pupils NME. compares the performance of our model using the COFW data set. This is the standard to evaluate occlusions. 3DDE obtains the best results, NME 5.11, establishing anew state-of-the-art. This shows the importance of the face shape model implicit in the cascade of 5.28 -17.00 -7.58 -43.12 10.45 SDM 5.60 -15.40 -7.52 -42.94 10.89 ECSAN 5.42 -11.80 -6.67 ---ERT ----6.40 ---LBF 4.95 -11.98 -6.32 ---cGPRT ----5.71 ---CFSS 4.73 -9.98 -5.76 -49.87 5.08 DDN ----5.65 ---TCDCN 4.80 -8.60 -5.54 ---MDM ------52.12 4.21 3DDFA 5.09 -8.07 -5.63 ---RCN 4.67 -8.44 -5.41 ---DAN 4.42 3.19 7.57 5.24 5.03 3.59 55.33 1.16 TSR 4.36 -7.56 -4.99 ---RAR 4.12 -8.35 -4.94 ---SHN 4.12 -7.00 4.90 4.68 ---DCFE 3.83 2.76 7.54 5.22 4.55 3.24 60.13 1.59 PCD-CNN     ERT to cope with severe occlusions. In terms of landmark visibility estimation, we have obtained better precision with an overall better recall than the best previous approach, DCFE. Again, the regularization together with the new initialization contributes to improve DCFE.
In we show the results of our evaluation with AFLW. This is a challenging data set not only because of its size and the large variability of face poses, but also because of the large number of samples with occluded landmarks, that are unannotated. Although the results in are not strictly comparable, because each paper uses its own train and test subsets, we get an NME of 2.06 with the full 21 landmarks set. Again, it is anew state-of-the-art, since most competing approaches do not use the two most difficult landmarks, each located in one earlobe (see 19 landmarks results in). We have also evaluated 3DDE without the two earlobe landmarks. In this case we get an NME of 2.01, the best reported result.
Finally, we have also evaluated 3DDE with the newly released WFLW data set. In enables us to evaluate different sources of variability (i.e., expressions, illumination, make-up, occlusions and blur). In we provide the results of various competing methods, normalized by the eye corners distance. 3DDE outperforms its competitors in all the WFLW subsets by a large margin. We hypothesize that the reason for this is that the hybrid approach in 3DDE can be trained with less samples that some of its most prominent competitors and at the same time provide a very accurate face shape (see). Moreover, we Method pupils occlusion NM E AU C8 F R8 precision/recall RCPR 8.50 --80/40 TCDCN 8.05 ---RAR 6.03 ---DAC-CSR  6.03 ---Wu et al. 5.93 --80/49.11 SHN 5.6 ---PCD-CNN -4.45 CFSS 3.92 -CCL 2.72 -DAC-CSR  2.27 -Binary-CNN -2.85 PCD-CNN -2.40 TSR 2.17 -DCFE 2.12 2.17 3DDE 2.01 2.06 Figure 5: First row shows LAB results, second row 3DDE results. We report the corresponding NME normalized by the eye corners distance. Blue and green colours represent ground truth and predictions respectively.
achieve the best AU C in all subsets, which determines that 3DDE is the best approach under all capture conditions (easy/frontal and difficult/profile) including all subsets that contain several types of difficulties.

Ablation study
3DDE is based on three key ideas: 3D initialization, a cascaded ERT regressor operating on probabilistic CNN features and a coarse-to-fine scheme. In this section we analyze the contribution of each one to the overall performance of our algorithm. In we show the results obtained by different configurations of our framework when evaluated on WFLW. We have chosen WFLW in our study because it allows the analysis of results stratified by different types of difficulties (i.e., facial expressions, large poses, illumination changes, etc.). In this case, since there are many profile faces, we use the height as normalization for the NME. So, the numerical values are not di-rectly comparable to those in. MS stands for "mean shape initialization" of the ERT. 3D means to initialize the ERT with the procedure in section 3.1. SE denotes using plain gray level features for the ERT whereas DE denotes using probability maps produced by the CNN to train the ERT. Finally CF stands for using the coarseto-fine scheme.
When combined with the cascaded ERT, the 3D initialization is key to achieve top overall performance, see CNN+MS+DE vs CNN+3D+DE in the full subset. The reason for this is that, in the 3D case, the initialization takes care of the rigid component of face pose so that the ERT cascade only models non-rigid deformations. Moreover, the projection of the 3D face model is a correct 2D shape, a requirement for the ERT to converge to a valid face shape. Of course, the 3D initialization is fundamental to achieve good performance in presence of large face rotations. So, it provides the largest improvement in the pose subset.
The use of CNN probability maps improves the NME in the full data set in about 20% (see CNN+3D+SE vs CNN+3D+DE). The large receptive fields of CNNs are specially helpful in challenging situations, specifically those in the pose and occlusion subsets.
The coarse-to-fine strategy in our cascaded ERT provides significative local improvements in difficult cases, with rare facial part combinations (see). For this reason, the largest gain of CNN+3D+DE+CF vs CNN+3D+DE occurs in the expressions subset. Although this strategy provides improvements in all the database subsets, the actual NME differences are washed out when averaged over the number of landmarks in the face and the number of images in the subset. They maybe appreciated by looking into specific data subsets or samples (see), such

Method Full
Pose Expression Illumination Make-up Occlusion Blur corners corners corners corners corners corners corners NM E AU C 10 F R 10 NM E AU C 10 F R 10 NM E AU C 10 F R 10 NM E AU C 10 F R 10 NM E AU C 10 F R 10 NM E AU C 10 F R 10 NM E AU C 10 F R 10 ESR 10.29 30.02   as the left eyebrow/eye location improvement in (best viewed after zoom-in). Finally, we analyze the NME distribution produced by the rigid initialization and the final 3DDE model (see). Using the model trained for the WFLW experiment, we align the 2500 test samples of WFLW and plot the distribution of NMEs, produced both with the CNN+3D regressor (softPOSIT result) and the full CNN+3D+DE+CF regressor (3DDE result). The values of percentiles 10 and 90 of the NME distribution are 3.71 and 6.87 for the CNN+3D regressor and 1.03 and 3.32 for the CNN+3D+DE+CF one. So, on average, the full regressor reduces in about 60% the NME achieved by the rigid initialization.

Cross-dataset evaluation
In this section we perform cross-dataset experiments to evaluate the quality of present benchmarks and the generalization of the regressors trained on them. Here we benefit from the fact that 3DDE maybe trained in a semi-supervised way, i.e., using data sets with missing or unlabeled landmarks. To this end we select 24 distinct facial landmarks (see). We consider them distinct because they maybe accurately located by a human annotator. We train and evaluate 3DDE respectively with the training and test sets of each database. We have also performed one more experiment training 3DDE with the training sets of all data bases and evaluating it successively with the tests sets of each of them, we denote this experiment with label All.
In we show the results of our evaluation. The smallest database, COFW, has the worst cross-dataset results. On the other hand, the data set with greatest diversity, WFLW, has the best results. Moreover, the model All, trained with the training sets of all data bases, is able to improve, in all cross-dataset experiments, the models trained in a single data set. However, the most prominent outcome of this experiment is that we always achieve the best result when training with the train subset of the same database. This holds even when compared against the model trained with all data sets, confirming the existence of the so-called "data set bias" in current benchmarks.
Ina final experiment we use model All to evaluate the NME of each landmark using the test sets of all data sets (see). The landmarks with highest NME are those related to the ears, the bottom of the mouth and the chin.

Conclusions
We have introduced 3DDE, a robust face alignment method that leverages on good properties of CNNs, cascade of ERT and 3D face models. The CNN provides robust landmark estimations    We use the height as normalization for the NME.   with weak face shape enforcement. The ERT is able to enforce the face shape and achieve better accuracy in landmark detection, but it only converges with a good initialization. Finally, 3D models exploit face orientation information to improve self-occlusion estimation. 3DDE is initialized by robustly fitting a 3D face model to the probability maps produced by the CNN. The 3D model enables 3DDE to handle self-occlusions and successfully deal with both frontal and profile faces. Once initialized, the cascade of ERT only models the non-rigid component of face motion. It provides various benefits, namely, it enforces shape consistency, maybe trained with unlabeled landmarks, estimate landmark visibility and efficiently parallelize the execution of the regression trees within each stage. We have additionally introduced a coarse-to-fine scheme within the cascade of ERT that is able to deal with the combinatorial explosion of local parts deformation. In this case, the usual monolithic ERT will perform poorly when fitting faces with combinations of facial part deformations not present in the training set. This is a fundamental limitation of implicit shape models addressed by 3DDE.
In the experiments we have shown that 3DDE improves, as far as we know, the state-of-theart performance in 300W, COFW, AFLW and WFLW data sets. In our ablation analysis we have shown that all the components of the system critically contribute to the final result.
The availability of large annotated data sets has encouraged research in this area with important performance improvements in recent years. However, as shown in, this problem is still far from being completely solved. A critical question here is whether the models trained with present data sets will generalize to the situations present in real-life operation. The cross-dataset experiments performed reveal the existence of a significant data set bias in present benchmarks that limit the generalization of models trained with them. So, further work in this direction is required to improve the performance of present face alignment algorithms.: Representative results considered errors using 3DDE in 300W, COFW, AFLW and WFLW testing subsets. Blue colour represents ground truth, green and red colours point out visible and non-visible shape predictions respectively.