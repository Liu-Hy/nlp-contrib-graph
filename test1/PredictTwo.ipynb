{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "designing-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from ast import literal_eval\n",
    "import logging\n",
    "import argparse\n",
    "from simpletransformers.ner import (\n",
    "    NERArgs,\n",
    "    NERModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "productive-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIO_type = 1\n",
    "\n",
    "labelset = [\"B-p\", \"I-p\", \"B-n\", \"I-n\", \"O\"]\n",
    "type_ls = ['-p', '-n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "animal-maintenance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3149\n",
      "3149\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "pos = pd.read_csv('pos_sent.csv')\n",
    "print(len(pos))\n",
    "col_name = pos.columns[6+BIO_type]\n",
    "pos = pos.dropna(axis=0, subset=[col_name])\n",
    "print(len(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oriented-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(pos)):\n",
    "    words = pos.iloc[i, 1].split(' ')\n",
    "    tags = literal_eval(pos.iloc[i, 6+BIO_type])\n",
    "    for j in range(len(words)):\n",
    "        data.append([i, words[j], tags[j]])\n",
    "df = pd.DataFrame(data, columns=['sentence_id', 'words', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "representative-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = NERArgs()\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.save_model_every_epoch = False\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.fp16 = False\n",
    "model_args.manual_seed = 1\n",
    "model_args.use_multiprocessing = True\n",
    "model_args.do_lower_case = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "superior-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_F1(ref, pred):\n",
    "    return 0\n",
    "\n",
    "# Create a TransformerModel\n",
    "model = NERModel(\n",
    "    \"xlmroberta\",\n",
    "    \"../ner/Noutputs/best_model\",\n",
    "    labels=labelset,\n",
    "    args=model_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indonesian-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.ner.ner_model: Converting to features started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6989a2789c8844f5883c44b9734760ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8e3b91ed1842d3a267e4fffb25787a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/394 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/hl/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "INFO:simpletransformers.ner.ner_model:{'eval_loss': 2.7530998868990673, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0, 'F1_score': 0}\n"
     ]
    }
   ],
   "source": [
    "result, model_outputs, pred_label = model.eval_model(df, F1_score=phrase_F1)\n",
    "# 'pred_label' is a list, where each element is the list of predicted labels for one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "filled-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[str(l) for l in pred_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "powered-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.read_csv('pos_sent.csv')\n",
    "pos['BIO_1']=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "guided-princess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>main_heading</th>\n",
       "      <th>heading</th>\n",
       "      <th>topic</th>\n",
       "      <th>paper_idx</th>\n",
       "      <th>BIO</th>\n",
       "      <th>BIO_1</th>\n",
       "      <th>offset1</th>\n",
       "      <th>pro1</th>\n",
       "      <th>offset2</th>\n",
       "      <th>pro2</th>\n",
       "      <th>offset3</th>\n",
       "      <th>pro3</th>\n",
       "      <th>mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "      <th>paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Recurrent Neural Network Grammars</td>\n",
       "      <td>title</td>\n",
       "      <td>title</td>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>0</td>\n",
       "      <td>['O', 'O', 'O', 'O']</td>\n",
       "      <td>['B-n', 'I-n', 'I-n', 'I-n']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>research-problem</td>\n",
       "      <td>title</td>\n",
       "      <td>constituency_parsing0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>In this paper , we introduce recurrent neural ...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>0</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n',...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>11</td>\n",
       "      <td>0.049327</td>\n",
       "      <td>4</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>model</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>constituency_parsing0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>We give two variants of the algorithm , one fo...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>0</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>14</td>\n",
       "      <td>0.062780</td>\n",
       "      <td>7</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1</td>\n",
       "      <td>model</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>constituency_parsing0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Similar to previously published discriminative...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>0</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>19</td>\n",
       "      <td>0.085202</td>\n",
       "      <td>12</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>model</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>constituency_parsing0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>We present a simple importance sampling algori...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Refer to for an example .</td>\n",
       "      <td>constituency_parsing</td>\n",
       "      <td>0</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', ...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>24</td>\n",
       "      <td>0.107623</td>\n",
       "      <td>17</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1</td>\n",
       "      <td>model</td>\n",
       "      <td>Introduction: Refer to for an example .</td>\n",
       "      <td>constituency_parsing0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>17</td>\n",
       "      <td>The key insights in our approach are 1 . to jo...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>natural_language_inference</td>\n",
       "      <td>9</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>9</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1</td>\n",
       "      <td>approach</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>natural_language_inference9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>18</td>\n",
       "      <td>We refer to our model as BERT joint to emphasi...</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>natural_language_inference</td>\n",
       "      <td>9</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n',...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>17</td>\n",
       "      <td>0.261538</td>\n",
       "      <td>10</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1</td>\n",
       "      <td>approach</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>natural_language_inference9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>54</td>\n",
       "      <td>We initialized our model from a BERT model alr...</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>natural_language_inference</td>\n",
       "      <td>9</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>53</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>hyperparameters</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>natural_language_inference9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>56</td>\n",
       "      <td>We trained the model by minimizing loss L from...</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>natural_language_inference</td>\n",
       "      <td>9</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-n', ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>55</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>hyperparameters</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>natural_language_inference9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>60</td>\n",
       "      <td>Our BERT model for NQ performs dramatically be...</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>natural_language_inference</td>\n",
       "      <td>9</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "      <td>['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>59</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>results</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>natural_language_inference9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3149 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      idx                                               text  main_heading  \\\n",
       "0       2                  Recurrent Neural Network Grammars         title   \n",
       "1      12  In this paper , we introduce recurrent neural ...  Introduction   \n",
       "2      15  We give two variants of the algorithm , one fo...  Introduction   \n",
       "3      20  Similar to previously published discriminative...  Introduction   \n",
       "4      25  We present a simple importance sampling algori...  Introduction   \n",
       "...   ...                                                ...           ...   \n",
       "3144   17  The key insights in our approach are 1 . to jo...  Introduction   \n",
       "3145   18  We refer to our model as BERT joint to emphasi...  Introduction   \n",
       "3146   54  We initialized our model from a BERT model alr...   Experiments   \n",
       "3147   56  We trained the model by minimizing loss L from...   Experiments   \n",
       "3148   60  Our BERT model for NQ performs dramatically be...   Experiments   \n",
       "\n",
       "                        heading                       topic  paper_idx  \\\n",
       "0                         title        constituency_parsing          0   \n",
       "1                  Introduction        constituency_parsing          0   \n",
       "2                  Introduction        constituency_parsing          0   \n",
       "3                  Introduction        constituency_parsing          0   \n",
       "4     Refer to for an example .        constituency_parsing          0   \n",
       "...                         ...                         ...        ...   \n",
       "3144               Introduction  natural_language_inference          9   \n",
       "3145               Introduction  natural_language_inference          9   \n",
       "3146                Experiments  natural_language_inference          9   \n",
       "3147                Experiments  natural_language_inference          9   \n",
       "3148                Experiments  natural_language_inference          9   \n",
       "\n",
       "                                                    BIO  \\\n",
       "0                                  ['O', 'O', 'O', 'O']   \n",
       "1     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "2     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "3     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "4     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "...                                                 ...   \n",
       "3144  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "3145  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "3146  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "3147  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "3148  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...   \n",
       "\n",
       "                                                  BIO_1  offset1      pro1  \\\n",
       "0                          ['B-n', 'I-n', 'I-n', 'I-n']        1  0.000000   \n",
       "1     ['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n',...        4  0.043478   \n",
       "2     ['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', ...        7  0.076087   \n",
       "3     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...       12  0.130435   \n",
       "4     ['O', 'B-p', 'O', 'B-n', 'I-n', 'I-n', 'I-n', ...       17  0.184783   \n",
       "...                                                 ...      ...       ...   \n",
       "3144  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...        9  0.250000   \n",
       "3145  ['O', 'O', 'O', 'O', 'O', 'B-p', 'B-n', 'I-n',...       10  0.277778   \n",
       "3146  ['O', 'B-p', 'B-n', 'I-n', 'B-p', 'O', 'B-n', ...        1  0.111111   \n",
       "3147  ['O', 'B-p', 'O', 'B-n', 'B-p', 'B-n', 'B-n', ...        3  0.333333   \n",
       "3148  ['B-n', 'I-n', 'I-n', 'B-p', 'B-n', 'B-p', 'B-...        7  0.777778   \n",
       "\n",
       "      offset2      pro2  offset3      pro3  mask            labels  \\\n",
       "0           1  0.004484        1  0.000000     1  research-problem   \n",
       "1          11  0.049327        4  0.200000     1             model   \n",
       "2          14  0.062780        7  0.350000     1             model   \n",
       "3          19  0.085202       12  0.600000     1             model   \n",
       "4          24  0.107623       17  0.850000     1             model   \n",
       "...       ...       ...      ...       ...   ...               ...   \n",
       "3144       16  0.246154        9  0.818182     1          approach   \n",
       "3145       17  0.261538       10  0.909091     1          approach   \n",
       "3146       53  0.815385        1  0.111111     1   hyperparameters   \n",
       "3147       55  0.846154        3  0.333333     1   hyperparameters   \n",
       "3148       59  0.907692        7  0.777778     1           results   \n",
       "\n",
       "                                        title                        paper  \n",
       "0                                       title        constituency_parsing0  \n",
       "1                                Introduction        constituency_parsing0  \n",
       "2                                Introduction        constituency_parsing0  \n",
       "3                                Introduction        constituency_parsing0  \n",
       "4     Introduction: Refer to for an example .        constituency_parsing0  \n",
       "...                                       ...                          ...  \n",
       "3144                             Introduction  natural_language_inference9  \n",
       "3145                             Introduction  natural_language_inference9  \n",
       "3146                              Experiments  natural_language_inference9  \n",
       "3147                              Experiments  natural_language_inference9  \n",
       "3148                              Experiments  natural_language_inference9  \n",
       "\n",
       "[3149 rows x 18 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ls = ['-p', '-n']\n",
    "def get_entity_spans(idx, ls):\n",
    "    # given a sequence of BIO taggs, get the list of tuples representing spans of entities\n",
    "    spans = [[],[]]\n",
    "    for t in range(2):\n",
    "        st, ed = 0, 0\n",
    "        for i in range(len(ls)):\n",
    "            #st, ed = 0, 0\n",
    "            if ls[i] == 'B' + type_ls[t]:\n",
    "                st, ed = i, i + 1\n",
    "                for j in range(i+1, len(ls)):\n",
    "                    if ls[j] == 'I' + type_ls[t]:\n",
    "                        ed += 1\n",
    "                    else:\n",
    "                        break\n",
    "                phrase=' '.join(pos.loc[idx,'text'].split(' ')[st:ed])\n",
    "                tup=(phrase, (st, ed))\n",
    "                spans[t].append(tup)\n",
    "    spans[0] = sorted(spans[0], key=lambda x: x[0])\n",
    "    spans[0] = sorted(spans[1], key=lambda x: x[0])\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_spans(k, ls):\n",
    "    spans = [[],[]]\n",
    "    for i in range(len(ls)):\n",
    "        if ls[i]=='B-p':\n",
    "            for j in range(i+1,len(ls)):\n",
    "                if ls[j]!='I-p':\n",
    "                    phrase=' '.join(pos.loc[k,'text'].split(' ')[i:j])\n",
    "                    tup=(phrase, (i, j))\n",
    "                    spans[0].append(tup)\n",
    "                    break\n",
    "        elif ls[i]=='B-n':\n",
    "            for j in range(i+1,len(ls)):\n",
    "                if ls[j]!='I-n':\n",
    "                    phrase=' '.join(pos.loc[k,'text'].split(' ')[i:j])\n",
    "                    tup=(phrase, (i, j))\n",
    "                    spans[1].append(tup)\n",
    "                    break\n",
    "    return spans\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "all=[]\n",
    "for k in range(len(pred_label)):\n",
    "    all.append(get_entity_spans(k, pred_label[k]))\n",
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-engagement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "all=[]\n",
    "for k in range(len(pred_label)):\n",
    "    all.append(get_entity_spans(k, pred_label[k]))\n",
    "all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=pd.read_csv('pos_sent.csv')\n",
    "#dt=dt['labels','text']\n",
    "a=pd.DataFrame(all)\n",
    "a.columns=['predicates', 'subj/obj']\n",
    "a=pd.concat([dt[['labels','text']],a],axis=1)\n",
    "a['triple_A']='[]'\n",
    "a['triple_B']='[]'\n",
    "a['triple_C']='[]'\n",
    "a['triple_D']='[]'\n",
    "a=a.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv('triples.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-bottom",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
