{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval as load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6128\n5421\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('try1.csv')\n",
    "print(len(df))\n",
    "df = df[(df['predicates']!='[]')|(df['subj/obj']!='[]')]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "707"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "6128-5421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb=df[df['triple_B']!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 820 0 1093 46\n"
     ]
    }
   ],
   "source": [
    "a=b=bb=c=d=0\n",
    "for i in range(len(dfb)):\n",
    "    trip_ls=load(dfb.iloc[i,5])\n",
    "    if dfb.iloc[i,3]=='[]':\n",
    "        a+=1\n",
    "    else:\n",
    "        if len(load(dfb.iloc[i,3]))>1:\n",
    "            b+=1\n",
    "        else:\n",
    "            bb+=1\n",
    "        for trip in trip_ls:\n",
    "            np_ls=load(dfb.iloc[i,3])\n",
    "            np_ls=[np[0] for np in np_ls]\n",
    "            if np_ls.index(trip[0])<np_ls.index(trip[2]):\n",
    "                c+=1\n",
    "            else:\n",
    "                d+=1\n",
    "print(a,b,bb,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1652"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "c=0\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i,6]!='[]':\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll=[]\n",
    "for i in range(len(df)):\n",
    "    un_ls=load(df.iloc[i,0])\n",
    "    if len(un_ls)>1:\n",
    "        ll.append(un_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['dataset', 'research-problem'],\n",
       " ['model', 'research-problem'],\n",
       " ['model', 'research-problem'],\n",
       " ['code', 'model'],\n",
       " ['approach', 'research-problem'],\n",
       " ['code', 'experimental-setup'],\n",
       " ['approach', 'research-problem'],\n",
       " ['approach', 'research-problem'],\n",
       " ['model', 'research-problem'],\n",
       " ['code', 'model'],\n",
       " ['approach', 'research-problem'],\n",
       " ['model', 'research-problem'],\n",
       " ['approach', 'research-problem']]"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "len(df[(df['triple_C']!='[]')&(df['triple_D']!='[]')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df[df['triple_C']!='[]']\n",
    "dfc['type']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1535 32 190 0\n"
     ]
    }
   ],
   "source": [
    "a=b=c=d=0\n",
    "for i in range(len(dfc)):\n",
    "    trip_ls = load(dfc.iloc[i,6])\n",
    "    for trip in trip_ls:\n",
    "        if dfc.iloc[i,2]!='[]' and dfc.iloc[i,3]!='[]':\n",
    "            p_ls = load(dfc.iloc[i,2])\n",
    "            np_ls = load(dfc.iloc[i,3])\n",
    "            if trip[1] == p_ls[0][0] and trip[2] == np_ls[0][0]:\n",
    "                if p_ls[0][1][0] < np_ls[0][1][0]:\n",
    "                    dfc.iloc[i,16]=0\n",
    "                    a+=1\n",
    "                else:\n",
    "                    dfc.iloc[i,16]=1\n",
    "                    b+=1\n",
    "            else:\n",
    "                dfc.iloc[i,16]=2\n",
    "                c+=1\n",
    "        else:\n",
    "            dfc.iloc[i,16]=3\n",
    "            d+=1\n",
    "print(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "c=0\n",
    "for i in range(len(dfc)):\n",
    "    if dfc.iloc[i,6]!='[]':\n",
    "        if len(load(dfc.iloc[i,6]))>1:\n",
    "            c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfc[dfc['type']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2336\n1588\n29\n1535\n"
     ]
    }
   ],
   "source": [
    "p1=q=p=f=0\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i,2]!='[]' and df.iloc[i,3]!='[]':\n",
    "        p_ls = load(df.iloc[i,2])\n",
    "        np_ls = load(df.iloc[i,3])\n",
    "        if p_ls[0][1][0] < np_ls[0][1][0]:\n",
    "            f+=1\n",
    "            if df.iloc[i,6]!='[]':\n",
    "                p+=1\n",
    "                trip_ls=load(df.iloc[i,6])\n",
    "                for trip in trip_ls:\n",
    "                    if trip[1]==p_ls[0][0] and trip[2]==np_ls[0][0]:\n",
    "                        p1+=1\n",
    "            if df.iloc[i,7]!='[]':\n",
    "                q+=1\n",
    "print(f)\n",
    "print(p)\n",
    "print(q)\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1864\n64\n1300\n"
     ]
    }
   ],
   "source": [
    "q=p=f=0\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i,2]!='[]' and df.iloc[i,3]!='[]':\n",
    "        p_ls = load(df.iloc[i,2])\n",
    "        np_ls = load(df.iloc[i,3])\n",
    "        if p_ls[0][1][0] > np_ls[0][1][0]:\n",
    "            f+=1\n",
    "            if df.iloc[i,6]!='[]':\n",
    "                p+=1\n",
    "            if df.iloc[i,7]!='[]':\n",
    "                q+=1\n",
    "print(f)\n",
    "print(p)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1210\n0\n330\n"
     ]
    }
   ],
   "source": [
    "q=p=f=0\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i,2]=='[]' and df.iloc[i,3]!='[]':\n",
    "        np_ls = load(df.iloc[i,3])\n",
    "        f+=1\n",
    "        if df.iloc[i,6]!='[]':\n",
    "            p+=1\n",
    "        if df.iloc[i,7]!='[]':\n",
    "            q+=1\n",
    "print(f)\n",
    "print(p)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n0\n0\n"
     ]
    }
   ],
   "source": [
    "q=p=f=0\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i,2]=='[]' and df.iloc[i,3]=='[]':\n",
    "        np_ls = load(df.iloc[i,3])\n",
    "        f+=1\n",
    "        if df.iloc[i,6]!='[]':\n",
    "            p+=1\n",
    "        if df.iloc[i,7]!='[]':\n",
    "            q+=1\n",
    "print(f)\n",
    "print(p)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1659"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "dfd = df[df['triple_D']!='[]']\n",
    "len(dfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1376 1347 340 88 1628 1397\n"
     ]
    }
   ],
   "source": [
    "b1=b2=c=d=e=k=0\n",
    "ll=[]\n",
    "for i in range(len(dfd)):\n",
    "    trip_ls = load(dfd.iloc[i,7])\n",
    "    for trip in trip_ls:\n",
    "        if dfd.iloc[i,3]!='[]':\n",
    "            if dfd.iloc[i,2]!='[]':\n",
    "                b1+=1\n",
    "                if load(dfd.iloc[i,2])[0][1][0]>load(dfd.iloc[i,3])[0][1][0]:\n",
    "                    k+=1\n",
    "            else:\n",
    "                b2+=1\n",
    "            np_ls = load(dfd.iloc[i,3])\n",
    "            if trip[2] == np_ls[0][0]:\n",
    "                d+= 1\n",
    "                ll.append(trip[1])\n",
    "                if trip[1]=='has':\n",
    "                    e+=1\n",
    "            else:\n",
    "                c+=1\n",
    "#(b1,b2,c,d,e)=1376 340 88 1628 1397\n",
    "print(b1,k,b2,c,d,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfd)):\n",
    "    trip_ls = load(dfd.iloc[i,7])\n",
    "    for trip in trip_ls:\n",
    "        if dfd.iloc[i,3]!='[]':\n",
    "            if dfd.iloc[i,2]!='[]':\n",
    "                b1+=1\n",
    "            else:\n",
    "                b2+=1\n",
    "            np_ls = load(dfd.iloc[i,3])\n",
    "            if trip[2] == np_ls[0][0]:\n",
    "                d+= 1\n",
    "                ll.append(trip[1])\n",
    "                if trip[1]=='has':\n",
    "                    e+=1\n",
    "            else:\n",
    "                c+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'has': 1397,\n",
       "         'From': 1,\n",
       "         'introduce': 3,\n",
       "         'use': 55,\n",
       "         'For': 30,\n",
       "         'list of the five MT systems submitted': 3,\n",
       "         'Tasks': 7,\n",
       "         'train': 1,\n",
       "         'In': 9,\n",
       "         'for': 6,\n",
       "         'on': 18,\n",
       "         'name': 8,\n",
       "         'used': 9,\n",
       "         'of': 3,\n",
       "         'shows': 1,\n",
       "         'set': 5,\n",
       "         'During': 1,\n",
       "         'employ': 1,\n",
       "         'propose': 17,\n",
       "         'observe': 7,\n",
       "         'observe that': 2,\n",
       "         'extend': 1,\n",
       "         'remove': 5,\n",
       "         'investigate': 1,\n",
       "         'apply': 1,\n",
       "         'note that': 1,\n",
       "         'Among': 2,\n",
       "         'Ablating': 1,\n",
       "         'In the case of': 1,\n",
       "         'see that': 2,\n",
       "         'present': 1,\n",
       "         'adopt': 2,\n",
       "         'add': 1,\n",
       "         'find that': 3,\n",
       "         'show that': 2,\n",
       "         'notice that': 1,\n",
       "         'At': 1,\n",
       "         'compared with': 1,\n",
       "         'performs': 1,\n",
       "         'initialize': 2,\n",
       "         'As': 1,\n",
       "         'Adding': 1,\n",
       "         'When': 2,\n",
       "         'in': 1,\n",
       "         'compare to': 1,\n",
       "         'Comparing': 1,\n",
       "         'Compared with': 1,\n",
       "         'see': 1,\n",
       "         'On': 3,\n",
       "         'study': 1,\n",
       "         'adopts': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1535\n32\n190\n0\n"
     ]
    }
   ],
   "source": [
    "e=c=b=a=0\n",
    "for i in range(len(dfc)):\n",
    "    trip_ls = load(dfc.iloc[i,6])\n",
    "    for trip in trip_ls:\n",
    "        if dfc.iloc[i,2]!='[]' and dfc.iloc[i,3]!='[]':\n",
    "            p_ls = load(dfc.iloc[i,2])\n",
    "            np_ls = load(dfc.iloc[i,3])\n",
    "            if trip[1] == p_ls[0][0] and trip[2] == np_ls[0][0]:\n",
    "                if p_ls[0][1][0] < np_ls[0][1][0]:\n",
    "                    c += 1\n",
    "                else:\n",
    "                    b += 1\n",
    "            else:\n",
    "                a+=1\n",
    "        else:\n",
    "            e+=1\n",
    "print(c)\n",
    "print(b)\n",
    "print(a)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us=0\n",
    "for i in df['predicates'].values:\n",
    "    if i!='[]':\n",
    "        ls=load(i)\n",
    "        for phrase in ls:\n",
    "            if phrase[0]=='on':\n",
    "                us+=1\n",
    "print(us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\nIn addition , we introduce an interleaved bi-directional architecture to stack LSTM layers in the encoder .\n['Model', 'introduce', 'interleaved bi-directional architecture']\n[('to stack', (9, 11))]\n[('interleaved bi-directional architecture', (6, 9)), ('LSTM layers in the encoder', (11, 16))]\n               \n1\n0\nIt is also evident that the unconstrained models ( tilde - nc - nmt ) achieved the best results .\n['Results', 'achieved', 'best results']\n[('evident', (3, 4))]\n[('unconstrained models', (6, 8)), ('best results', (17, 19))]\n               \n1\nIn addition to explicit dropout regularization , we also use early stopping to prevent over-fitting and use the following process to determine when to stop training .\n['Hyperparameters', 'use', 'early stopping']\n[('to prevent', (12, 14))]\n[('early stopping', (10, 12)), ('over-fitting', (14, 15))]\n               \n0\n2\n1\n1\n1\n3\n2\n2\nare baselines reported by . reports our results on the Narrative QA benchmark .\n['Results', 'on', 'Narrative QA benchmark']\n[]\n[('Narrative QA benchmark', (10, 13))]\n               \nTrecQA and SelQA shows the performance of different models on TrecQA and SelQA datasets for answer sentence selection task that aims to select a set of candidate answer sentences given a question .\n['Results', 'on', 'TrecQA and SelQA datasets']\n[]\n[('TrecQA and SelQA datasets', (10, 14))]\n               \nAnd , the result of ( 11 ) shows that the attentive information functioning as a soft - alignment is significantly effective in semantic sentence matching .\n['Ablation analysis', 'shows', 'attentive information']\n[('functioning as', (13, 15)), ('is', (19, 20)), ('in', (22, 23))]\n[('attentive information', (11, 13)), ('soft - alignment', (16, 19)), ('significantly effective', (20, 22)), ('semantic sentence matching', (23, 26))]\n               \n0\n1\n1\n1\n1\n1\n1\nIn addition , we introduce an answer-question similarity loss to penalize overlap between question and predicted answer , a common feature in the errors of our base model .\n['Model', 'introduce', 'answer-question similarity loss']\n[('to penalize', (9, 11)), ('between', (12, 13))]\n[('answer-question similarity loss', (6, 9)), ('overlap', (11, 12)), ('question and predicted answer', (13, 17))]\n               \n1\n0\n3\n3\n3\nFor example , we observe a 0.2-0.5 % improvement over the decomposable attention model .\n['Results', 'observe', '0.2-0.5 % improvement']\n[('over', (9, 10))]\n[('0.2-0.5 % improvement', (6, 9)), ('decomposable attention model', (11, 14))]\n               \n3\nTo solve the second challenge , we propose a fusion process in DFGN to solve the unrestricted QA challenge .\n['Model', 'propose', 'fusion process']\n[('in', (11, 12)), ('to solve', (13, 15))]\n[('fusion process', (9, 11)), ('DFGN', (12, 13)), ('unrestricted QA challenge', (16, 19))]\n               \n0\n0\n1\n1\n2\n2\n1\n0\n0\n0\nIn experiment 5 , we remove both self - attention and fuse gate , thus retaining only highway network .\n['Ablation analysis', 'remove', 'both self - attention and fuse gate']\n[('retaining only', (15, 17))]\n[('both self - attention and fuse gate', (6, 13)), ('highway network', (17, 19))]\n               \nSimilarly , reports the results on TrecQA ( clean ) .\n['Results', 'on', 'TrecQA ( clean )']\n[]\n[('TrecQA ( clean )', (6, 10))]\n               \n3\n0\n1\n1\nOn the other hand , we propose an end - to - end MRC model named as Knowledge Aided Reader ( KAR ) , which explicitly uses the above extracted general knowledge to assist its attention mechanisms .\n['Approach', 'propose', 'end - to - end MRC model']\n[('named', (15, 16)), ('explicitly uses', (25, 27)), ('to assist', (32, 34))]\n[('end - to - end MRC model', (8, 15)), ('Knowledge Aided Reader ( KAR )', (17, 23)), ('extracted general knowledge', (29, 32)), ('attention mechanisms', (35, 37))]\n               \n1\nFor AP - CNN , AP - biLSTM and QA - LSTM , we also use a learning rate schedule that decreases the learning rate ?\n['Experimental setup', 'use', 'learning rate schedule']\n[('For', (0, 1)), ('that', (20, 21))]\n[('AP - CNN', (1, 4)), ('AP - biLSTM', (5, 8)), ('QA - LSTM', (9, 12)), ('learning rate schedule', (17, 20)), ('decreases', (21, 22)), ('learning rate', (23, 25))]\n               \nIn , we present the experimental results of the four NNs for the TREC - QA dataset .\n['Results', 'for', 'TREC - QA dataset']\n[]\n[('TREC - QA dataset', (13, 17))]\n               \nshows the experimental results of the four NNs for the WikiQA dataset .\n['Results', 'for', 'WikiQA dataset']\n[]\n[('WikiQA dataset', (10, 12))]\n               \n1\n3\n1\n2\n1\n1\nOn MultiNLI , CAFE significantly outperforms ESIM , a strong state - of - the - art model on both settings .\n['Results', 'on', 'MultiNLI']\n[]\n[('MultiNLI', (1, 2)), ('CAFE', (3, 4)), ('significantly outperforms', (4, 6)), ('ESIM', (6, 7))]\n               \n1\n1\n1\n0\n3\n1\n1\n2\n2\nWe apply dropout to every layers in , and set the dropout ratio as 0.2 .\n['Experimental setup', 'set', 'dropout ratio']\n[('apply', (1, 2)), ('to', (3, 4)), ('as', (13, 14))]\n[('dropout', (2, 3)), ('every layers', (4, 6)), ('dropout ratio', (11, 13)), ('0.2', (14, 15))]\n               \n1\n0\n0\n0\nThe hidden size used to compute attention scores is also 75 . ['Experimental setup', 'use', 'hidden size']\nThe results of these are shown in , where we see that neither NumberBatch nor random - relationships nor single - hop common - sense offer statistically significant improvements 7 , whereas our commonsense selection and incorporation mechanism improves performance significantly across all metrics .\n['Ablation analysis', 'see that', 'our commonsense selection and incorporation mechanism']\n[('across', (41, 42))]\n[('our commonsense selection and incorporation mechanism', (32, 38)), ('improves', (38, 39)), ('performance significantly', (39, 41)), ('all metrics', (42, 44))]\n               \n1\n1\n1\n2\n2\n2\nFor all other corpuses , we use a default 70 - 15 - 15 split for the train - dev - test data .\n['Experimental setup', 'use', 'default 70 - 15 - 15 split']\n[('for', (15, 16))]\n[('default 70 - 15 - 15 split', (8, 15)), ('train - dev - test data', (17, 23))]\n               \n0\n0\nTo address this limitation , we present a mechanism to condition our VAE model on the original sentence for which we wish to generate the paraphrases .\n['Model', 'present', 'mechanism']\n[('to condition', (9, 11)), ('on', (14, 15)), ('to generate', (22, 24))]\n[('mechanism', (8, 9)), ('our VAE model', (11, 14)), ('original sentence', (16, 18)), ('paraphrases', (25, 26))]\n               \nIn , we report results for the Quora dataset .\n['Results', 'for', 'Quora dataset']\n[]\n[('Quora dataset', (7, 9))]\n               \n1\n3\nAs a contrastive condition , we find that query expansion with RM3 hurts in both datasets , whether applied to the unexpanded corpus ( BM25 + RM3 ) or the expanded version ( BM25 + Doc2query + RM3 ) .\n['Results', 'find that', 'query expansion']\n[('with', (10, 11)), ('in', (13, 14))]\n[('query expansion', (8, 10)), ('RM3', (11, 12)), ('hurts', (12, 13)), ('both datasets', (14, 16))]\n               \nFor our experiments we use the smaller BERT - base model using the uncased alternative .\n['Experimental setup', 'use', 'smaller BERT - base model']\n[('using', (11, 12))]\n[('smaller BERT - base model', (6, 11)), ('uncased alternative', (13, 15))]\n               \n1\n1\n0\n0\n1\n1\n1\nL2 weight decay of 0.001 ( 0.0005 for QA 10 k ) is used for all weights .\n['Hyperparameters', 'used', 'L2 weight decay']\n[('of', (3, 4))]\n[('L2 weight decay', (0, 3)), ('0.001 ( 0.0005 for QA 10 k )', (4, 12))]\n               \n1\nFurthermore , our boundary model has outperformed the sequence model , achieving an exact match score of 61.1 % and an F1 score of 71.2 % .\n['Results', 'outperformed', 'sequence model']\n[('achieving', (11, 12))]\n[('boundary model', (3, 5)), ('sequence model', (8, 10)), ('exact match score of 61.1 %', (13, 19)), ('an F1 score of 71.2 %', (20, 26))]\n               \n3\n1\nTable 2 reports our results on the Search QA dataset .\n['Results', 'on', 'Search QA dataset']\n[]\n[('Search QA dataset', (7, 10))]\n               \nContrary to MCQ - based datasets , we found that reports our results on the NarrativeQA benchmark .\n['Results', 'on', 'NarrativeQA benchmark']\n[]\n[('NarrativeQA benchmark', (15, 17))]\n               \n3\n1\nSQuAD reports dev scores 8 of our model against several representative models on the popular SQuAD benchmark .\n['Results', 'on', 'popular SQuAD benchmark']\n[]\n[('our model', (6, 8)), ('popular SQuAD benchmark', (14, 17))]\n               \n1\nIn addition , we see that our coverage - based re-ranker achieves consistently good performance on the three datasets , even though its performance is marginally lower than the strength - based re-ranker on the Search QA dataset .\n['Results', 'see that', 'our coverage - based re-ranker']\n[('achieves', (11, 12)), ('on', (15, 16))]\n[('our coverage - based re-ranker', (6, 11)), ('consistently good performance', (12, 15)), ('three datasets', (17, 19))]\n               \n2\n0\n0\n1\n1\n1\n3\n2\n0\n2\nIn addition , we notice that the performance of C - AGGCN with full trees outperforms all C - AGGCNs with pruned trees .\n['Ablation analysis', 'notice that', 'performance']\n[('of', (8, 9)), ('outperforms', (15, 16))]\n[('performance', (7, 8)), ('C - AGGCN with full trees', (9, 15)), ('all C - AGGCNs with pruned trees', (16, 23))]\n               \n0\n1\n3\n1\n1\n1\n1\n1\n2\nFor other parameters , we initialize them by sampling each element from a Gaussian distribution with mean 0 and variance 1 ? d .\n['Hyperparameters', 'initialize', 'other parameters']\n[('by sampling', (7, 9)), ('from', (11, 12)), ('with', (15, 16))]\n[('other parameters', (1, 3)), ('each element', (9, 11)), ('Gaussian distribution', (13, 15)), ('mean 0 and variance 1 ? d', (16, 23))]\n               \n0\nIn particular , we propose two auxiliary tasks as structural scaffolds to improve citation intent prediction : 1 ( 1 ) predicting the section title in which the citation occurs and ( 2 ) predicting whether a sentence needs a citation .\n['Model', 'propose', 'two auxiliary tasks']\n[('as', (8, 9)), ('to improve', (11, 13))]\n[('two auxiliary tasks', (5, 8)), ('structural scaffolds', (9, 11)), ('citation intent prediction', (13, 16))]\n               \nOur contributions are : ( i ) we propose a neural scaffold framework for citation intent classification to incorporate into citations knowledge from structure of scientific papers ; ( ii ) we achieve a new state - of - the - art of 67.9 % F1 on the ACL - ARC citations benchmark , an absolute 13.3 % increase over the previous state - of - the - art ; and ( iii ) we introduce SciCite , a new dataset of citation intents which is at least five times as large as existing datasets and covers a variety of scientific domains .\n['Model', 'propose', 'neural scaffold framework']\n[('for', (13, 14)), ('to incorporate into', (17, 20)), ('from', (22, 23))]\n[('neural scaffold framework', (10, 13)), ('citation intent classification', (14, 17)), ('citations', (20, 21)), ('knowledge', (21, 22)), ('structure of scientific papers', (23, 27))]\n               \n0\n1\n0\n2\nIn this paper , we propose a method to mitigate the possible problems when using translated sentences as context based on the following observations .\n['Approach', 'propose', 'method']\n[('to mitigate', (8, 10)), ('when using', (13, 15)), ('as', (17, 18))]\n[('method', (7, 8)), ('possible problems', (11, 13)), ('translated sentences', (15, 17)), ('context', (18, 19))]\n               \n0\n2\n1\n0\n3\n1\nIn preparing the textual dataset , we first use the released transcripts of the IEMOCAP dataset for simplicity .\n['Hyperparameters', 'use', 'released transcripts']\n[('of', (12, 13)), ('for', (16, 17))]\n[('released transcripts', (10, 12)), ('IEMOCAP dataset', (14, 16)), ('simplicity', (17, 18))]\n               \nTo optimize the parameters , we use Stochastic Gradient Descent ( SGD ) optimizer , starting with an initial learning Utterances whose history has atleast 3 similar emotion labels in either own history or the history of the other person , is counted in case 1 or 2 , respectively .\n['Hyperparameters', 'use', 'Stochastic Gradient Descent ( SGD ) optimizer']\n[('starting with', (15, 17)), ('whose history has', (21, 24))]\n[('Stochastic Gradient Descent ( SGD ) optimizer', (7, 14)), ('initial learning Utterances', (18, 21)), ('atleast 3 similar emotion labels', (24, 29))]\n               \n0\n0\n2\n2\n0\n2\n1\n2\n0\nIn addition , we propose a hierarchical self - attention mechanism allowing KET to model the hierarchical structure of conversations .\n['Model', 'propose', 'hierarchical self - attention mechanism']\n[('allowing', (11, 12)), ('to model', (13, 15))]\n[('hierarchical self - attention mechanism', (6, 11)), ('KET', (12, 13)), ('hierarchical structure of conversations', (16, 20))]\n               \n1\n2\n0\n0\n3\n0\n2\n3\n3\nTo better address these concerns we propose a novel fusion method by focusing on inter-modality relations computed between the target utterance and its context .\n['Model', 'propose', 'novel fusion method']\n[('focusing on', (12, 14)), ('computed between', (16, 18))]\n[('novel fusion method', (8, 11)), ('inter-modality relations', (14, 16)), ('target utterance and its context', (19, 24))]\n               \n0\n0\n1\n1\n3\nIn this regard , we propose a novel bidirectional filter generation mechanism to allow interactions between sentence pairs while constructing context - sensitive representations .\n['Approach', 'propose', 'novel bidirectional filter generation mechanism']\n[('to allow', (12, 14)), ('while constructing', (18, 20))]\n[('novel bidirectional filter generation mechanism', (7, 12)), ('interactions between sentence pairs', (14, 18)), ('context - sensitive representations', (20, 24))]\n               \n0\n0\n1\n1\n1\n0\n0\n0\n1\n1\n1\n0\n3\nWe compare our method with the previous state - of - the - art CNN with NSGD ( which is reproduced by ourself ) on our internal dataset , as shown in .\n['Results', 'on', 'internal dataset']\n[('by', (21, 22))]\n[('CNN with NSGD', (14, 17)), ('internal dataset', (26, 28))]\n               \nSince a mel-spectrogram sequence is much longer than its corresponding phoneme sequence , in order to solve the problem of length mismatch between the two sequences , FastSpeech adopts a length regulator that up - samples the phoneme sequence according to the phoneme duration ( i.e. , the number of mel- spectrograms that each phoneme corresponds to ) to match the length of the mel-spectrogram sequence .\n['Model', 'adopts', 'length regulator']\n[('up - samples', (33, 36)), ('to match', (58, 60))]\n[('length regulator', (30, 32)), ('phoneme sequence according to the phoneme duration', (37, 44)), ('length of the mel-spectrogram sequence', (61, 66))]\n               \n0\nAs opposed to performing a binary classification task , we propose to train the ranker to rank the machine - written sentences lower than human - written sentences with respect to a reference sentence which is human-written .\n['Model', 'propose', 'train']\n[('to rank', (15, 17)), ('lower than', (22, 24)), ('with respect to', (28, 31)), ('which is', (34, 36))]\n[('train', (12, 13)), ('ranker', (14, 15)), ('machine - written sentences', (18, 22)), ('human - written sentences', (24, 28)), ('reference sentence', (32, 34)), ('human-written', (36, 37))]\n               \n1\n1\n1\nBased on the performance on the validation set , we set the hidden size to 512 , embedding size to 64 and vocabulary size to 40 K for baseline models and the proposed model .\n['Hyperparameters', 'set', 'hidden size']\n[]\n[('hidden size', (12, 14)), ('512', (15, 16)), ('embedding size', (17, 19)), ('64', (20, 21)), ('vocabulary size', (22, 24)), ('40 K', (25, 27))]\n               \nBased on the performance on the validation set , we set the hidden size to 512 , embedding size to 64 and vocabulary size to 40 K for baseline models and the proposed model .\n['Hyperparameters', 'set', 'vocabulary size']\n[]\n[('hidden size', (12, 14)), ('512', (15, 16)), ('embedding size', (17, 19)), ('64', (20, 21)), ('vocabulary size', (22, 24)), ('40 K', (25, 27))]\n               \nBased on the performance on the validation set , we set the hidden size to 512 , embedding size to 64 and vocabulary size to 40 K for baseline models and the proposed model .\n['Hyperparameters', 'set', 'embedding size']\n[]\n[('hidden size', (12, 14)), ('512', (15, 16)), ('embedding size', (17, 19)), ('64', (20, 21)), ('vocabulary size', (22, 24)), ('40 K', (25, 27))]\n               \n1\n1\n1\n1\nFollowing , we also use drop word for the LSTM decoder , the drop word ratio is selected from [ 0 , 0.3 , 0.5 , 0.7 ] .\n['Hyperparameters', 'use', 'drop word']\n[('for', (7, 8)), ('selected from', (17, 19))]\n[('drop word', (5, 7)), ('LSTM decoder', (9, 11)), ('drop word ratio', (13, 16)), ('0 , 0.3 , 0.5 , 0.7', (20, 27))]\n               \nFollowing , we also use drop word for the LSTM decoder , the drop word ratio is selected from [ 0 , 0.3 , 0.5 , 0.7 ] .\n['Hyperparameters', 'use', 'drop word ratio']\n[('for', (7, 8)), ('selected from', (17, 19))]\n[('drop word', (5, 7)), ('LSTM decoder', (9, 11)), ('drop word ratio', (13, 16)), ('0 , 0.3 , 0.5 , 0.7', (20, 27))]\n               \n0\n1\n3\nAs to the baselines for Gigaword , ABS and ABS + are the models with local attention and handcrafted features .\n['Baselines', 'for', 'Gigaword']\n[('are', (11, 12)), ('with', (14, 15))]\n[('Gigaword', (5, 6)), ('ABS and ABS +', (7, 11)), ('models', (13, 14)), ('local attention and handcrafted features', (15, 20))]\n               \nTo both speedup the training and converge quickly , we use mini-batch size 64 by grid search .\n['Hyperparameters', 'use', 'mini-batch size 64']\n[('To both speedup', (0, 3)), ('by', (14, 15))]\n[('training and converge quickly', (4, 8)), ('mini-batch size 64', (11, 14)), ('grid search', (15, 17))]\n               \n1\n1\n3\n1\n0\n0\n1\n0\n0\n0\n0\n1469 220 27\n"
     ]
    }
   ],
   "source": [
    "u=v=w=0\n",
    "for i in range(len(dfd)):\n",
    "    if dfd.iloc[i,7]!='[]':\n",
    "        trip_ls=load(dfd.iloc[i,7])\n",
    "        for trip in trip_ls:\n",
    "            if trip[1]=='has':\n",
    "                u+=1\n",
    "            else:\n",
    "                if trip[1] in dfd.iloc[i,1]:\n",
    "                    v+=1\n",
    "                    try:\n",
    "                        idd=dfd.iloc[i,1].split().index(trip[1].split()[0])\n",
    "                        if idd<=3:\n",
    "                            print(idd)\n",
    "                        else:\n",
    "                            print(dfd.iloc[i,1])\n",
    "                            print(trip)\n",
    "                            print(dfd.iloc[i,2])\n",
    "                            print(dfd.iloc[i,3])\n",
    "                            print('               ')\n",
    "                    except ValueError:\n",
    "                        print(dfd.iloc[i,1],trip)\n",
    "                else:\n",
    "                    w+=1\n",
    "print(u,v,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['info_unit']=='research-problem') & (df['triple_C']!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['info_unit']=='research-problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=0\n",
    "for i in range(len(df)):\n",
    "    cand = ['github.','github .','https:','https :','http:','http :']\n",
    "    for cue in cand:\n",
    "        if cue in df.iloc[i,1]:\n",
    "            z+=1\n",
    "            print(df.iloc[i,0])\n",
    "            print(df.iloc[i,1])\n",
    "            print('')\n",
    "            break\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "for i in range(len(df)):\n",
    "    if 'dataset' in load(df.iloc[i,0]):\n",
    "        print(df.iloc[i,1])\n",
    "        print('')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "for i in range(len(df)):\n",
    "    if 'experimental-setup' in df.iloc[i,0]:\n",
    "        t+=1\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Transformer', 'with', 'RNN and CNN based models'] ['Transformer', 'outperforms', 'RNN and CNN based models']\n['DRGD', 'baseline for', 'Gigaword'] ['Gigaword', 'has', 'DRGD']\nCounter({'has': 968, 'name': 143, 'of': 8, 'is': 4, 'outperforms': 3, 'on': 2, 'where': 1, 'get': 1, 'using': 1, 'to': 1, 'by': 1, 'with': 1, 'when': 1, 'removal of': 1, 'than': 1, 'in': 1, 'are': 1})\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "m=0\n",
    "from collections import Counter\n",
    "add=[]\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i,4]!='[]':\n",
    "        trip_ls1=load(df.iloc[i,4])\n",
    "    else:\n",
    "        trip_ls1=[]\n",
    "    trip_ls=load(df.iloc[i,5])\n",
    "    for trip in trip_ls:\n",
    "        add.append(trip[1])\n",
    "        for tp in trip_ls1:\n",
    "            if tp[0]==trip[0] and tp[2]==trip[2]:\n",
    "                print(tp,trip)\n",
    "            elif tp[0]==trip[2] and tp[2]==trip[0]:\n",
    "                print(tp,trip)\n",
    "\n",
    "c=Counter(add)\n",
    "print(c)\n",
    "#print(k,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=b=c=d=e=f=0\n",
    "df2=pd.read_csv('../interim/pos_sent.csv')\n",
    "for i in range(len(df2)):\n",
    "    if 'approach' in load(df2.iloc[i,12]):\n",
    "        if 'method' in df2.iloc[i,1].lower() or 'application' in df2.iloc[i,1].lower():\n",
    "            a+=1\n",
    "        if isinstance(df2.iloc[i,2],str):\n",
    "            if 'method' in df2.iloc[i,2].lower() or 'application' in df2.iloc[i,2].lower():\n",
    "                b+=1\n",
    "        if isinstance(df2.iloc[i,3],str):\n",
    "            if 'method' in df2.iloc[i,3].lower() or 'application' in df2.iloc[i,3].lower():\n",
    "                c+=1\n",
    "        if 'system' in df2.iloc[i,1].lower() or 'architecture' in df2.iloc[i,1].lower():\n",
    "            d+=1\n",
    "        if isinstance(df2.iloc[i,2],str):\n",
    "            if 'system' in df2.iloc[i,2].lower() or 'architecture' in df2.iloc[i,2].lower():\n",
    "                e+=1\n",
    "        if isinstance(df2.iloc[i,3],str):\n",
    "            if 'system' in df2.iloc[i,3].lower() or 'architecture' in df2.iloc[i,3].lower():\n",
    "                f+=1\n",
    "print(a,b,c)\n",
    "print(d,e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=b=c=d=e=f=0\n",
    "df2=pd.read_csv('../interim/pos_sent.csv')\n",
    "for i in range(len(df2)):\n",
    "    if 'model' in load(df2.iloc[i,12]):\n",
    "        if 'method' in df2.iloc[i,1].lower() or 'application' in df2.iloc[i,1].lower():\n",
    "            a+=1\n",
    "        if isinstance(df2.iloc[i,2],str):\n",
    "            if 'method' in df2.iloc[i,2].lower() or 'application' in df2.iloc[i,2].lower():\n",
    "                b+=1\n",
    "        if isinstance(df2.iloc[i,3],str):\n",
    "            if 'method' in df2.iloc[i,3].lower() or 'application' in df2.iloc[i,3].lower():\n",
    "                c+=1\n",
    "        if 'system' in df2.iloc[i,1].lower() or 'architecture' in df2.iloc[i,1].lower():\n",
    "            d+=1\n",
    "        if isinstance(df2.iloc[i,2],str):\n",
    "            if 'system' in df2.iloc[i,2].lower() or 'architecture' in df2.iloc[i,2].lower():\n",
    "                e+=1\n",
    "        if isinstance(df2.iloc[i,3],str):\n",
    "            if 'system' in df2.iloc[i,3].lower() or 'architecture' in df2.iloc[i,3].lower():\n",
    "                f+=1\n",
    "print(a,b,c)\n",
    "print(d,e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=[]\n",
    "df2=pd.read_csv('../interim/pos_sent.csv')\n",
    "for i in range(len(df2)):\n",
    "    if 'approach' in load(df2.iloc[i,12]):\n",
    "        a=b=0\n",
    "        if 'method' in df2.iloc[i,1].lower() or 'application' in df2.iloc[i,1].lower():\n",
    "            a+=1\n",
    "        if isinstance(df2.iloc[i,2],str):\n",
    "            if 'method' in df2.iloc[i,2].lower() or 'application' in df2.iloc[i,2].lower():\n",
    "                a+=1\n",
    "        if isinstance(df2.iloc[i,3],str):\n",
    "            if 'method' in df2.iloc[i,3].lower() or 'application' in df2.iloc[i,3].lower():\n",
    "                a+=1\n",
    "        if 'system' in df2.iloc[i,1].lower() or 'architecture' in df2.iloc[i,1].lower():\n",
    "            b+=1\n",
    "        if isinstance(df2.iloc[i,2],str):\n",
    "            if 'system' in df2.iloc[i,2].lower() or 'architecture' in df2.iloc[i,2].lower():\n",
    "                b+=1\n",
    "        if isinstance(df2.iloc[i,3],str):\n",
    "            if 'system' in df2.iloc[i,3].lower() or 'architecture' in df2.iloc[i,3].lower():\n",
    "                b+=1\n",
    "        tup=(a,b)\n",
    "        r.append(tup)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(len(df2)):\n",
    "    if 'approach' in load(df2.iloc[i,12]):\n",
    "        tp=df2.iloc[i,4]+str(df2.iloc[i,5])\n",
    "        l.append(tp)\n",
    "ls=set(l)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=[]\n",
    "for i in range(len(df2)):\n",
    "    if 'model' in load(df2.iloc[i,12]):\n",
    "        tp=df2.iloc[i,4]+str(df2.iloc[i,5])\n",
    "        l2.append(tp)\n",
    "ls2=set(l2)\n",
    "ls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls&ls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2=pd.read_csv('../interim/pos_sent.csv')\n",
    "l=[]\n",
    "for i in range(len(df2)):\n",
    "    if 'hyperparameters' in load(df2.iloc[i,12]):\n",
    "        tp=df2.iloc[i,4]+str(df2.iloc[i,5])\n",
    "        l.append(tp)\n",
    "ls=set(l)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=[]\n",
    "for i in range(len(df2)):\n",
    "    if 'experimental-setup' in load(df2.iloc[i,12]):\n",
    "        tp=df2.iloc[i,4]+str(df2.iloc[i,5])\n",
    "        l2.append(tp)\n",
    "ls2=set(l2)\n",
    "ls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls&ls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=b=c=d=e=f=0\n",
    "df2=pd.read_csv('../interim/pos_sent.csv')\n",
    "for i in range(len(df2)):\n",
    "    if 'experimental-setup' in load(df2.iloc[i,12]):\n",
    "        if 'experimental setup' in df2.iloc[i,1].lower(): \n",
    "            a+=1\n",
    "        if isinstance(df2.iloc[i,2],str):\n",
    "            if 'experimental setup' in df2.iloc[i,2].lower():\n",
    "                b+=1\n",
    "        if isinstance(df2.iloc[i,3],str):\n",
    "            if 'experimental setup' in df2.iloc[i,3].lower():\n",
    "                c+=1\n",
    "        if 'hyperparameters' in df2.iloc[i,1].lower():\n",
    "            d+=1\n",
    "        if isinstance(df2.iloc[i,2],str):\n",
    "            if 'hyperparameters' in df2.iloc[i,2].lower():\n",
    "                e+=1\n",
    "        if isinstance(df2.iloc[i,3],str):\n",
    "            if 'hyperparameters' in df2.iloc[i,3].lower():\n",
    "                f+=1\n",
    "print(a,b,c)\n",
    "print(d,e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=b=c=d=e=f=0\n",
    "df2=pd.read_csv('../interim/pos_sent.csv')\n",
    "for i in range(len(df2)):\n",
    "    if 'hyperparameters' in load(df2.iloc[i,12]):\n",
    "        if 'hyperparameters' in df2.iloc[i,1].lower():\n",
    "            a+=1\n",
    "        if isinstance(df2.iloc[i,2],str):\n",
    "            if 'hyperparameters' in df2.iloc[i,2].lower():\n",
    "                b+=1\n",
    "        if isinstance(df2.iloc[i,3],str):\n",
    "            if 'hyperparameters' in df2.iloc[i,3].lower():\n",
    "                c+=1\n",
    "        if 'experimental setup' in df2.iloc[i,1].lower():\n",
    "            d+=1\n",
    "        if isinstance(df2.iloc[i,2],str):\n",
    "            if 'experimental setup' in df2.iloc[i,2].lower():\n",
    "                e+=1\n",
    "        if isinstance(df2.iloc[i,3],str):\n",
    "            if 'experimental setup' in df2.iloc[i,3].lower():\n",
    "                f+=1\n",
    "print(a,b,c)\n",
    "print(d,e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['BIO_1'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 info_unit                                               text  \\\n",
       "0     ['research-problem']  Learning Phrase Representations using RNN Enco...   \n",
       "1     ['research-problem']  Along this line of research on using neural ne...   \n",
       "2                ['model']  The proposed neural network architecture , whi...   \n",
       "4                ['model']  The two networks are trained jointly to maximi...   \n",
       "5                ['model']  Additionally , we propose to use a rather soph...   \n",
       "...                    ...                                                ...   \n",
       "6123           ['results']  presents the classification results on Fisher ...   \n",
       "6124           ['results']  We can see that our proposed systems achieve c...   \n",
       "6125           ['results']  presents classification results on 20 Newsgrou...   \n",
       "6126           ['results']  We see that the topic ID systems based on Baye...   \n",
       "6127           ['results']  We can also see that all the topic ID systems ...   \n",
       "\n",
       "                                             predicates  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2     [('refer to as', (9, 12)), ('consists of', (18...   \n",
       "4     [('trained', (4, 5)), ('to maximize', (6, 8)),...   \n",
       "5       [('propose', (3, 4)), ('to improve', (13, 15))]   \n",
       "...                                                 ...   \n",
       "6123                                 [('with', (8, 9))]   \n",
       "6124  [('see that', (2, 4)), ('achieve', (7, 8)), ('...   \n",
       "6125                                                 []   \n",
       "6126  [('see that', (1, 3)), ('better than', (15, 17...   \n",
       "6127           [('consistently better than', (15, 18))]   \n",
       "\n",
       "                                               subj/obj  \\\n",
       "0        [('Statistical Machine Translation', (9, 12))]   \n",
       "1     [('SMT', (10, 11)), ('phrase - based SMT', (30...   \n",
       "2     [('neural network architecture', (2, 5)), ('RN...   \n",
       "4     [('jointly', (5, 6)), ('conditional probabilit...   \n",
       "5     [('sophisticated hidden unit', (8, 11)), ('bot...   \n",
       "...                                                 ...   \n",
       "6123  [('Fisher speech corpora', (5, 8)), ('manual a...   \n",
       "6124  [('our proposed systems', (4, 7)), ('consisten...   \n",
       "6125                [('20 Newsgroups dataset', (4, 7))]   \n",
       "6126  [('topic ID systems based on Bayesian SMM and ...   \n",
       "6127  [('topic ID systems based on Bayesian SMM', (7...   \n",
       "\n",
       "                                               triple_A  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2     [['neural network architecture', 'refer to as'...   \n",
       "4     [['jointly', 'to maximize', 'conditional proba...   \n",
       "5     [['sophisticated hidden unit', 'to improve', '...   \n",
       "...                                                 ...   \n",
       "6123  [['Fisher speech corpora', 'with', 'manual and...   \n",
       "6124  [['much lower cross - entropy', 'than', 'GLC']...   \n",
       "6125                                                 []   \n",
       "6126  [['topic ID systems based on Bayesian SMM and ...   \n",
       "6127  [['topic ID systems based on Bayesian SMM', 'c...   \n",
       "\n",
       "                                             triple_B  \\\n",
       "0                                                  []   \n",
       "1                                                  []   \n",
       "2                                                  []   \n",
       "4                                                  []   \n",
       "5                                                  []   \n",
       "...                                               ...   \n",
       "6123                                               []   \n",
       "6124  [['GLCU', 'has', 'much lower cross - entropy']]   \n",
       "6125                                               []   \n",
       "6126                                               []   \n",
       "6127                                               []   \n",
       "\n",
       "                                               triple_C  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "4                                                    []   \n",
       "5     [['Model', 'propose', 'sophisticated hidden un...   \n",
       "...                                                 ...   \n",
       "6123                                                 []   \n",
       "6124                                                 []   \n",
       "6125                                                 []   \n",
       "6126                                                 []   \n",
       "6127                                                 []   \n",
       "\n",
       "                                               triple_D  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2     [['Model', 'has', 'neural network architecture']]   \n",
       "4                                                    []   \n",
       "5                                                    []   \n",
       "...                                                 ...   \n",
       "6123      [['Results', 'has', 'Fisher speech corpora']]   \n",
       "6124                                                 []   \n",
       "6125      [['Results', 'has', '20 Newsgroups dataset']]   \n",
       "6126                                                 []   \n",
       "6127                                                 []   \n",
       "\n",
       "                                               triple_E  \\\n",
       "0     [['Contribution', 'has research problem', 'Sta...   \n",
       "1     [['Contribution', 'has research problem', 'SMT...   \n",
       "2                                                    []   \n",
       "4                                                    []   \n",
       "5                                                    []   \n",
       "...                                                 ...   \n",
       "6123                                                 []   \n",
       "6124                                                 []   \n",
       "6125                                                 []   \n",
       "6126                                                 []   \n",
       "6127                                                 []   \n",
       "\n",
       "                                                 SPEC_1 SPEC_2 SPEC_3  \\\n",
       "0                                                    []     []     []   \n",
       "1                                                    []     []     []   \n",
       "2                                                    []     []     []   \n",
       "4     [['two recurrent neural networks ( RNN )', 'tr...     []     []   \n",
       "5                                                    []     []     []   \n",
       "...                                                 ...    ...    ...   \n",
       "6123                                                 []     []     []   \n",
       "6124  [['Fisher speech corpora', 'see that', 'GLCU']...     []     []   \n",
       "6125                                                 []     []     []   \n",
       "6126  [['20 Newsgroups dataset', 'see that', 'topic ...     []     []   \n",
       "6127                                                 []     []     []   \n",
       "\n",
       "                                                 SPEC_4                topic  \\\n",
       "0                                                    []  machine-translation   \n",
       "1                                                    []  machine-translation   \n",
       "2                                                    []  machine-translation   \n",
       "4                                                    []  machine-translation   \n",
       "5                                                    []  machine-translation   \n",
       "...                                                 ...                  ...   \n",
       "6123                                                 []         topic_models   \n",
       "6124                                                 []         topic_models   \n",
       "6125  [['20 Newsgroups dataset', 'see that', 'topic ...         topic_models   \n",
       "6126                                                 []         topic_models   \n",
       "6127                                                 []         topic_models   \n",
       "\n",
       "      paper_idx  idx  \n",
       "0             0    2  \n",
       "1             0   15  \n",
       "2             0   16  \n",
       "4             0   18  \n",
       "5             0   19  \n",
       "...         ...  ...  \n",
       "6123          0  362  \n",
       "6124          0  367  \n",
       "6125          0  370  \n",
       "6126          0  376  \n",
       "6127          0  377  \n",
       "\n",
       "[5421 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>info_unit</th>\n      <th>text</th>\n      <th>predicates</th>\n      <th>subj/obj</th>\n      <th>triple_A</th>\n      <th>triple_B</th>\n      <th>triple_C</th>\n      <th>triple_D</th>\n      <th>triple_E</th>\n      <th>SPEC_1</th>\n      <th>SPEC_2</th>\n      <th>SPEC_3</th>\n      <th>SPEC_4</th>\n      <th>topic</th>\n      <th>paper_idx</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['research-problem']</td>\n      <td>Learning Phrase Representations using RNN Enco...</td>\n      <td>[]</td>\n      <td>[('Statistical Machine Translation', (9, 12))]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[['Contribution', 'has research problem', 'Sta...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>machine-translation</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['research-problem']</td>\n      <td>Along this line of research on using neural ne...</td>\n      <td>[]</td>\n      <td>[('SMT', (10, 11)), ('phrase - based SMT', (30...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[['Contribution', 'has research problem', 'SMT...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>machine-translation</td>\n      <td>0</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['model']</td>\n      <td>The proposed neural network architecture , whi...</td>\n      <td>[('refer to as', (9, 12)), ('consists of', (18...</td>\n      <td>[('neural network architecture', (2, 5)), ('RN...</td>\n      <td>[['neural network architecture', 'refer to as'...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[['Model', 'has', 'neural network architecture']]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>machine-translation</td>\n      <td>0</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['model']</td>\n      <td>The two networks are trained jointly to maximi...</td>\n      <td>[('trained', (4, 5)), ('to maximize', (6, 8)),...</td>\n      <td>[('jointly', (5, 6)), ('conditional probabilit...</td>\n      <td>[['jointly', 'to maximize', 'conditional proba...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[['two recurrent neural networks ( RNN )', 'tr...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>machine-translation</td>\n      <td>0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>['model']</td>\n      <td>Additionally , we propose to use a rather soph...</td>\n      <td>[('propose', (3, 4)), ('to improve', (13, 15))]</td>\n      <td>[('sophisticated hidden unit', (8, 11)), ('bot...</td>\n      <td>[['sophisticated hidden unit', 'to improve', '...</td>\n      <td>[]</td>\n      <td>[['Model', 'propose', 'sophisticated hidden un...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>machine-translation</td>\n      <td>0</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6123</th>\n      <td>['results']</td>\n      <td>presents the classification results on Fisher ...</td>\n      <td>[('with', (8, 9))]</td>\n      <td>[('Fisher speech corpora', (5, 8)), ('manual a...</td>\n      <td>[['Fisher speech corpora', 'with', 'manual and...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[['Results', 'has', 'Fisher speech corpora']]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>topic_models</td>\n      <td>0</td>\n      <td>362</td>\n    </tr>\n    <tr>\n      <th>6124</th>\n      <td>['results']</td>\n      <td>We can see that our proposed systems achieve c...</td>\n      <td>[('see that', (2, 4)), ('achieve', (7, 8)), ('...</td>\n      <td>[('our proposed systems', (4, 7)), ('consisten...</td>\n      <td>[['much lower cross - entropy', 'than', 'GLC']...</td>\n      <td>[['GLCU', 'has', 'much lower cross - entropy']]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[['Fisher speech corpora', 'see that', 'GLCU']...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>topic_models</td>\n      <td>0</td>\n      <td>367</td>\n    </tr>\n    <tr>\n      <th>6125</th>\n      <td>['results']</td>\n      <td>presents classification results on 20 Newsgrou...</td>\n      <td>[]</td>\n      <td>[('20 Newsgroups dataset', (4, 7))]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[['Results', 'has', '20 Newsgroups dataset']]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[['20 Newsgroups dataset', 'see that', 'topic ...</td>\n      <td>topic_models</td>\n      <td>0</td>\n      <td>370</td>\n    </tr>\n    <tr>\n      <th>6126</th>\n      <td>['results']</td>\n      <td>We see that the topic ID systems based on Baye...</td>\n      <td>[('see that', (1, 3)), ('better than', (15, 17...</td>\n      <td>[('topic ID systems based on Bayesian SMM and ...</td>\n      <td>[['topic ID systems based on Bayesian SMM and ...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[['20 Newsgroups dataset', 'see that', 'topic ...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>topic_models</td>\n      <td>0</td>\n      <td>376</td>\n    </tr>\n    <tr>\n      <th>6127</th>\n      <td>['results']</td>\n      <td>We can also see that all the topic ID systems ...</td>\n      <td>[('consistently better than', (15, 18))]</td>\n      <td>[('topic ID systems based on Bayesian SMM', (7...</td>\n      <td>[['topic ID systems based on Bayesian SMM', 'c...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>topic_models</td>\n      <td>0</td>\n      <td>377</td>\n    </tr>\n  </tbody>\n</table>\n<p>5421 rows  16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}